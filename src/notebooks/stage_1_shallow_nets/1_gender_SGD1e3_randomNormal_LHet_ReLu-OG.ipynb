{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# NECESSARY IMPORTS\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "from keras.models     import Sequential\n",
    "from keras.layers     import Dense, Dropout, Activation, Flatten, advanced_activations\n",
    "from keras.layers     import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "from keras import initializations\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend     as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas                     import Series\n",
    "from scipy.misc                 import imresize\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image  import (ImageDataGenerator, \n",
    "                                        array_to_img,\n",
    "                                        img_to_array,\n",
    "                                        load_img)\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__closure__',\n",
       " '__code__',\n",
       " '__defaults__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__get__',\n",
       " '__getattribute__',\n",
       " '__globals__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__name__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'func_closure',\n",
       " 'func_code',\n",
       " 'func_defaults',\n",
       " 'func_dict',\n",
       " 'func_doc',\n",
       " 'func_globals',\n",
       " 'func_name']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(initializations.normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Ensure reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Path constants\n",
    "DATA_TEMPLATE     = \"./../../data/\"\n",
    "ADIENCE_META_P    = DATA_TEMPLATE + \"adience/meta\"\n",
    "ADIENCE_RAW_P     = DATA_TEMPLATE + \"adience/keras_format\"\n",
    "ADIENCE_AGE_P     = ADIENCE_RAW_P + \"/age\"\n",
    "ADIENCE_GEN_P     = ADIENCE_RAW_P + \"/gender\"\n",
    "IMG_PATH          = DATA_TEMPLATE + \"wiki/%s\"\n",
    "\n",
    "WIKI_META_P       = DATA_TEMPLATE + \"wiki_meta\"\n",
    "MODEL_TEMPLATE    = \"./models/%s\"\n",
    "WEIGHTS_TEMPLATE  = \"./weights/%s\"\n",
    "GRAPHS_TEMPLATE   = \"./graphs/%s\"\n",
    "HISTORY_TEMPLATE   = \"./histories/%s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Independent constants\n",
    "MODEL_NAME = \"1_gender_SGD1e3_randomNormal_LHet_ReLu-OG\"\n",
    "INITIALIZATION = 'normal'\n",
    "LOSS           = \"categorical_crossentropy\"\n",
    "OPTIMIZER      = SGD(lr=1e-3)\n",
    "BATCH_SIZE     = 32\n",
    "\n",
    "\n",
    "PIC_NAME     = GRAPHS_TEMPLATE % (MODEL_NAME + \".png\")\n",
    "PIC_NAME_FINETUNING = GRAPHS_TEMPLATE % (MODEL_NAME + \"_finetuning_.png\")\n",
    "WEIGHTS_NAME = WEIGHTS_TEMPLATE % (MODEL_NAME + \".h5\")\n",
    "TRA_HISTORY_NAME = HISTORY_TEMPLATE % (MODEL_NAME + \"_train_\"+\".npy\")\n",
    "VAL_HISTORY_NAME = HISTORY_TEMPLATE % (MODEL_NAME + \"_valid_\"+\".npy\")\n",
    "\n",
    "\n",
    "WEIGHTS_NAME_FINETUNING = WEIGHTS_TEMPLATE % (MODEL_NAME + \"_finetuning_.h5\")\n",
    "TRA_HISTORY_NAME_FINETUNING = HISTORY_TEMPLATE % (MODEL_NAME + \"_train_\"+\"_finetuning_.npy\")\n",
    "VAL_HISTORY_NAME_FINETUNING = HISTORY_TEMPLATE % (MODEL_NAME + \"_valid_\"+\"_finetuning_.npy\")\n",
    "\n",
    "IMG_WIDTH  = 227\n",
    "IMG_HEIGHT = 227\n",
    "\n",
    "\n",
    "ADIENCE_FULL = [\"idx\",\"user_id\",\"face_id\",\"original_image\",\"gender\",\"age\",\"img_path\",\"keras_path\"]\n",
    "ADIENCE_HEADER = [\"user_id\",\"face_id\",\"original_image\",\"gender\",\"age\",\"img_path\",\"keras_path\"]\n",
    "WIKI_HEADER    = [\"full_path\",\"age\",\"gender\"]\n",
    "\n",
    "NUM_EPOCHS  = 1500\n",
    "NUM_EPOCHS2 = 500\n",
    "\n",
    "\n",
    "BEST_CHECKPOINT = MODEL_NAME + \".weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "BEST_CHECKPOINT_FINE = MODEL_NAME + \"FINETUNE.weights.{epoch:02d}-{val_loss:.2f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "callback1 = ModelCheckpoint(BEST_CHECKPOINT, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callback2 = ModelCheckpoint(BEST_CHECKPOINT_FINE, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dependent constants\n",
    "IMG_DIMS = (IMG_WIDTH, IMG_HEIGHT)\n",
    "MODEL_W  = MODEL_NAME + \".h5\"\n",
    "MODEL_P  = MODEL_NAME + \".txt\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Loading metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Adience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gender_train_path = ADIENCE_META_P + \"/gender_train_0.csv\"\n",
    "gender_valid_path = ADIENCE_META_P + \"/gender_valid_0.csv\"\n",
    "gender_train = pd.read_csv(filepath_or_buffer =gender_train_path)\n",
    "gender_valid = pd.read_csv(filepath_or_buffer =gender_valid_path)\n",
    "\n",
    "gender_train = gender_train[ADIENCE_HEADER]\n",
    "gender_valid = gender_valid[ADIENCE_HEADER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "age_train_path = ADIENCE_META_P + \"/age_train_0.csv\"\n",
    "age_valid_path = ADIENCE_META_P + \"/age_valid_0.csv\"\n",
    "age_train = pd.read_csv(filepath_or_buffer =gender_train_path)\n",
    "age_valid = pd.read_csv(filepath_or_buffer =gender_valid_path)\n",
    "\n",
    "age_train = age_train[ADIENCE_HEADER]\n",
    "age_valid = age_valid[ADIENCE_HEADER]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w_gender_train_path = WIKI_META_P + \"/gender/train_1.csv\"\n",
    "w_gender_valid_path = WIKI_META_P + \"/gender/valid_1.csv\"\n",
    "\n",
    "w_gender_train = pd.read_csv(filepath_or_buffer =w_gender_train_path)\n",
    "w_gender_valid = pd.read_csv(filepath_or_buffer =w_gender_valid_path)\n",
    "\n",
    "w_gender_train = w_gender_train[WIKI_HEADER]\n",
    "w_gender_valid = w_gender_valid[WIKI_HEADER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w_age_train_path = WIKI_META_P + \"/gender/train_1.csv\"\n",
    "w_age_valid_path = WIKI_META_P + \"/gender/valid_1.csv\"\n",
    "w_age_train = pd.read_csv(filepath_or_buffer =w_age_train_path)\n",
    "w_age_valid = pd.read_csv(filepath_or_buffer =w_age_valid_path)\n",
    "\n",
    "w_age_train = w_age_train[WIKI_HEADER]\n",
    "w_age_valid = w_age_valid[WIKI_HEADER]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### SHALLOW-ONLY TASK: Fix age ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fix_age_ranges(age):\n",
    "    if age < 4:\n",
    "        return \"(0, 2)\"\n",
    "    if age < 8:\n",
    "        return \"(4, 6)\"\n",
    "    if age < 15:\n",
    "        return \"(8, 13)\"\n",
    "    if age < 25:\n",
    "        return \"(15, 20)\"\n",
    "    if age < 38:\n",
    "        return \"(25, 32)\"\n",
    "    if age < 48:\n",
    "        return \"(38, 43)\"\n",
    "    if age < 60:\n",
    "        return \"(48, 53)\"\n",
    "    return \"(60-100)\"\n",
    "\n",
    "w_age_train[\"age\"]    = w_age_train[\"age\"].apply(lambda x: fix_age_ranges(x))\n",
    "w_age_valid[\"age\"]    = w_age_valid[\"age\"].apply(lambda x: fix_age_ranges(x))\n",
    "w_gender_train[\"age\"] = w_gender_train[\"age\"].apply(lambda x: fix_age_ranges(x))\n",
    "w_gender_valid[\"age\"] = w_gender_valid[\"age\"].apply(lambda x: fix_age_ranges(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.1 Adience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "adience_train_aug = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "adience_valid_aug = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10505 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "ADIENCE_GENDER_TRAIN_P = ADIENCE_GEN_P + \"/train/1\"\n",
    "adience_gender_train_gen = adience_train_aug.flow_from_directory(\n",
    "    ADIENCE_GENDER_TRAIN_P,\n",
    "    target_size=IMG_DIMS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10505 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "ADIENCE_AGE_TRAIN_P = ADIENCE_AGE_P + \"/train/1\"\n",
    "adience_age_train_gen = adience_train_aug.flow_from_directory(\n",
    "    ADIENCE_AGE_TRAIN_P,\n",
    "    target_size=IMG_DIMS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3502 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "ADIENCE_GENDER_VALID_P = ADIENCE_GEN_P + \"/valid/1\"\n",
    "adience_gender_valid_gen = adience_valid_aug.flow_from_directory(\n",
    "    ADIENCE_GENDER_VALID_P,\n",
    "    target_size=IMG_DIMS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3502 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "ADIENCE_AGE_VALID_P = ADIENCE_AGE_P + \"/valid/1\"\n",
    "adience_age_valid_gen = adience_valid_aug.flow_from_directory(\n",
    "    ADIENCE_AGE_VALID_P,\n",
    "    target_size=IMG_DIMS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3445 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "ADIENCE_GENDER_TEST_P = ADIENCE_GEN_P + \"/test/\"\n",
    "adience_gender_test_gen = adience_valid_aug.flow_from_directory(\n",
    "    ADIENCE_GENDER_TEST_P,\n",
    "    target_size=IMG_DIMS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3445 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "ADIENCE_AGE_TEST_P = ADIENCE_AGE_P + \"/test/\"\n",
    "adience_age_test_gen = adience_valid_aug.flow_from_directory(\n",
    "    ADIENCE_AGE_TEST_P,\n",
    "    target_size=IMG_DIMS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.2 Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "true_path = lambda x: IMG_PATH % x\n",
    "w_age_train[\"full_path\"]    = w_age_train[\"full_path\"].apply(lambda x: true_path(x))\n",
    "w_gender_train[\"full_path\"] = w_gender_train[\"full_path\"].apply(lambda x: true_path(x))\n",
    "w_age_valid[\"full_path\"]    = w_age_valid[\"full_path\"].apply(lambda x: true_path(x))\n",
    "w_gender_valid[\"full_path\"] = w_gender_valid[\"full_path\"].apply(lambda x: true_path(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_image(x):\n",
    "    try:\n",
    "        val = img_to_array(imresize(load_img(x),IMG_DIMS))\n",
    "    except:\n",
    "        val = \"ERR\"\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data generator\n",
    "def generate_test(df, batch_size, target_feature):\n",
    "    start, end = 0, batch_size\n",
    "    while True:\n",
    "        while end < len(dfs.shape[0]):\n",
    "            ages_h = list(pd.get_dummies(data[\"age\"]).columns.values)\n",
    "            ages   = pd.get_dummies(data[\"age\"])\n",
    "            data[ages_h] = ages\n",
    "\n",
    "            sample = data[start:end]\n",
    "            start += batch_size\n",
    "            end   += batch_size\n",
    "\n",
    "            X         = pd.DataFrame(sample[\"full_path\"].apply(lambda x:get_image(x)))\n",
    "            good_rows = X[\"full_path\"] != \"ERR\"\n",
    "            X         = X[good_rows]\n",
    "            X.reset_index(inplace=True)\n",
    "            X = X[\"full_path\"].apply(lambda x: x.reshape((1,)+ x.shape))\n",
    "            X = np.vstack(X)\n",
    "            X /= 255\n",
    "\n",
    "            #X = model.predict(X, X.shape[0])\n",
    "\n",
    "            Y = sample[good_rows]\n",
    "            if target_feature == \"age\":\n",
    "                Y = Y[ages_h].as_matrix()\n",
    "            else:\n",
    "                Y = pd.get_dummies(Y[\"gender\"]).as_matrix()\n",
    "            yield (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data generator\n",
    "def generate_data(df, batch_size, target_feature):\n",
    "    start, end = 0, batch_size\n",
    "    while True:\n",
    "        data   = df.sample(frac=1).reset_index(drop=True)\n",
    "        ages_h = list(pd.get_dummies(data[\"age\"]).columns.values)\n",
    "        ages   = pd.get_dummies(data[\"age\"])\n",
    "        data[ages_h] = ages\n",
    "        \n",
    "        sample = data[start:end]\n",
    "        \n",
    "        X         = pd.DataFrame(sample[\"full_path\"].apply(lambda x:get_image(x)))\n",
    "        good_rows = X[\"full_path\"] != \"ERR\"\n",
    "        X         = X[good_rows]\n",
    "        X.reset_index(inplace=True)\n",
    "        X = X[\"full_path\"].apply(lambda x: x.reshape((1,)+ x.shape))\n",
    "        X = np.vstack(X)\n",
    "        X /= 255\n",
    "        #X = model.predict(X, X.shape[0])\n",
    "        \n",
    "        Y = sample[good_rows]\n",
    "        if target_feature == \"age\":\n",
    "            Y = Y[ages_h].as_matrix()\n",
    "        else:\n",
    "            Y = pd.get_dummies(Y[\"gender\"]).as_matrix()\n",
    "        yield (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w_age_train_gen = generate_data(w_age_train, BATCH_SIZE, \"age\")\n",
    "w_age_valid_gen = generate_data(w_age_valid, BATCH_SIZE, \"age\")\n",
    "w_gender_train_gen = generate_data(w_gender_train, BATCH_SIZE, \"gender\")\n",
    "w_gender_valid_gen = generate_data(w_gender_valid, BATCH_SIZE, \"gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "class LRN2D(Layer):\n",
    "    \"\"\"\n",
    "    This code is adapted from pylearn2.\n",
    "    License at: https://github.com/lisa-lab/pylearn2/blob/master/LICENSE.txt\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=1e-4, k=2, beta=0.75, n=5):\n",
    "        if n % 2 == 0:\n",
    "            raise NotImplementedError(\"LRN2D only works with odd n. n provided: \" + str(n))\n",
    "        super(LRN2D, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.k = k\n",
    "        self.beta = beta\n",
    "        self.n = n\n",
    "\n",
    "    def get_output(self, train):\n",
    "        X = self.get_input(train)\n",
    "        b, ch, r, c = X.shape\n",
    "        half_n = self.n // 2\n",
    "        input_sqr = T.sqr(X)\n",
    "        extra_channels = T.alloc(0., b, ch + 2*half_n, r, c)\n",
    "        input_sqr = T.set_subtensor(extra_channels[:, half_n:half_n+ch, :, :], input_sqr)\n",
    "        scale = self.k\n",
    "        for i in range(self.n):\n",
    "            scale += self.alpha * input_sqr[:, i:i+ch, :, :]\n",
    "        scale = scale ** self.beta\n",
    "        return X / scale\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"name\": self.__class__.__name__,\n",
    "                \"alpha\": self.alpha,\n",
    "                \"k\": self.k,\n",
    "                \"beta\": self.beta,\n",
    "\"n\": self.n}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4. Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Building a vainilla CNN\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(96, 7, 7, input_shape=(IMG_WIDTH,IMG_HEIGHT,3), init=INITIALIZATION))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3),strides=(2,2)))\n",
    "model.add(LRN2D())\n",
    "\n",
    "model.add(Convolution2D(256, 5, 5, init=INITIALIZATION))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3, init=INITIALIZATION))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(LRN2D())\n",
    "\n",
    "model.add(Convolution2D(384, 3, 3, init=INITIALIZATION))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(output_dim=512,input_dim=512, init=INITIALIZATION))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(output_dim=512,input_dim=512, init=INITIALIZATION))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(output_dim=2))\n",
    "model.add(Activation(\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=['accuracy', 'recall', 'precision','f1score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 6. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "32/32 [==============================] - 2s - loss: 5.4311 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 3.6992 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 2/1500\n",
      "32/32 [==============================] - 1s - loss: 2.7931 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 4.3651 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 3/1500\n",
      "32/32 [==============================] - 1s - loss: 5.5481 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 1.0640 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 4/1500\n",
      "32/32 [==============================] - 1s - loss: 2.8075 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 2.5113 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 5/1500\n",
      "32/32 [==============================] - 1s - loss: 2.6008 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 2.0219 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 6/1500\n",
      "32/32 [==============================] - 1s - loss: 3.5371 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 2.1801 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 7/1500\n",
      "32/32 [==============================] - 1s - loss: 1.1495 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 1.0231 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 8/1500\n",
      "32/32 [==============================] - 1s - loss: 3.3704 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 3.0544 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 9/1500\n",
      "32/32 [==============================] - 1s - loss: 3.1401 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4673 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 10/1500\n",
      "32/32 [==============================] - 1s - loss: 2.9326 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 2.3832 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 11/1500\n",
      "32/32 [==============================] - 1s - loss: 2.7568 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.9716 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 12/1500\n",
      "32/32 [==============================] - 1s - loss: 1.7919 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.7929 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 13/1500\n",
      "32/32 [==============================] - 1s - loss: 3.6263 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.8503 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 14/1500\n",
      "32/32 [==============================] - 1s - loss: 1.4481 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 1.2641 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 15/1500\n",
      "32/32 [==============================] - 1s - loss: 0.9963 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.9965 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 16/1500\n",
      "32/32 [==============================] - 1s - loss: 1.7359 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6772 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 17/1500\n",
      "32/32 [==============================] - 1s - loss: 1.3693 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.2219 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 18/1500\n",
      "32/32 [==============================] - 1s - loss: 2.1420 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 1.3275 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 19/1500\n",
      "32/32 [==============================] - 1s - loss: 1.9800 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.9239 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 20/1500\n",
      "32/32 [==============================] - 1s - loss: 1.2578 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2436 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 21/1500\n",
      "32/32 [==============================] - 1s - loss: 1.8351 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.4024 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 22/1500\n",
      "32/32 [==============================] - 1s - loss: 0.9386 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 1.0832 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 23/1500\n",
      "32/32 [==============================] - 1s - loss: 2.0046 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 1.2278 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 24/1500\n",
      "32/32 [==============================] - 1s - loss: 1.6296 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.4137 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 25/1500\n",
      "32/32 [==============================] - 1s - loss: 1.1233 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.8640 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 26/1500\n",
      "32/32 [==============================] - 1s - loss: 1.6373 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.2919 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 27/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8806 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5590 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 28/1500\n",
      "32/32 [==============================] - 1s - loss: 1.2125 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.7444 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 29/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6861 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2700 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 30/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6298 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5121 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 31/1500\n",
      "32/32 [==============================] - 1s - loss: 1.0479 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6138 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 32/1500\n",
      "32/32 [==============================] - 1s - loss: 1.3330 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.5473 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 33/1500\n",
      "32/32 [==============================] - 1s - loss: 0.9458 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5749 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 34/1500\n",
      "32/32 [==============================] - 1s - loss: 1.4182 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.5761 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 35/1500\n",
      "32/32 [==============================] - 1s - loss: 1.0399 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5749 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 36/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7255 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.9476 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 37/1500\n",
      "32/32 [==============================] - 1s - loss: 1.6667 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.5206 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 38/1500\n",
      "32/32 [==============================] - 1s - loss: 1.2888 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.5828 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 39/1500\n",
      "32/32 [==============================] - 1s - loss: 1.0962 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.4706 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 40/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7095 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.2359 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 41/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7980 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4978 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 42/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7992 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4847 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 43/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6268 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5946 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 44/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3048 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2443 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 45/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6275 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.8268 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 46/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5263 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5450 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 47/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5137 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5421 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 48/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8887 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6725 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 49/1500\n",
      "32/32 [==============================] - 1s - loss: 1.4585 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5023 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 50/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8306 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5705 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 51/1500\n",
      "32/32 [==============================] - 1s - loss: 1.1964 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.5841 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 52/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7585 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5376 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 53/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8694 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6189 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 54/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7145 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6719 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 55/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5066 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.5105 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 56/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6572 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4232 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 57/1500\n",
      "32/32 [==============================] - 1s - loss: 1.0906 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.4633 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 58/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6811 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4683 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 59/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7961 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.7554 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 60/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6196 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6793 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 61/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8191 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.5044 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 62/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5719 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6759 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 63/1500\n",
      "32/32 [==============================] - 1s - loss: 0.9181 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.5490 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 64/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8505 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5757 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 65/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5839 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6090 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 66/1500\n",
      "32/32 [==============================] - 1s - loss: 0.9029 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5866 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 67/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7130 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.5964 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 68/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7123 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6329 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 69/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7182 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6491 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 70/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6545 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5834 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 71/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7047 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.5312 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 72/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6522 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5483 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 73/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6402 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6882 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 74/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5112 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6335 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 75/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7090 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.7570 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 76/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5965 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4526 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 77/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7523 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.5622 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 78/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6347 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6356 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 79/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7940 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6314 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 80/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7543 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4201 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 81/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7527 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5203 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 82/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5082 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6485 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 83/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6113 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5221 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 84/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6165 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5525 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 85/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6140 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6337 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 86/1500\n",
      "32/32 [==============================] - 1s - loss: 0.9191 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6221 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 87/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6949 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5934 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 88/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5937 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5974 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 89/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8166 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.5406 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 90/1500\n",
      "32/32 [==============================] - 1s - loss: 1.0027 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.5368 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 91/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6578 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5720 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 92/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4605 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6172 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 93/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6643 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5886 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 94/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5434 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.8535 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 95/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5589 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5405 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 96/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6841 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6832 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 97/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6767 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5433 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 98/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6146 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5671 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 99/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6800 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5562 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 100/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7029 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.7085 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 101/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5909 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6731 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 102/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7891 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6682 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 103/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5364 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5164 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 104/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5679 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5065 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 105/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6000 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4733 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 106/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6791 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5272 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 107/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5652 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5068 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 108/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7568 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5566 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 109/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7522 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6429 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 110/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7058 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6104 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 111/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6714 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5758 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 112/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4864 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5086 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 113/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6012 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.7112 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 114/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5490 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5374 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 115/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6484 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4752 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 116/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7068 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5267 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 117/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7136 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.5691 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 118/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7135 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.5645 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 119/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8260 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6304 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 120/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5173 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5895 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 121/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5785 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5417 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 122/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5714 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5983 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 123/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4538 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6282 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 124/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4996 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.8518 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 125/1500\n",
      "32/32 [==============================] - 1s - loss: 0.9889 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5048 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 126/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3957 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5040 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 127/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5584 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5333 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 128/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6198 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5668 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 129/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7471 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5804 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 130/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5928 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5209 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 131/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3743 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4721 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 132/1500\n",
      "32/32 [==============================] - 1s - loss: 1.0845 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.5912 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 133/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6319 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5686 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 134/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6302 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5300 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 135/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6225 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6827 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 136/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5517 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4350 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 137/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6753 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6451 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 138/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6836 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4851 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 139/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6430 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4821 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 140/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4629 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5415 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 141/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7763 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.4763 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 142/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4638 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6058 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 143/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5059 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6825 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 144/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6146 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4594 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 145/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4607 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.7416 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 146/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6115 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6223 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 147/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7656 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6339 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 148/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6540 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6085 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 149/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5851 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5123 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 150/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6724 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4501 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 151/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5432 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6015 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 152/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5871 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5878 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 153/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6859 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5535 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 154/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6681 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6285 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 155/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5971 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6195 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 156/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4739 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5788 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 157/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5352 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5856 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 158/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6832 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5418 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 159/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7733 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4676 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 160/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6713 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6188 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 161/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6912 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6655 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 162/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5981 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5305 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 163/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6157 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5507 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 164/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6114 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5390 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 165/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8682 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.5994 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 166/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4934 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5836 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 167/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6324 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4320 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 168/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5212 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5535 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 169/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6288 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6305 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 170/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6678 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5456 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 171/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5027 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4979 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 172/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6309 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4144 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 173/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5794 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5851 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 174/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3866 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4038 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 175/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4764 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4912 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 176/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6933 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5149 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 177/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5701 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5557 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 178/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7868 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5640 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 179/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5822 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6905 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 180/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5111 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.7230 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 181/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6553 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4688 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 182/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4521 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6446 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 183/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4569 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5927 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 184/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5148 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6888 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 185/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6731 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5687 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 186/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6191 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5198 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 187/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7701 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5725 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 188/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4454 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5250 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 189/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5302 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3641 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 190/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6231 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3899 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 191/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6380 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5298 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 192/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5554 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4807 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 193/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5351 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4883 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 194/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4586 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3499 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 195/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7288 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.4283 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 196/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5800 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4576 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 197/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5233 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5768 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 198/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6556 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5025 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 199/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7106 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4747 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 200/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6378 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5375 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 201/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5627 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5260 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 202/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5774 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4855 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 203/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6698 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4734 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 204/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8030 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.5919 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 205/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7759 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5689 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 206/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4577 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4837 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 207/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6767 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.4800 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 208/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6832 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4820 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 209/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5127 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4445 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 210/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6922 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5855 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 211/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5158 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4173 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 212/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5530 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.7362 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 213/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5486 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5802 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 214/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7001 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6734 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 215/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4480 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3391 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 216/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4693 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6809 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 217/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7927 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4797 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 218/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5436 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5044 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 219/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6452 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5597 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 220/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6612 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6041 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 221/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6128 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5687 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 222/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5002 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5625 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 223/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5938 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6599 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 224/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5924 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4616 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 225/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6146 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.5102 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 226/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7178 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5971 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 227/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5452 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4896 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 228/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7178 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4779 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 229/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4820 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4610 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 230/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5181 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5585 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 231/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6689 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6272 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 232/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4329 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6386 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 233/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5889 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5318 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 234/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4865 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5295 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 235/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5807 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4621 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 236/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5220 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5048 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 237/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4756 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5954 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 238/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4293 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6182 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 239/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4559 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4848 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 240/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4701 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4127 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 241/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4563 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3806 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 242/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6899 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5681 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 243/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5877 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5351 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 244/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4674 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5858 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 245/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5162 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5671 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 246/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6230 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.7323 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 247/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6219 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4820 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 248/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7792 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4933 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 249/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5013 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6786 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 250/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6456 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5727 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 251/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4221 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5276 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 252/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4460 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.5647 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 253/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8253 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.5721 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 254/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5068 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4990 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 255/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5036 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5286 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 256/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5130 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6569 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 257/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6093 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4737 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 258/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6337 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5840 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 259/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6440 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5490 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 260/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5614 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6155 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 261/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7304 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4345 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 262/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4205 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4203 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 263/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6474 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5189 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 264/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5773 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5193 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 265/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4912 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5104 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 266/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5090 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6377 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 267/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4432 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5144 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 268/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6143 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5614 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 269/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5608 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5227 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 270/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5387 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5262 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 271/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6414 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6146 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 272/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5709 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5818 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 273/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7060 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4247 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 274/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6427 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5748 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 275/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5221 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4489 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 276/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6674 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.5929 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 277/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4334 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5600 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 278/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6754 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6027 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 279/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5723 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5733 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 280/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4233 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5468 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 281/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5608 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5598 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 282/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4815 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6280 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 283/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5898 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6875 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 284/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5838 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5572 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 285/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5805 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6171 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 286/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6175 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4590 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 287/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4753 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6073 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 288/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5135 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5435 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 289/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5063 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4805 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 290/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5044 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5778 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 291/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5305 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5878 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 292/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5512 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3962 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 293/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4350 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4902 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 294/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5773 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4270 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 295/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6127 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4937 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 296/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5389 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4714 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 297/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5475 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4203 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 298/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4092 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4925 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 299/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5307 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5254 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 300/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4710 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5620 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 301/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6576 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6169 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 302/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7763 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.3795 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 303/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6147 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5157 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 304/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5775 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4574 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 305/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7012 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5751 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 306/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6711 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5340 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 307/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5434 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4706 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 308/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4670 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5557 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 309/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5205 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5494 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 310/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5260 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6466 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 311/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6701 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4799 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 312/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6755 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5329 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 313/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6385 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6665 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 314/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5234 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6343 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 315/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6047 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5355 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 316/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6924 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5343 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 317/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6155 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5188 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 318/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5508 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4793 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 319/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4876 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4901 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 320/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5108 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4100 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 321/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5000 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5534 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 322/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6521 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.5465 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 323/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5639 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6287 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 324/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4177 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3795 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 325/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4447 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5813 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 326/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5246 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6589 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 327/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5991 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5398 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 328/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6107 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4948 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 329/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5993 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5820 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 330/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5169 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5583 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 331/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6345 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5705 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 332/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6168 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4953 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 333/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6659 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4605 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 334/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4674 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4528 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 335/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5975 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4594 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 336/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4399 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6486 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 337/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5024 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4228 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 338/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5511 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4204 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 339/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6154 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4968 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 340/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5209 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5099 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 341/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4743 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4933 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 342/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4400 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6379 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 343/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6021 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3697 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 344/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4999 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4872 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 345/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6009 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6778 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 346/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6556 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4418 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 347/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3897 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4205 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 348/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6078 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3956 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 349/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6055 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4596 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 350/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4522 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4595 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 351/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6393 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5173 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 352/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4166 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4823 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 353/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5382 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5411 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 354/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6375 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5179 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 355/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4750 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4586 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 356/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5999 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4919 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 357/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4878 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5693 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 358/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5401 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5863 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 359/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6045 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5886 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 360/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5346 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5843 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 361/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4801 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5235 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 362/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5225 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6303 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 363/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4093 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5717 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 364/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5593 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4580 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 365/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5015 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4428 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 366/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5545 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5350 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 367/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5999 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3923 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 368/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5795 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4288 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 369/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4973 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5228 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 370/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3581 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4245 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 371/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7713 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.4496 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 372/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5141 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6053 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 373/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4558 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5273 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 374/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7247 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.7260 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 375/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4939 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5021 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 376/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7156 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.4913 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 377/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4669 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4885 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 378/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5876 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4624 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 379/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5825 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5869 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 380/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4780 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5611 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 381/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4236 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4392 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 382/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8108 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5969 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 383/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4600 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6277 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 384/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4732 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4541 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 385/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4553 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4215 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 386/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6470 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4303 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 387/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5277 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4525 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 388/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4444 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4699 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 389/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4141 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3719 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 390/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6977 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5322 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 391/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6397 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4893 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 392/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5111 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4788 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 393/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6284 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4237 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 394/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5915 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4278 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 395/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6438 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4512 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 396/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6667 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4147 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 397/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5854 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5189 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 398/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6999 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5128 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 399/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6973 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.4999 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 400/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4294 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4280 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 401/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3996 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3617 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 402/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6158 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4175 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 403/1500\n",
      "32/32 [==============================] - 1s - loss: 0.9482 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.5696 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 404/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4285 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4737 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 405/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4849 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5778 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 406/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4302 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6400 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 407/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4144 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4850 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 408/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4959 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3910 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 409/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6479 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4758 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 410/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5411 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4193 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 411/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4085 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6730 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 412/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6495 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5988 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 413/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4640 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5907 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 414/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4999 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5146 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 415/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4205 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5067 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 416/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6096 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5358 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 417/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6309 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5066 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 418/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5473 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4546 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 419/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5265 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5611 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 420/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6440 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4788 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 421/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6715 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5934 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 422/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4964 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5556 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 423/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4484 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5934 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 424/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5169 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6109 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 425/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4468 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6724 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 426/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5578 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6164 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 427/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4870 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3880 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 428/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3837 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.7394 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 429/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5095 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5640 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 430/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5944 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4626 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 431/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6084 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5227 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 432/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5328 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4364 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 433/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7278 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6028 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 434/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4444 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5413 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 435/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4393 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6299 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 436/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4810 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5788 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 437/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5583 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5070 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 438/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5128 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4331 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 439/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5636 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3904 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 440/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5792 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4991 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 441/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4315 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5884 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 442/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4310 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4985 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 443/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5204 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5891 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 444/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5375 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5489 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 445/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5757 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5596 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 446/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4703 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4519 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 447/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3603 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.6094 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 448/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6530 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4246 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 449/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5857 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6592 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 450/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5301 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4834 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 451/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5030 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6344 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 452/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5556 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4965 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 453/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4359 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4730 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 454/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6521 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5066 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 455/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5079 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4004 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 456/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5502 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4534 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 457/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4073 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5692 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 458/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4958 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4348 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 459/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7565 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6918 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 460/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5814 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5867 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 461/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6349 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4914 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 462/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5729 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6569 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 463/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4503 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4934 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 464/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6098 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5466 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 465/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5549 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5589 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 466/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5115 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5211 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 467/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3966 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4521 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 468/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4698 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5295 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 469/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6395 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4418 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 470/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4932 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4925 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 471/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5072 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5674 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 472/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5374 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6810 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 473/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5780 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6601 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 474/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8666 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.4820 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 475/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6515 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5197 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 476/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6857 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6929 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 477/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4824 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5039 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 478/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5884 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4997 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 479/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6070 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5462 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 480/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5187 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5184 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 481/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6375 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4873 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 482/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4222 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5261 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 483/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4505 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5969 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 484/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5028 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5249 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 485/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6650 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.3413 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 486/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4787 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5754 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 487/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5243 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3795 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 488/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3844 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5251 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 489/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4912 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4498 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 490/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5109 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4529 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 491/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3569 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4842 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 492/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5903 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4532 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 493/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6001 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6212 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 494/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4577 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3924 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 495/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4855 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4808 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 496/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7709 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.4760 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 497/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5060 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4435 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 498/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3928 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5619 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 499/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5848 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5433 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 500/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4389 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4091 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 501/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4976 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5203 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 502/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8521 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.5505 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 503/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5587 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5190 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 504/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7347 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6945 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 505/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4935 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5273 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 506/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4530 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5388 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 507/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5954 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3490 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 508/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4392 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4433 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 509/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6710 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5968 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 510/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4669 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5990 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 511/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6800 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5556 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 512/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5206 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5285 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 513/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4979 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4129 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 514/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6413 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4701 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 515/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4935 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5412 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 516/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7009 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6543 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 517/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4937 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5286 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 518/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5409 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5590 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 519/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5688 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3822 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 520/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5386 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4641 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 521/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6550 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5029 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 522/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5496 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5133 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 523/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4783 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5287 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 524/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4634 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3411 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 525/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4035 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6005 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 526/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5561 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4994 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 527/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5178 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4450 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 528/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6124 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5440 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 529/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5404 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4785 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 530/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5809 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6470 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 531/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7387 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.5860 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 532/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6418 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5467 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 533/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5924 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4878 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 534/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5952 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6107 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 535/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4276 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4566 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 536/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4570 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4183 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 537/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5587 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4559 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 538/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4782 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4465 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 539/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5779 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5673 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 540/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4571 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5105 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 541/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3871 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4978 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 542/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6916 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4771 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 543/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5102 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4679 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 544/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4318 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3273 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 545/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6142 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5895 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 546/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7097 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.7516 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 547/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6748 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4457 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 548/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2924 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.6622 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 549/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5934 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4181 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 550/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5269 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5259 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 551/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5663 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5327 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 552/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3783 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4078 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 553/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4768 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5934 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 554/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5387 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5189 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 555/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5757 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4034 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 556/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7062 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4436 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 557/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6708 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4646 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 558/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6318 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5613 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 559/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5102 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5535 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 560/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5943 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5534 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 561/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6090 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5972 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 562/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4244 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5404 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 563/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5241 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5652 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 564/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5120 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5764 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 565/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5117 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5031 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 566/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8140 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.4936 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 567/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5509 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4432 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 568/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4746 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4706 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 569/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4702 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6564 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 570/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5115 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4863 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 571/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5007 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5646 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 572/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6388 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4878 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 573/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6454 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5577 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 574/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6512 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5080 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 575/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4487 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5942 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 576/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5206 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5808 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 577/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4294 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5196 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 578/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5711 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5328 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 579/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4829 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5440 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 580/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6334 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4132 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 581/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5164 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4591 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 582/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5774 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5937 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 583/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4885 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5310 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 584/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6244 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4200 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 585/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5024 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4736 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 586/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5181 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4536 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 587/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5135 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4896 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 588/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5818 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4945 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 589/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5296 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3816 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 590/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4868 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5403 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 591/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5146 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4199 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 592/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5145 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4195 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 593/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5682 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4561 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 594/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5150 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4027 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 595/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5549 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3865 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 596/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5551 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3848 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 597/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6105 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5308 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 598/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4660 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3694 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 599/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6778 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5420 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 600/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6165 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4514 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 601/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5215 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.7455 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 602/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5055 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5552 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 603/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5764 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5911 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 604/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4707 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4442 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 605/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6099 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5203 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 606/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5854 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5338 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 607/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5348 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4985 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 608/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4755 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4458 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 609/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3564 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4018 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 610/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5897 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4498 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 611/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6891 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6556 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 612/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5423 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4583 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 613/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4935 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4790 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 614/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5109 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3088 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 615/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7536 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.4497 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 616/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4147 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4076 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 617/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5022 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4939 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 618/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5319 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6351 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 619/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4314 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5311 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 620/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5507 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4911 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 621/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6295 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.7148 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 622/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5778 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4849 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 623/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5311 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5596 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 624/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4645 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5594 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 625/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4114 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5161 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 626/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5326 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6182 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 627/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6302 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4348 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 628/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5914 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4657 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 629/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5075 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6308 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 630/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5797 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4188 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 631/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6517 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4678 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 632/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5512 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5574 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 633/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6695 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6179 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 634/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6462 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4486 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 635/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4695 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5675 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 636/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4617 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4477 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 637/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5206 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4868 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 638/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6293 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5611 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 639/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5724 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5597 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 640/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4120 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4110 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 641/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3948 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6185 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 642/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5630 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4415 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 643/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5899 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4274 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 644/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5264 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6426 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 645/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4627 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5832 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 646/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5047 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5012 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 647/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4393 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5883 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 648/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5810 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6055 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 649/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5306 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4226 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 650/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6170 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5291 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 651/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5768 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.7005 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 652/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7919 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.5309 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 653/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5022 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4911 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 654/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3989 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4881 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 655/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4765 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4858 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 656/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4933 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.7167 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 657/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6833 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5151 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 658/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7098 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.4542 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 659/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6786 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5644 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 660/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6028 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5242 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 661/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6299 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5554 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 662/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5928 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4828 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 663/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4653 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5479 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 664/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7560 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.5790 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 665/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5663 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5920 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 666/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4712 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5660 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 667/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5301 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4929 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 668/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6001 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3922 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 669/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4535 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4946 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 670/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4544 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5323 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 671/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5148 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4148 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 672/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5855 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6678 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 673/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5151 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4950 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 674/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4828 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5234 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 675/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4652 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5468 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 676/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5817 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.7075 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 677/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5964 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5636 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 678/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5153 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4482 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 679/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4709 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3400 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 680/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5827 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6792 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 681/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4810 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5967 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 682/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5085 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5399 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 683/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5484 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4769 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 684/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5172 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5209 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 685/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6899 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.4907 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 686/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5188 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4867 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 687/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5143 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4819 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 688/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4951 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4148 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 689/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4260 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4352 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 690/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5040 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5672 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 691/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4864 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.7205 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 692/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5275 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6601 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 693/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6697 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4264 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 694/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5083 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3812 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 695/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6507 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4854 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 696/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6354 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5189 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 697/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4752 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6328 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 698/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6476 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3475 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 699/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4443 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5540 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 700/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4703 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4760 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 701/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6210 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5285 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 702/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6252 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5289 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 703/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4549 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5590 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 704/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6252 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4998 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 705/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7499 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4590 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 706/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5883 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4233 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 707/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5707 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5592 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 708/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5089 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4909 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 709/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6514 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.3849 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 710/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4919 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.8064 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 711/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6728 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5541 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 712/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7083 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.5240 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 713/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5529 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5392 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 714/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4417 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4591 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 715/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5647 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5185 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 716/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5055 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6020 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 717/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5594 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6334 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 718/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3820 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.6351 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 719/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6221 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6384 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 720/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5455 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5337 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 721/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5475 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4164 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 722/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5653 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4768 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 723/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6741 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4504 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 724/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7454 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4565 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 725/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4575 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5942 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 726/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5680 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5542 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 727/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6426 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5347 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 728/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5744 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5599 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 729/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4382 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5850 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 730/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5814 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3812 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 731/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6028 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4198 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 732/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6368 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5468 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 733/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5255 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5139 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 734/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4480 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3488 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 735/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5778 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5368 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 736/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5668 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5249 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 737/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5706 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4699 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 738/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5427 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5458 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 739/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6096 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4548 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 740/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4500 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3794 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 741/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5922 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4525 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 742/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4049 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3196 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 743/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5856 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4546 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 744/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5253 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6258 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 745/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6089 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6994 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 746/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5971 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4948 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 747/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5722 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4955 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 748/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4542 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4200 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 749/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5777 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5954 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 750/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5768 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6287 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 751/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4379 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4533 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 752/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5153 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4941 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 753/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4337 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4583 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 754/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4603 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6259 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 755/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6779 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5212 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 756/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5442 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6724 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 757/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4137 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5500 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 758/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4464 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6413 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 759/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4956 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6055 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 760/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6073 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5562 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 761/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5586 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5114 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 762/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5290 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5916 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 763/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5889 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4759 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 764/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7044 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.4703 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 765/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6752 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4512 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 766/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5425 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5267 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 767/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4866 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5236 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 768/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4470 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4114 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 769/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5227 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6120 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 770/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4763 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4866 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 771/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7284 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.7068 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 772/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5348 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5922 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 773/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5228 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5182 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 774/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5042 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5288 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 775/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5641 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4221 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 776/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4229 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5160 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 777/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5367 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4215 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 778/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6739 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5971 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 779/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4902 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5257 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 780/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4576 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5263 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 781/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4837 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5612 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 782/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4651 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4887 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 783/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6537 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3824 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 784/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5949 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4453 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 785/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5400 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6450 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 786/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6544 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5203 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 787/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4453 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6712 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 788/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3198 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.4120 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 789/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5790 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4079 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 790/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4263 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4712 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 791/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6324 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6360 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 792/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5364 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4803 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 793/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6259 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5657 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 794/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5510 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4771 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 795/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5885 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6004 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 796/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5183 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5901 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 797/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4329 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4223 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 798/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5335 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5898 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 799/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3864 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4127 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 800/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4917 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6543 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 801/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4498 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5895 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 802/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6253 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3716 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 803/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4225 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4641 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 804/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6733 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.3472 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 805/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4347 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6868 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 806/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4224 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4373 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 807/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6163 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5918 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 808/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5765 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5986 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 809/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7577 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.5076 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 810/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4323 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6012 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 811/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3707 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4151 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 812/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5035 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5520 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 813/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5780 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5234 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 814/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4441 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6060 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 815/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5867 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4114 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 816/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5469 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5236 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 817/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7056 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.4844 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 818/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4801 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4400 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 819/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4720 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5288 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 820/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5749 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3253 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 821/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4802 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4849 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 822/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5712 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4799 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 823/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7145 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5625 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 824/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6509 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6164 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 825/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6032 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3901 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 826/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6308 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4514 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 827/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6126 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4516 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 828/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3748 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4471 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 829/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4939 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4470 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 830/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4865 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3363 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 831/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7502 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.5612 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 832/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4184 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5207 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 833/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5159 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4871 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 834/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4875 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5211 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 835/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5744 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5576 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 836/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5089 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4421 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 837/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6925 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5738 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 838/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4642 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4892 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 839/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4905 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4441 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 840/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4514 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5282 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 841/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5227 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4505 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 842/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5179 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5570 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 843/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4370 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5197 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 844/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6300 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4880 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 845/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5465 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6794 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 846/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6456 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.3754 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 847/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6179 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4886 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 848/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6302 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5279 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 849/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5260 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5061 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 850/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6700 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5891 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 851/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4209 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6170 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 852/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5203 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5957 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 853/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4282 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5226 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 854/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4560 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6732 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 855/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6032 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5766 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 856/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5590 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6016 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 857/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4755 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5707 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 858/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6316 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5290 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 859/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7162 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4426 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 860/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5244 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4558 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 861/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5346 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6335 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 862/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5053 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5642 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 863/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5748 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5889 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 864/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4840 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5256 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 865/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6895 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4508 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 866/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4661 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4039 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 867/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5933 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5369 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 868/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4848 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6386 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 869/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4058 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5532 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 870/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4838 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4125 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 871/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4858 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5097 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 872/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4698 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4776 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 873/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6580 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4135 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 874/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6177 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3698 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 875/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5796 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5296 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 876/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6054 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.3813 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 877/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5338 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5315 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 878/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5459 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4150 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 879/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6851 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5425 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 880/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5618 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5327 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 881/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3559 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4479 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 882/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4363 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4869 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 883/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4481 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5204 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 884/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6119 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5993 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 885/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4197 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4831 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 886/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3792 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4080 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 887/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6736 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5427 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 888/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6740 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4073 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 889/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6761 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6107 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 890/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5710 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4561 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 891/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4272 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4106 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 892/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4507 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4902 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 893/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4123 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4003 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 894/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6265 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3974 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 895/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4408 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5603 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 896/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4103 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5281 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 897/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4358 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4813 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 898/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5286 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5557 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 899/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4837 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6358 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 900/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4514 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4416 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 901/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5218 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5180 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 902/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6159 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5397 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 903/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4881 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5692 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 904/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4241 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4121 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 905/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4059 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5966 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 906/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6413 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4457 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 907/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3434 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4848 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 908/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3819 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4896 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 909/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6525 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5206 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 910/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6213 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6091 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 911/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4783 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5366 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 912/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5886 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5252 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 913/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6500 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4532 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 914/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6805 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5567 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 915/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5431 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5227 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 916/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4558 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5128 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 917/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5249 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5368 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 918/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5322 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5286 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 919/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5799 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4100 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 920/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4799 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4834 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 921/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5267 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5898 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 922/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5607 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5228 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 923/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5552 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6379 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 924/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5041 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5595 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 925/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5652 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3343 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 926/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4812 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4471 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 927/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5516 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4886 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 928/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5905 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3782 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 929/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4412 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5974 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 930/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4712 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5392 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 931/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5179 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4868 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 932/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4116 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5249 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 933/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4547 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4788 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 934/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5967 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6099 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 935/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6700 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6096 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 936/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4092 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5669 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 937/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5906 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4747 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 938/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5132 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5336 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 939/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5592 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4782 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 940/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5372 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.7418 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 941/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4474 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5614 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 942/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3722 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6054 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 943/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5074 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4772 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 944/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5246 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3606 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 945/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5444 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5170 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 946/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4812 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5818 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 947/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5095 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4470 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 948/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4541 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5693 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 949/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6189 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5708 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 950/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4294 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5815 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 951/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5775 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6765 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 952/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6342 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4824 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 953/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5403 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5808 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 954/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4865 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5625 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 955/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3849 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4470 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 956/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5905 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3678 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 957/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3798 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5647 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 958/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6760 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4449 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 959/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5803 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4001 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 960/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6447 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5581 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 961/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7209 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.4547 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 962/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6115 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5976 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 963/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4254 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4833 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 964/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5351 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6407 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 965/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6143 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.3337 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 966/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6299 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4972 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 967/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3371 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.5234 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 968/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4001 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5599 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 969/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4178 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6116 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 970/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4730 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4621 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 971/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6600 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5204 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 972/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8128 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.4101 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 973/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4834 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6007 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 974/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6648 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5614 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 975/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6434 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6016 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 976/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7552 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.5734 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 977/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5097 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5205 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 978/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6683 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4812 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 979/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5207 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5961 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 980/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5135 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6446 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 981/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4736 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5578 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 982/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5292 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6715 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 983/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6029 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6152 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 984/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5556 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4545 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 985/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7791 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.5239 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 986/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3438 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4819 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 987/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8065 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.5617 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 988/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4938 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5346 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 989/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5816 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4830 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 990/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5046 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5683 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 991/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3600 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4708 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 992/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5743 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4392 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 993/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5373 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4469 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 994/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5294 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5234 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 995/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5297 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4890 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 996/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4546 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5220 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 997/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5732 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5663 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 998/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5196 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4062 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 999/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5328 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4928 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1000/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5144 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4863 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1001/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8069 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.5179 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1002/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3737 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5109 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1003/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4893 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6684 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 1004/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5736 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5265 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1005/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4591 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5045 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1006/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5921 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4897 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1007/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4118 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5305 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1008/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4174 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5235 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1009/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3657 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4851 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1010/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4199 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5702 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1011/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5522 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4073 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1012/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5395 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3705 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1013/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4654 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4076 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1014/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4873 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6422 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1015/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6119 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4883 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1016/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5576 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6003 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1017/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4468 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4097 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1018/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5542 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2884 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1019/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5687 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5277 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1020/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7371 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.4463 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1021/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6627 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6744 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 1022/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5357 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5362 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1023/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5748 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5983 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1024/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5039 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4573 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1025/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4705 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5654 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1026/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4983 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.7175 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 1027/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4652 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5571 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1028/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5980 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5289 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1029/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4432 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5635 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1030/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4902 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5253 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1031/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7169 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.4147 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1032/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4519 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4515 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1033/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5458 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6362 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1034/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5772 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5292 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1035/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4911 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6104 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1036/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5030 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4913 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1037/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6653 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4452 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1038/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6552 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4828 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1039/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6397 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4469 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1040/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5500 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5975 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1041/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4222 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5230 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1042/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6518 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5483 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1043/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4666 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4453 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1044/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5604 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5220 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1045/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5082 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5197 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1046/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4690 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6040 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1047/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3608 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5316 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1048/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6394 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4923 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1049/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5329 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4889 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1050/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5457 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5333 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1051/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5016 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5208 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1052/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4571 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5930 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1053/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5815 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4508 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1054/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5597 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5198 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1055/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4559 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5250 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1056/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6246 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5232 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1057/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4443 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6376 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1058/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6584 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6039 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1059/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4591 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4864 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1060/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5452 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5963 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1061/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4237 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5157 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1062/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6318 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5477 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1063/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6439 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4211 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1064/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6853 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5689 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1065/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4626 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3737 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1066/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4081 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5677 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1067/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6081 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.7152 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 1068/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5397 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5091 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1069/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3707 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5992 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1070/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6961 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4717 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1071/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5047 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4867 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1072/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6474 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4933 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1073/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4685 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4492 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1074/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5311 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5709 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1075/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5064 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5660 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1076/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3807 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5997 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1077/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5162 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5918 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1078/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5989 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5976 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1079/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5791 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5683 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1080/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7153 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.4907 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1081/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5168 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4794 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1082/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5130 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6298 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1083/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4415 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5771 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1084/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5278 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4225 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1085/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6561 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4484 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1086/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3810 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4891 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1087/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4813 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6726 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 1088/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4463 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.7230 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 1089/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6061 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3875 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1090/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5783 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5862 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1091/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5251 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4015 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1092/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3911 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6034 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1093/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4533 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4878 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1094/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5617 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4799 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1095/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4058 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5231 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1096/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5196 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4429 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1097/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3412 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.6862 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 1098/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6317 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3637 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1099/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3669 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5250 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1100/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5463 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6035 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1101/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5713 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3997 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1102/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3850 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5143 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1103/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4573 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5672 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1104/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5696 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6489 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1105/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4916 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4836 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1106/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6330 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4882 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1107/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5185 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5385 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1108/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4832 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5276 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1109/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5332 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6045 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1110/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4946 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5653 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1111/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5767 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5238 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1112/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4342 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4855 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1113/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3607 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3193 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1114/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3726 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4050 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1115/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4980 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5462 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1116/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4490 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5640 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1117/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4651 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4082 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1118/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4780 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.7398 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 1119/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5267 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3583 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1120/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3583 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6918 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 1121/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5355 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4007 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1122/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6171 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5272 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1123/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6209 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5204 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1124/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6487 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5504 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1125/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5146 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5198 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1126/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4539 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6125 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1127/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6039 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5249 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1128/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3500 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.6916 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 1129/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5293 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5232 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1130/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6568 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5993 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1131/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6948 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4855 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1132/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5475 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6480 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1133/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4029 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6459 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1134/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4802 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6271 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1135/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6549 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4452 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1136/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4893 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4032 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1137/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5425 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4137 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1138/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3568 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6801 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 1139/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3621 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5707 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1140/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3181 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4855 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1141/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5224 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6037 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1142/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4619 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4061 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1143/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4128 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.7631 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 1144/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5576 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4503 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1145/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3554 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.6498 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1146/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5783 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4620 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1147/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5282 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4410 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1148/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5221 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4336 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1149/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5071 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6103 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1150/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5973 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4871 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1151/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4956 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3990 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1152/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3785 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5752 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1153/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5203 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4685 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1154/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5898 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6960 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 1155/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6391 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.3980 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1156/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5968 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4931 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1157/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4737 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5624 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1158/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6347 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4839 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1159/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3934 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5329 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1160/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5765 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4857 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1161/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4582 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6130 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1162/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5142 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4491 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1163/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4821 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5235 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1164/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6685 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4037 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1165/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5444 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5641 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1166/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5148 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5540 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1167/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4539 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6881 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 1168/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4272 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5216 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1169/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4464 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5581 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1170/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4552 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5215 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1171/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6439 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4791 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1172/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7270 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.7015 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 1173/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4604 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4047 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1174/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5045 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3295 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1175/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4610 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4474 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1176/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4290 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5273 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1177/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4652 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4813 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1178/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6430 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4852 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1179/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5486 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4745 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1180/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5224 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5758 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1181/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4551 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5225 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1182/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5677 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4815 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1183/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5480 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5268 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1184/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6190 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6032 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1185/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5773 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5678 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1186/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3468 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4052 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1187/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5250 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5674 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1188/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4312 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5796 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1189/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6155 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5206 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1190/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5629 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5277 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1191/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5403 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4045 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1192/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4441 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5275 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1193/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4867 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6059 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1194/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5257 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4834 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1195/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6087 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.2818 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1196/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5512 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6079 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1197/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6426 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4433 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1198/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7466 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.5612 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1199/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5794 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5233 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1200/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6933 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.3282 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1201/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6372 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3348 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1202/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5078 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5230 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1203/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5147 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.7124 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 1204/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4747 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4460 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1205/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4654 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4444 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1206/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5367 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6431 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1207/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5688 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4991 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1208/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5372 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3629 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1209/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4201 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4068 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1210/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3899 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4402 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1211/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5470 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3638 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1212/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4416 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6444 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1213/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5613 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4475 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1214/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6298 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4371 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1215/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6053 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5996 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1216/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7103 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4807 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1217/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3808 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4487 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1218/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4657 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3786 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1219/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7024 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4044 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1220/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5517 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4455 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1221/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5190 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6401 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1222/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5291 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4502 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1223/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5252 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5572 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1224/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6204 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4108 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1225/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5192 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5920 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1226/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4348 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5577 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1227/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4916 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5751 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1228/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4892 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6340 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1229/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4396 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5581 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1230/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5629 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5607 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1231/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4867 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4826 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1232/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6224 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4106 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1233/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5881 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4839 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1234/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6543 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5249 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1235/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7753 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6359 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1236/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5620 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5241 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1237/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5794 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4136 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1238/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5625 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5959 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1239/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6261 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4509 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1240/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4605 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.7858 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 1241/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4363 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6581 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1242/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3687 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4782 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1243/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5713 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4525 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1244/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4234 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5265 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1245/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5776 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5273 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1246/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4611 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3331 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1247/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6854 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6557 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1248/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3029 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.5625 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1249/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5123 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6084 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1250/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4995 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4409 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1251/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4970 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5275 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1252/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4303 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4813 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1253/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6266 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5243 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1254/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5208 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5229 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1255/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4419 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4414 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1256/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5504 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4672 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1257/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4559 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4499 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1258/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6384 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4048 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1259/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5387 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6410 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1260/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5403 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4541 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1261/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4279 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4813 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1262/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6318 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4873 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1263/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3990 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6018 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1264/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5691 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3250 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1265/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4394 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6387 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1266/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5831 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5211 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1267/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4307 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4824 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1268/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2975 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.5644 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1269/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4923 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6106 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1270/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5426 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6023 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1271/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3489 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6454 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1272/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5729 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5293 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1273/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3278 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.5624 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1274/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4504 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6012 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1275/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4027 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5188 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1276/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5705 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5186 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1277/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5504 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4936 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1278/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6113 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4803 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1279/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6881 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.5641 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1280/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4664 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6368 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1281/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6061 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6489 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1282/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5195 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5635 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1283/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3753 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5745 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1284/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5924 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5213 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1285/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5685 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5236 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1286/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5510 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6508 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1287/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2719 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.5370 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1288/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6171 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4025 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1289/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3541 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4778 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1290/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5012 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5287 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1291/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5520 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6059 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1292/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6473 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5632 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1293/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5388 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5234 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1294/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5242 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5263 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1295/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5389 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4857 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1296/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5891 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4855 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1297/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4631 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5694 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1298/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6390 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5238 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1299/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3151 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4851 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1300/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5472 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3139 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1301/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4954 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4033 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1302/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4096 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4458 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1303/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4813 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5441 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1304/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6297 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6438 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1305/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6997 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4437 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1306/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4005 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4833 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1307/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4657 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5670 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1308/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4555 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6433 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1309/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5020 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6133 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1310/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4960 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6040 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1311/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3801 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3559 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1312/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5520 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4845 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1313/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5511 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5644 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1314/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5127 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3564 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1315/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5322 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6096 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1316/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6048 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3605 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1317/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6587 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4026 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1318/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4202 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4185 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1319/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5557 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3986 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1320/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4057 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5669 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1321/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5053 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4489 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1322/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5213 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6095 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1323/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5557 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4875 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1324/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4975 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5372 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1325/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6261 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5242 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1326/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5542 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4001 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1327/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6482 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6429 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1328/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4779 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4780 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1329/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5138 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4854 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1330/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4675 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5597 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1331/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5753 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4450 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1332/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4712 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4846 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1333/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6782 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4450 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1334/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4888 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.7815 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 1335/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6071 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6018 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1336/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6365 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.7340 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 1337/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4749 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4414 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1338/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4500 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5485 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1339/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4464 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5271 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1340/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5149 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4862 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1341/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7337 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.4844 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1342/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5231 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5681 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1343/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4846 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4499 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1344/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4362 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6071 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1345/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6515 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.3704 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1346/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4488 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4042 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1347/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6387 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5270 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1348/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6696 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4883 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1349/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4750 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4104 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1350/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5471 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4051 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1351/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5710 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5985 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1352/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4110 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6438 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1353/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5667 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4036 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1354/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4634 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4869 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1355/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4167 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5442 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1356/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5069 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4910 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1357/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5535 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4713 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1358/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6436 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4100 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1359/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3906 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4455 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1360/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5321 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5278 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1361/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6139 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4075 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1362/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4512 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4041 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1363/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4145 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5250 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1364/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6502 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.7175 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 1365/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4989 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5188 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1366/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4719 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5704 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1367/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5110 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4478 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1368/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5488 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5250 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1369/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5334 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5675 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1370/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6068 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5679 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1371/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4862 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4435 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1372/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6184 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5243 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1373/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4777 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4951 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1374/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8214 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6093 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1375/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4973 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3288 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1376/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4885 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.7241 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 1377/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5046 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3704 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1378/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5545 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5640 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1379/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6395 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5243 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1380/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4955 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5168 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1381/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6244 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5976 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1382/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5843 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4118 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1383/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2925 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.4788 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1384/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5247 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6412 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1385/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5427 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4900 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1386/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5102 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4048 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1387/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4078 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4453 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1388/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5373 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5675 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1389/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3264 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.5694 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1390/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6259 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5258 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1391/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5320 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5249 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1392/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4762 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5058 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1393/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5514 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6371 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1394/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5143 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4040 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1395/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4378 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4564 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1396/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4406 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6075 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1397/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4943 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6580 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1398/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4321 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.7247 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 1399/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4852 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6036 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1400/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4861 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3602 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1401/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5431 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4470 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1402/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6570 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5188 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1403/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3735 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6058 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1404/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5227 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6051 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1405/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5158 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3599 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1406/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3754 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4736 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1407/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5569 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4919 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1408/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6828 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.2851 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1409/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6241 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3666 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1410/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4180 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5194 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1411/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4297 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4386 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1412/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6095 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4474 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1413/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4826 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4096 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1414/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5645 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4068 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1415/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5886 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5199 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1416/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5265 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5656 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1417/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5993 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6744 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 1418/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5536 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5678 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1419/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5559 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5993 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1420/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7017 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.5248 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1421/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5411 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5620 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1422/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5492 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5261 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1423/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4033 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5969 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1424/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5618 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5264 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1425/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5505 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4424 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1426/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5617 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6319 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1427/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5284 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2911 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1428/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5448 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6429 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1429/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7214 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4425 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1430/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5401 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5263 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1431/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5912 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4962 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1432/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4296 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4090 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1433/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5257 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4063 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1434/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4450 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5770 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1435/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4947 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5218 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1436/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4924 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4857 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1437/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4838 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4477 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1438/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5352 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5650 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1439/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5977 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4451 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1440/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6553 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4462 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1441/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5120 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4881 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1442/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5888 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4869 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1443/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5125 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4509 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1444/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5906 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5568 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1445/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5747 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6005 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1446/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5633 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5934 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1447/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5803 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4858 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1448/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5475 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4077 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1449/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5819 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5508 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1450/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5482 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5202 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1451/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6567 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5265 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1452/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4569 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6386 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1453/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5095 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5202 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1454/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4443 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5214 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1455/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5135 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4052 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1456/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6637 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4506 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1457/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6048 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5215 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1458/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5231 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2999 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1459/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6180 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5247 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1460/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4583 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4137 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1461/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5100 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4136 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1462/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6947 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4886 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1463/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4895 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6723 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 1464/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6050 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6025 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1465/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6592 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5002 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1466/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5001 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3326 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1467/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6896 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6344 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1468/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4280 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4603 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1469/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4756 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5739 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1470/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5449 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4069 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1471/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6233 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6021 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1472/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5891 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5940 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1473/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6083 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6544 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1474/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4935 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4193 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1475/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5370 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4870 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1476/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4426 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4652 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1477/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6222 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3052 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1478/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5438 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4109 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1479/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7416 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.5658 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1480/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6280 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5573 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1481/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6753 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4875 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1482/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5916 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3799 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1483/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5013 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6662 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 1484/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5708 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5590 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1485/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6022 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5657 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1486/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5429 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4171 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1487/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4721 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4575 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1488/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4998 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4245 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1489/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5023 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4876 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1490/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5276 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4526 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1491/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5220 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4487 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1492/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5400 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5670 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1493/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5508 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5804 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1494/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5010 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6225 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1495/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5603 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4466 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1496/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5579 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6621 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 1497/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6678 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4548 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1498/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3464 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4141 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1499/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5944 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4849 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1500/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6162 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5608 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(w_gender_train_gen, \n",
    "                              validation_data=w_gender_valid_gen,\n",
    "                              nb_val_samples=BATCH_SIZE,\n",
    "                              samples_per_epoch=BATCH_SIZE, \n",
    "                              nb_epoch=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 7. Evaluating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_history = history.history['acc']\n",
    "valid_history = history.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJIAAAJcCAYAAACi347hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd3ca04c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd3c922a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Plotting training accuracy and testing accuracy acros epochs\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(train_history)\n",
    "plt.plot(valid_history)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig(PIC_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Tail-rolling average transform\n",
    "series_train = Series(train_history)\n",
    "rolling_train = series_train.rolling(window=100)\n",
    "rolling_mean_train = rolling_train.mean()\n",
    "\n",
    "series_valid = Series(valid_history)\n",
    "rolling_valid = series_valid.rolling(window=100)\n",
    "rolling_mean_valid = rolling_valid.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJkAAAJcCAYAAABaP3UWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrk2CGsBRLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd3c9a6d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(rolling_mean_train)\n",
    "plt.plot(rolling_mean_valid)\n",
    "plt.title('Smoothened training and Validation Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Saving histories\n",
    "np.save(TRA_HISTORY_NAME, train_history)\n",
    "np.save(VAL_HISTORY_NAME, valid_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# saving weights\n",
    "model.save_weights(WEIGHTS_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Results on Adience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.88924012192511892,\n",
       " 0.46505460230961976,\n",
       " 0.46505460226080159,\n",
       " 0.46505460226080159,\n",
       " 0.46505454273054642]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(adience_gender_test_gen,BATCH_SIZE*400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raise EX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Finetuning with Adience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "32/32 [==============================] - 2s - loss: 0.8927 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.9173 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 2s - loss: 0.9506 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 1.0325 - val_acc: 0.3125 - val_recall: 0.3125 - val_precision: 0.3125 - val_fmeasure: 0.3125\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 2s - loss: 0.7855 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.9502 - val_acc: 0.3750 - val_recall: 0.3750 - val_precision: 0.3750 - val_fmeasure: 0.3750\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 2s - loss: 0.8829 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.7808 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 2s - loss: 0.9085 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.8261 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 2s - loss: 0.7626 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.8229 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 2s - loss: 0.8194 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.8477 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 2s - loss: 0.8131 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.8423 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 2s - loss: 0.8597 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.8376 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 2s - loss: 0.8674 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.7353 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 2s - loss: 0.8213 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.7421 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 2s - loss: 0.7606 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.7644 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 2s - loss: 0.8558 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.7990 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 2s - loss: 0.6863 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.7588 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 2s - loss: 0.8025 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.7737 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 2s - loss: 0.8103 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6816 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 2s - loss: 0.7835 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.9117 - val_acc: 0.2500 - val_recall: 0.2500 - val_precision: 0.2500 - val_fmeasure: 0.2500\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 2s - loss: 0.6693 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.7270 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 2s - loss: 0.8373 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.8346 - val_acc: 0.3438 - val_recall: 0.3438 - val_precision: 0.3438 - val_fmeasure: 0.3437\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 2s - loss: 0.7846 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.7911 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 2s - loss: 0.9318 - acc: 0.1875 - recall: 0.1875 - precision: 0.1875 - fmeasure: 0.1875 - val_loss: 0.7623 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 2s - loss: 0.6518 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.7606 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 2s - loss: 0.7675 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.7656 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 2s - loss: 0.6727 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6934 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 2s - loss: 0.7579 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.8981 - val_acc: 0.1562 - val_recall: 0.1562 - val_precision: 0.1562 - val_fmeasure: 0.1562\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 2s - loss: 0.6814 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.7445 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 2s - loss: 0.7394 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7901 - val_acc: 0.3438 - val_recall: 0.3438 - val_precision: 0.3438 - val_fmeasure: 0.3437\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 2s - loss: 0.7141 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6517 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 2s - loss: 0.7896 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.7280 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 2s - loss: 0.7736 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.7211 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 2s - loss: 0.6928 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.7071 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 2s - loss: 0.6616 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6890 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 2s - loss: 0.6843 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.7129 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 34/500\n",
      "32/32 [==============================] - 2s - loss: 0.7898 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.7140 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 35/500\n",
      "32/32 [==============================] - 2s - loss: 0.7084 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.7249 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 36/500\n",
      "32/32 [==============================] - 2s - loss: 0.7761 - acc: 0.3438 - recall: 0.3438 - precision: 0.3438 - fmeasure: 0.3437 - val_loss: 0.7426 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 37/500\n",
      "32/32 [==============================] - 2s - loss: 0.7761 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.7586 - val_acc: 0.3750 - val_recall: 0.3750 - val_precision: 0.3750 - val_fmeasure: 0.3750\n",
      "Epoch 38/500\n",
      "32/32 [==============================] - 2s - loss: 0.7026 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.7500 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 39/500\n",
      "32/32 [==============================] - 2s - loss: 0.7615 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6957 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 40/500\n",
      "32/32 [==============================] - 2s - loss: 0.7980 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6937 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 41/500\n",
      "32/32 [==============================] - 2s - loss: 0.7524 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6690 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 42/500\n",
      "32/32 [==============================] - 2s - loss: 0.7592 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7417 - val_acc: 0.3750 - val_recall: 0.3750 - val_precision: 0.3750 - val_fmeasure: 0.3750\n",
      "Epoch 43/500\n",
      "32/32 [==============================] - 2s - loss: 0.7205 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7236 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 44/500\n",
      "32/32 [==============================] - 2s - loss: 0.7340 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6627 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 45/500\n",
      "32/32 [==============================] - 2s - loss: 0.7552 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.7276 - val_acc: 0.3750 - val_recall: 0.3750 - val_precision: 0.3750 - val_fmeasure: 0.3750\n",
      "Epoch 46/500\n",
      "32/32 [==============================] - 2s - loss: 0.7496 - acc: 0.3438 - recall: 0.3438 - precision: 0.3438 - fmeasure: 0.3437 - val_loss: 0.7110 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 47/500\n",
      "32/32 [==============================] - 2s - loss: 0.6911 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.7042 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 48/500\n",
      "32/32 [==============================] - 2s - loss: 0.6769 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.7222 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 49/500\n",
      "32/32 [==============================] - 2s - loss: 0.7669 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.7104 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 50/500\n",
      "32/32 [==============================] - 2s - loss: 0.6842 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.7345 - val_acc: 0.3750 - val_recall: 0.3750 - val_precision: 0.3750 - val_fmeasure: 0.3750\n",
      "Epoch 51/500\n",
      "32/32 [==============================] - 2s - loss: 0.7380 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.7143 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 52/500\n",
      "32/32 [==============================] - 2s - loss: 0.7269 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6914 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 53/500\n",
      "32/32 [==============================] - 2s - loss: 0.6589 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.7475 - val_acc: 0.3438 - val_recall: 0.3438 - val_precision: 0.3438 - val_fmeasure: 0.3437\n",
      "Epoch 54/500\n",
      "32/32 [==============================] - 2s - loss: 0.7376 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.7043 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 55/500\n",
      "32/32 [==============================] - 1s - loss: 0.7383 - acc: 0.2812 - recall: 0.2812 - precision: 0.2812 - fmeasure: 0.2812 - val_loss: 0.6708 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 56/500\n",
      "32/32 [==============================] - 2s - loss: 0.7221 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6835 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 57/500\n",
      "32/32 [==============================] - 2s - loss: 0.7552 - acc: 0.2812 - recall: 0.2812 - precision: 0.2812 - fmeasure: 0.2812 - val_loss: 0.6821 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 58/500\n",
      "32/32 [==============================] - 2s - loss: 0.7255 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7077 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 59/500\n",
      "32/32 [==============================] - 2s - loss: 0.6912 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.7120 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 60/500\n",
      "32/32 [==============================] - 2s - loss: 0.7059 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6908 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 61/500\n",
      "32/32 [==============================] - 2s - loss: 0.6809 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6881 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 62/500\n",
      "32/32 [==============================] - 2s - loss: 0.7087 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.7065 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 63/500\n",
      "32/32 [==============================] - 2s - loss: 0.7112 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6608 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 64/500\n",
      "32/32 [==============================] - 2s - loss: 0.6938 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6886 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 65/500\n",
      "32/32 [==============================] - 2s - loss: 0.6818 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6960 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 66/500\n",
      "32/32 [==============================] - 2s - loss: 0.6970 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.7077 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 67/500\n",
      "32/32 [==============================] - 2s - loss: 0.6993 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6960 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 68/500\n",
      "32/32 [==============================] - 2s - loss: 0.7200 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6919 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 69/500\n",
      "32/32 [==============================] - 2s - loss: 0.7195 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.7006 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 70/500\n",
      "32/32 [==============================] - 2s - loss: 0.7008 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6944 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 71/500\n",
      "32/32 [==============================] - 2s - loss: 0.7110 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7016 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 72/500\n",
      "32/32 [==============================] - 2s - loss: 0.7022 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6944 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 73/500\n",
      "32/32 [==============================] - 2s - loss: 0.6970 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6912 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 74/500\n",
      "32/32 [==============================] - 2s - loss: 0.6954 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6737 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 75/500\n",
      "32/32 [==============================] - 2s - loss: 0.7178 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6894 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 76/500\n",
      "32/32 [==============================] - 2s - loss: 0.7132 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.7198 - val_acc: 0.3750 - val_recall: 0.3750 - val_precision: 0.3750 - val_fmeasure: 0.3750\n",
      "Epoch 77/500\n",
      "32/32 [==============================] - 2s - loss: 0.6886 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.7006 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 78/500\n",
      "32/32 [==============================] - 2s - loss: 0.6950 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6865 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 79/500\n",
      "32/32 [==============================] - 2s - loss: 0.7015 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6833 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 80/500\n",
      "32/32 [==============================] - 2s - loss: 0.6979 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6979 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 81/500\n",
      "32/32 [==============================] - 2s - loss: 0.6975 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6698 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 82/500\n",
      "32/32 [==============================] - 2s - loss: 0.7109 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6894 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 83/500\n",
      "32/32 [==============================] - 2s - loss: 0.6785 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6896 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 84/500\n",
      "32/32 [==============================] - 2s - loss: 0.6993 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6982 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 85/500\n",
      "32/32 [==============================] - 2s - loss: 0.6807 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7079 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 86/500\n",
      "32/32 [==============================] - 2s - loss: 0.7526 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6997 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 87/500\n",
      "32/32 [==============================] - 2s - loss: 0.7041 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.7125 - val_acc: 0.3125 - val_recall: 0.3125 - val_precision: 0.3125 - val_fmeasure: 0.3125\n",
      "Epoch 88/500\n",
      "32/32 [==============================] - 2s - loss: 0.7031 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.7081 - val_acc: 0.3438 - val_recall: 0.3438 - val_precision: 0.3438 - val_fmeasure: 0.3437\n",
      "Epoch 89/500\n",
      "32/32 [==============================] - 2s - loss: 0.7026 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6966 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 90/500\n",
      "32/32 [==============================] - 2s - loss: 0.7027 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6961 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 91/500\n",
      "32/32 [==============================] - 2s - loss: 0.7218 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6712 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 92/500\n",
      "32/32 [==============================] - 2s - loss: 0.6808 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6908 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 93/500\n",
      "32/32 [==============================] - 2s - loss: 0.7283 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.7085 - val_acc: 0.3750 - val_recall: 0.3750 - val_precision: 0.3750 - val_fmeasure: 0.3750\n",
      "Epoch 94/500\n",
      "32/32 [==============================] - 2s - loss: 0.7065 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6778 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 95/500\n",
      "32/32 [==============================] - 2s - loss: 0.6716 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6924 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 96/500\n",
      "32/32 [==============================] - 2s - loss: 0.7252 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6969 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 97/500\n",
      "32/32 [==============================] - 2s - loss: 0.6882 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.7059 - val_acc: 0.3438 - val_recall: 0.3438 - val_precision: 0.3438 - val_fmeasure: 0.3437\n",
      "Epoch 98/500\n",
      "32/32 [==============================] - 2s - loss: 0.6981 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6941 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 99/500\n",
      "32/32 [==============================] - 2s - loss: 0.6988 - acc: 0.2812 - recall: 0.2812 - precision: 0.2812 - fmeasure: 0.2812 - val_loss: 0.7042 - val_acc: 0.3438 - val_recall: 0.3438 - val_precision: 0.3438 - val_fmeasure: 0.3437\n",
      "Epoch 100/500\n",
      "32/32 [==============================] - 2s - loss: 0.6973 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6974 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 101/500\n",
      "32/32 [==============================] - 2s - loss: 0.7015 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6988 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 102/500\n",
      "32/32 [==============================] - 2s - loss: 0.6951 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7056 - val_acc: 0.3438 - val_recall: 0.3438 - val_precision: 0.3438 - val_fmeasure: 0.3437\n",
      "Epoch 103/500\n",
      "32/32 [==============================] - 2s - loss: 0.6966 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6870 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 104/500\n",
      "32/32 [==============================] - 2s - loss: 0.7157 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6798 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 105/500\n",
      "32/32 [==============================] - 2s - loss: 0.6763 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6942 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 106/500\n",
      "32/32 [==============================] - 2s - loss: 0.6752 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6875 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 107/500\n",
      "32/32 [==============================] - 2s - loss: 0.6617 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6927 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 108/500\n",
      "32/32 [==============================] - 2s - loss: 0.6783 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6973 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 109/500\n",
      "32/32 [==============================] - 2s - loss: 0.7092 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6975 - val_acc: 0.3438 - val_recall: 0.3438 - val_precision: 0.3438 - val_fmeasure: 0.3437\n",
      "Epoch 110/500\n",
      "32/32 [==============================] - 1s - loss: 0.7159 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6931 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 111/500\n",
      "32/32 [==============================] - 2s - loss: 0.6829 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6993 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 112/500\n",
      "32/32 [==============================] - 2s - loss: 0.6807 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.7003 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 113/500\n",
      "32/32 [==============================] - 2s - loss: 0.7370 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6882 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 114/500\n",
      "32/32 [==============================] - 2s - loss: 0.6887 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6836 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 115/500\n",
      "32/32 [==============================] - 2s - loss: 0.7213 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7012 - val_acc: 0.3438 - val_recall: 0.3438 - val_precision: 0.3438 - val_fmeasure: 0.3437\n",
      "Epoch 116/500\n",
      "32/32 [==============================] - 2s - loss: 0.7013 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6926 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 117/500\n",
      "32/32 [==============================] - 2s - loss: 0.7023 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6850 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 118/500\n",
      "32/32 [==============================] - 2s - loss: 0.6859 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6994 - val_acc: 0.3750 - val_recall: 0.3750 - val_precision: 0.3750 - val_fmeasure: 0.3750\n",
      "Epoch 119/500\n",
      "32/32 [==============================] - 2s - loss: 0.7146 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6989 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 120/500\n",
      "32/32 [==============================] - 2s - loss: 0.7059 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.7078 - val_acc: 0.3438 - val_recall: 0.3438 - val_precision: 0.3438 - val_fmeasure: 0.3437\n",
      "Epoch 121/500\n",
      "32/32 [==============================] - 2s - loss: 0.7227 - acc: 0.3438 - recall: 0.3438 - precision: 0.3438 - fmeasure: 0.3437 - val_loss: 0.6971 - val_acc: 0.3750 - val_recall: 0.3750 - val_precision: 0.3750 - val_fmeasure: 0.3750\n",
      "Epoch 122/500\n",
      "32/32 [==============================] - 2s - loss: 0.7086 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6886 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 123/500\n",
      "32/32 [==============================] - 2s - loss: 0.6995 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.7023 - val_acc: 0.3750 - val_recall: 0.3750 - val_precision: 0.3750 - val_fmeasure: 0.3750\n",
      "Epoch 124/500\n",
      "32/32 [==============================] - 2s - loss: 0.7040 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6797 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 125/500\n",
      "32/32 [==============================] - 2s - loss: 0.6836 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6962 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 126/500\n",
      "32/32 [==============================] - 2s - loss: 0.6960 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6915 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 127/500\n",
      "32/32 [==============================] - 2s - loss: 0.6932 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.7027 - val_acc: 0.3125 - val_recall: 0.3125 - val_precision: 0.3125 - val_fmeasure: 0.3125\n",
      "Epoch 128/500\n",
      "32/32 [==============================] - 2s - loss: 0.6806 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7008 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 129/500\n",
      "32/32 [==============================] - 2s - loss: 0.7024 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7044 - val_acc: 0.3750 - val_recall: 0.3750 - val_precision: 0.3750 - val_fmeasure: 0.3750\n",
      "Epoch 130/500\n",
      "32/32 [==============================] - 2s - loss: 0.7155 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7048 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 131/500\n",
      "32/32 [==============================] - 2s - loss: 0.6889 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6921 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 132/500\n",
      "32/32 [==============================] - 2s - loss: 0.7005 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.7016 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 133/500\n",
      "32/32 [==============================] - 2s - loss: 0.6853 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6997 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 134/500\n",
      "32/32 [==============================] - 2s - loss: 0.7306 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6909 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 135/500\n",
      "32/32 [==============================] - 2s - loss: 0.7089 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6898 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 136/500\n",
      "32/32 [==============================] - 2s - loss: 0.6520 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6964 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 137/500\n",
      "32/32 [==============================] - 2s - loss: 0.6724 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6988 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 138/500\n",
      "32/32 [==============================] - 2s - loss: 0.6975 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6951 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 139/500\n",
      "32/32 [==============================] - 2s - loss: 0.7028 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6913 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 140/500\n",
      "32/32 [==============================] - 2s - loss: 0.6992 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.7053 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 141/500\n",
      "32/32 [==============================] - 2s - loss: 0.7090 - acc: 0.3438 - recall: 0.3438 - precision: 0.3438 - fmeasure: 0.3437 - val_loss: 0.6873 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 142/500\n",
      "32/32 [==============================] - 2s - loss: 0.7017 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6883 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 143/500\n",
      "32/32 [==============================] - 2s - loss: 0.7129 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6847 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 144/500\n",
      "32/32 [==============================] - 2s - loss: 0.6934 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7001 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 145/500\n",
      "32/32 [==============================] - 2s - loss: 0.6753 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6925 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 146/500\n",
      "32/32 [==============================] - 2s - loss: 0.7495 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6912 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 147/500\n",
      "32/32 [==============================] - 2s - loss: 0.7026 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6948 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 148/500\n",
      "32/32 [==============================] - 2s - loss: 0.7240 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6950 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 149/500\n",
      "32/32 [==============================] - 2s - loss: 0.7568 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6970 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 150/500\n",
      "32/32 [==============================] - 2s - loss: 0.7067 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6968 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 151/500\n",
      "32/32 [==============================] - 2s - loss: 0.6988 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6952 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 152/500\n",
      "32/32 [==============================] - 2s - loss: 0.6981 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6870 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 153/500\n",
      "32/32 [==============================] - 2s - loss: 0.6891 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6880 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 154/500\n",
      "32/32 [==============================] - 2s - loss: 0.6882 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6907 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 155/500\n",
      "32/32 [==============================] - 2s - loss: 0.7002 - acc: 0.3438 - recall: 0.3438 - precision: 0.3438 - fmeasure: 0.3437 - val_loss: 0.6738 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 156/500\n",
      "32/32 [==============================] - 2s - loss: 0.6782 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6911 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 157/500\n",
      "32/32 [==============================] - 2s - loss: 0.7351 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6903 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 158/500\n",
      "32/32 [==============================] - 2s - loss: 0.7007 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.7091 - val_acc: 0.2812 - val_recall: 0.2812 - val_precision: 0.2812 - val_fmeasure: 0.2812\n",
      "Epoch 159/500\n",
      "32/32 [==============================] - 2s - loss: 0.6934 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7017 - val_acc: 0.3438 - val_recall: 0.3438 - val_precision: 0.3438 - val_fmeasure: 0.3437\n",
      "Epoch 160/500\n",
      "32/32 [==============================] - 2s - loss: 0.6794 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6997 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 161/500\n",
      "32/32 [==============================] - 2s - loss: 0.6591 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6784 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 162/500\n",
      "32/32 [==============================] - 2s - loss: 0.6852 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6847 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 163/500\n",
      "32/32 [==============================] - 2s - loss: 0.7037 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6788 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 164/500\n",
      "32/32 [==============================] - 2s - loss: 0.6933 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6859 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 165/500\n",
      "32/32 [==============================] - 1s - loss: 0.7047 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.7003 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 166/500\n",
      "32/32 [==============================] - 2s - loss: 0.6842 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6875 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 167/500\n",
      "32/32 [==============================] - 2s - loss: 0.6964 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6871 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 168/500\n",
      "32/32 [==============================] - 2s - loss: 0.7034 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6944 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 169/500\n",
      "32/32 [==============================] - 2s - loss: 0.7141 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7039 - val_acc: 0.2188 - val_recall: 0.2188 - val_precision: 0.2188 - val_fmeasure: 0.2187\n",
      "Epoch 170/500\n",
      "32/32 [==============================] - 2s - loss: 0.6851 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6978 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 171/500\n",
      "32/32 [==============================] - 2s - loss: 0.6983 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6964 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 172/500\n",
      "32/32 [==============================] - 2s - loss: 0.6983 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6896 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 173/500\n",
      "32/32 [==============================] - 2s - loss: 0.6977 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.7016 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 174/500\n",
      "32/32 [==============================] - 2s - loss: 0.6912 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6944 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 175/500\n",
      "32/32 [==============================] - 2s - loss: 0.6333 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6896 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 176/500\n",
      "32/32 [==============================] - 2s - loss: 0.6922 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6929 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 177/500\n",
      "32/32 [==============================] - 2s - loss: 0.6951 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6846 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 178/500\n",
      "32/32 [==============================] - 2s - loss: 0.6895 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6974 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 179/500\n",
      "32/32 [==============================] - 2s - loss: 0.6815 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6935 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 180/500\n",
      "32/32 [==============================] - 2s - loss: 0.7053 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6911 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 181/500\n",
      "32/32 [==============================] - 2s - loss: 0.6832 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6918 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 182/500\n",
      "32/32 [==============================] - 2s - loss: 0.6747 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6860 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 183/500\n",
      "32/32 [==============================] - 2s - loss: 0.6777 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6864 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 184/500\n",
      "32/32 [==============================] - 2s - loss: 0.6900 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6984 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 185/500\n",
      "32/32 [==============================] - 2s - loss: 0.6930 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6897 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 186/500\n",
      "32/32 [==============================] - 2s - loss: 0.6915 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7014 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 187/500\n",
      "32/32 [==============================] - 2s - loss: 0.6861 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6922 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 188/500\n",
      "32/32 [==============================] - 2s - loss: 0.6577 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6843 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 189/500\n",
      "32/32 [==============================] - 2s - loss: 0.6798 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.7041 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 190/500\n",
      "32/32 [==============================] - 2s - loss: 0.7087 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6938 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 191/500\n",
      "32/32 [==============================] - 2s - loss: 0.6761 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.7133 - val_acc: 0.2500 - val_recall: 0.2500 - val_precision: 0.2500 - val_fmeasure: 0.2500\n",
      "Epoch 192/500\n",
      "32/32 [==============================] - 2s - loss: 0.6937 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6866 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 193/500\n",
      "32/32 [==============================] - 2s - loss: 0.7028 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6851 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 194/500\n",
      "32/32 [==============================] - 2s - loss: 0.6987 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6945 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 195/500\n",
      "32/32 [==============================] - 2s - loss: 0.6977 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6973 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 196/500\n",
      "32/32 [==============================] - 2s - loss: 0.7173 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6870 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 197/500\n",
      "32/32 [==============================] - 2s - loss: 0.7039 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6887 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 198/500\n",
      "32/32 [==============================] - 2s - loss: 0.7062 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6789 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 199/500\n",
      "32/32 [==============================] - 2s - loss: 0.6779 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6963 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 200/500\n",
      "32/32 [==============================] - 2s - loss: 0.6968 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6919 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 201/500\n",
      "32/32 [==============================] - 2s - loss: 0.7017 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6917 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 202/500\n",
      "32/32 [==============================] - 2s - loss: 0.6945 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6880 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 203/500\n",
      "32/32 [==============================] - 2s - loss: 0.6651 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6935 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 204/500\n",
      "32/32 [==============================] - 2s - loss: 0.6969 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6876 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 205/500\n",
      "32/32 [==============================] - 2s - loss: 0.7087 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.7058 - val_acc: 0.3750 - val_recall: 0.3750 - val_precision: 0.3750 - val_fmeasure: 0.3750\n",
      "Epoch 206/500\n",
      "32/32 [==============================] - 2s - loss: 0.6915 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6920 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 207/500\n",
      "32/32 [==============================] - 2s - loss: 0.7087 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6955 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 208/500\n",
      "32/32 [==============================] - 2s - loss: 0.6845 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6920 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 209/500\n",
      "32/32 [==============================] - 2s - loss: 0.7042 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6949 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 210/500\n",
      "32/32 [==============================] - 2s - loss: 0.6920 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6831 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 211/500\n",
      "32/32 [==============================] - 2s - loss: 0.7088 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6918 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 212/500\n",
      "32/32 [==============================] - 2s - loss: 0.7044 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6843 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 213/500\n",
      "32/32 [==============================] - 2s - loss: 0.6890 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.7017 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 214/500\n",
      "32/32 [==============================] - 2s - loss: 0.6900 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6882 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 215/500\n",
      "32/32 [==============================] - 2s - loss: 0.7059 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6920 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 216/500\n",
      "32/32 [==============================] - 2s - loss: 0.6934 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6964 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 217/500\n",
      "32/32 [==============================] - 2s - loss: 0.6879 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6906 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 218/500\n",
      "32/32 [==============================] - 2s - loss: 0.7216 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6879 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 219/500\n",
      "32/32 [==============================] - 2s - loss: 0.7105 - acc: 0.3438 - recall: 0.3438 - precision: 0.3438 - fmeasure: 0.3437 - val_loss: 0.6874 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 220/500\n",
      "32/32 [==============================] - 1s - loss: 0.6909 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6877 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 221/500\n",
      "32/32 [==============================] - 2s - loss: 0.6768 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6802 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 222/500\n",
      "32/32 [==============================] - 2s - loss: 0.6984 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6991 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 223/500\n",
      "32/32 [==============================] - 2s - loss: 0.7056 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6964 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 224/500\n",
      "32/32 [==============================] - 2s - loss: 0.6932 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6907 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 225/500\n",
      "32/32 [==============================] - 2s - loss: 0.7212 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6850 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 226/500\n",
      "32/32 [==============================] - 2s - loss: 0.7064 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6799 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 227/500\n",
      "32/32 [==============================] - 2s - loss: 0.6963 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6866 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 228/500\n",
      "32/32 [==============================] - 2s - loss: 0.6781 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6916 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 229/500\n",
      "32/32 [==============================] - 2s - loss: 0.6960 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6817 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 230/500\n",
      "32/32 [==============================] - 2s - loss: 0.7067 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7003 - val_acc: 0.3750 - val_recall: 0.3750 - val_precision: 0.3750 - val_fmeasure: 0.3750\n",
      "Epoch 231/500\n",
      "32/32 [==============================] - 2s - loss: 0.6940 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6797 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 232/500\n",
      "32/32 [==============================] - 2s - loss: 0.6946 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6846 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 233/500\n",
      "32/32 [==============================] - 2s - loss: 0.7034 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7013 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 234/500\n",
      "32/32 [==============================] - 2s - loss: 0.7075 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6940 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 235/500\n",
      "32/32 [==============================] - 2s - loss: 0.7094 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6971 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 236/500\n",
      "32/32 [==============================] - 2s - loss: 0.6877 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6881 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 237/500\n",
      "32/32 [==============================] - 2s - loss: 0.7092 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6945 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 238/500\n",
      "32/32 [==============================] - 2s - loss: 0.7023 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6947 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 239/500\n",
      "32/32 [==============================] - 2s - loss: 0.7030 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6842 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 240/500\n",
      "32/32 [==============================] - 2s - loss: 0.7027 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6896 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 241/500\n",
      "32/32 [==============================] - 2s - loss: 0.6558 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.7022 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 242/500\n",
      "32/32 [==============================] - 2s - loss: 0.7015 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6905 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 243/500\n",
      "32/32 [==============================] - 2s - loss: 0.7097 - acc: 0.3125 - recall: 0.3125 - precision: 0.3125 - fmeasure: 0.3125 - val_loss: 0.6891 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 244/500\n",
      "32/32 [==============================] - 2s - loss: 0.7105 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6924 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 245/500\n",
      "32/32 [==============================] - 2s - loss: 0.6663 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6888 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 246/500\n",
      "32/32 [==============================] - 2s - loss: 0.6889 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6858 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 247/500\n",
      "32/32 [==============================] - 2s - loss: 0.6858 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6826 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 248/500\n",
      "32/32 [==============================] - 2s - loss: 0.6891 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.7061 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 249/500\n",
      "32/32 [==============================] - 2s - loss: 0.6894 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6851 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 250/500\n",
      "32/32 [==============================] - 2s - loss: 0.7106 - acc: 0.3125 - recall: 0.3125 - precision: 0.3125 - fmeasure: 0.3125 - val_loss: 0.6809 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 251/500\n",
      "32/32 [==============================] - 2s - loss: 0.6749 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6825 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 252/500\n",
      "32/32 [==============================] - 2s - loss: 0.6981 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6789 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 253/500\n",
      "32/32 [==============================] - 2s - loss: 0.7140 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.7047 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 254/500\n",
      "32/32 [==============================] - 2s - loss: 0.6524 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6936 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 255/500\n",
      "32/32 [==============================] - 2s - loss: 0.7125 - acc: 0.3125 - recall: 0.3125 - precision: 0.3125 - fmeasure: 0.3125 - val_loss: 0.6967 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 256/500\n",
      "32/32 [==============================] - 2s - loss: 0.6772 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6807 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 257/500\n",
      "32/32 [==============================] - 2s - loss: 0.6708 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6724 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 258/500\n",
      "32/32 [==============================] - 2s - loss: 0.6860 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6857 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 259/500\n",
      "32/32 [==============================] - 2s - loss: 0.6805 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6835 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 260/500\n",
      "32/32 [==============================] - 2s - loss: 0.7091 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6861 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 261/500\n",
      "32/32 [==============================] - 2s - loss: 0.6868 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6891 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 262/500\n",
      "32/32 [==============================] - 2s - loss: 0.6970 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6864 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 263/500\n",
      "32/32 [==============================] - 2s - loss: 0.6903 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6805 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 264/500\n",
      "32/32 [==============================] - 2s - loss: 0.6903 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6866 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 265/500\n",
      "32/32 [==============================] - 2s - loss: 0.6922 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6962 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 266/500\n",
      "32/32 [==============================] - 2s - loss: 0.7027 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6919 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 267/500\n",
      "32/32 [==============================] - 2s - loss: 0.6851 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6916 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 268/500\n",
      "32/32 [==============================] - 2s - loss: 0.7082 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6885 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 269/500\n",
      "32/32 [==============================] - 2s - loss: 0.6941 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6828 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 270/500\n",
      "32/32 [==============================] - 2s - loss: 0.6897 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6777 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 271/500\n",
      "32/32 [==============================] - 2s - loss: 0.6756 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.7048 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 272/500\n",
      "32/32 [==============================] - 2s - loss: 0.6687 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6972 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 273/500\n",
      "32/32 [==============================] - 2s - loss: 0.7564 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6797 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 274/500\n",
      "32/32 [==============================] - 2s - loss: 0.6813 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6736 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 275/500\n",
      "32/32 [==============================] - 1s - loss: 0.6906 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6907 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 276/500\n",
      "32/32 [==============================] - 2s - loss: 0.6828 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6755 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 277/500\n",
      "32/32 [==============================] - 2s - loss: 0.6530 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.7025 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 278/500\n",
      "32/32 [==============================] - 2s - loss: 0.7055 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6812 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 279/500\n",
      "32/32 [==============================] - 2s - loss: 0.6784 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6864 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 280/500\n",
      "32/32 [==============================] - 2s - loss: 0.7273 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.7046 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 281/500\n",
      "32/32 [==============================] - 2s - loss: 0.6956 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6988 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 282/500\n",
      "32/32 [==============================] - 2s - loss: 0.6871 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.7075 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 283/500\n",
      "32/32 [==============================] - 2s - loss: 0.7037 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6767 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 284/500\n",
      "32/32 [==============================] - 2s - loss: 0.6865 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6892 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 285/500\n",
      "32/32 [==============================] - 2s - loss: 0.6760 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.7139 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 286/500\n",
      "32/32 [==============================] - 2s - loss: 0.7247 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6873 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 287/500\n",
      "32/32 [==============================] - 2s - loss: 0.7266 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6791 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 288/500\n",
      "32/32 [==============================] - 2s - loss: 0.6728 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6774 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 289/500\n",
      "32/32 [==============================] - 2s - loss: 0.6814 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6796 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 290/500\n",
      "32/32 [==============================] - 2s - loss: 0.6955 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6911 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 291/500\n",
      "32/32 [==============================] - 2s - loss: 0.6779 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6930 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 292/500\n",
      "32/32 [==============================] - 2s - loss: 0.7085 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6835 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 293/500\n",
      "32/32 [==============================] - 2s - loss: 0.6843 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.7000 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 294/500\n",
      "32/32 [==============================] - 2s - loss: 0.7063 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6774 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 295/500\n",
      "32/32 [==============================] - 2s - loss: 0.6861 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6698 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 296/500\n",
      "32/32 [==============================] - 2s - loss: 0.7146 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6978 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 297/500\n",
      "32/32 [==============================] - 2s - loss: 0.6482 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.7005 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 298/500\n",
      "32/32 [==============================] - 2s - loss: 0.7091 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.7019 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 299/500\n",
      "32/32 [==============================] - 2s - loss: 0.6876 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6943 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 300/500\n",
      "32/32 [==============================] - 2s - loss: 0.6949 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6839 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 301/500\n",
      "32/32 [==============================] - 2s - loss: 0.6746 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.7014 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 302/500\n",
      "32/32 [==============================] - 2s - loss: 0.6844 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.7045 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 303/500\n",
      "32/32 [==============================] - 2s - loss: 0.7345 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.7087 - val_acc: 0.3750 - val_recall: 0.3750 - val_precision: 0.3750 - val_fmeasure: 0.3750\n",
      "Epoch 304/500\n",
      "32/32 [==============================] - 2s - loss: 0.6722 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6880 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 305/500\n",
      "32/32 [==============================] - 2s - loss: 0.7182 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.7035 - val_acc: 0.3750 - val_recall: 0.3750 - val_precision: 0.3750 - val_fmeasure: 0.3750\n",
      "Epoch 306/500\n",
      "32/32 [==============================] - 2s - loss: 0.7112 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6955 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 307/500\n",
      "32/32 [==============================] - 2s - loss: 0.6947 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6958 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 308/500\n",
      "32/32 [==============================] - 2s - loss: 0.6803 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6989 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 309/500\n",
      "32/32 [==============================] - 2s - loss: 0.7110 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6887 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 310/500\n",
      "32/32 [==============================] - 2s - loss: 0.6981 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6962 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 311/500\n",
      "32/32 [==============================] - 2s - loss: 0.6648 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6945 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 312/500\n",
      "32/32 [==============================] - 2s - loss: 0.6897 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6945 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 313/500\n",
      "32/32 [==============================] - 2s - loss: 0.7147 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6860 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 314/500\n",
      "32/32 [==============================] - 2s - loss: 0.6919 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6824 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 315/500\n",
      "32/32 [==============================] - 2s - loss: 0.6753 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6607 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 316/500\n",
      "32/32 [==============================] - 2s - loss: 0.6664 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6855 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 317/500\n",
      "32/32 [==============================] - 2s - loss: 0.7033 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6800 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 318/500\n",
      "32/32 [==============================] - 2s - loss: 0.7186 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6674 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 319/500\n",
      "32/32 [==============================] - 2s - loss: 0.6702 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6773 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 320/500\n",
      "32/32 [==============================] - 2s - loss: 0.6966 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6820 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 321/500\n",
      "32/32 [==============================] - 2s - loss: 0.7109 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6798 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 322/500\n",
      "32/32 [==============================] - 2s - loss: 0.6815 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6869 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 323/500\n",
      "32/32 [==============================] - 2s - loss: 0.7130 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6911 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 324/500\n",
      "32/32 [==============================] - 2s - loss: 0.6914 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7012 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 325/500\n",
      "32/32 [==============================] - 2s - loss: 0.6722 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6888 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 326/500\n",
      "32/32 [==============================] - 2s - loss: 0.6986 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6756 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 327/500\n",
      "32/32 [==============================] - 2s - loss: 0.7016 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6787 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 328/500\n",
      "32/32 [==============================] - 2s - loss: 0.6726 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.7042 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 329/500\n",
      " 9/32 [=======>......................] - ETA: 5s - loss: 0.6990 - acc: 0.3333 - recall: 0.3333 - precision: 0.3333 - fmeasure: 0.3333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg/keras/engine/training.py:1573: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/32 [======================================] - 4s - loss: 0.7051 - acc: 0.4878 - recall: 0.4878 - precision: 0.4878 - fmeasure: 0.4878 - val_loss: 0.6961 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 330/500\n",
      "32/32 [==============================] - 1s - loss: 0.7035 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6834 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 331/500\n",
      "32/32 [==============================] - 2s - loss: 0.6838 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6745 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 332/500\n",
      "32/32 [==============================] - 2s - loss: 0.6673 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.7053 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 333/500\n",
      "32/32 [==============================] - 2s - loss: 0.6939 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6761 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 334/500\n",
      "32/32 [==============================] - 2s - loss: 0.7108 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6789 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 335/500\n",
      "32/32 [==============================] - 2s - loss: 0.6892 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6926 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 336/500\n",
      "32/32 [==============================] - 2s - loss: 0.6910 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6781 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 337/500\n",
      "32/32 [==============================] - 2s - loss: 0.7023 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6769 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 338/500\n",
      "32/32 [==============================] - 2s - loss: 0.7042 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6833 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 339/500\n",
      "32/32 [==============================] - 2s - loss: 0.6861 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6765 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 340/500\n",
      "32/32 [==============================] - 2s - loss: 0.6684 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6869 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 341/500\n",
      "32/32 [==============================] - 2s - loss: 0.6791 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6787 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 342/500\n",
      "32/32 [==============================] - 2s - loss: 0.7043 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6980 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 343/500\n",
      "32/32 [==============================] - 2s - loss: 0.6809 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6830 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 344/500\n",
      "32/32 [==============================] - 2s - loss: 0.6662 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6956 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 345/500\n",
      "32/32 [==============================] - 2s - loss: 0.7170 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6789 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 346/500\n",
      "32/32 [==============================] - 2s - loss: 0.7348 - acc: 0.3125 - recall: 0.3125 - precision: 0.3125 - fmeasure: 0.3125 - val_loss: 0.6812 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 347/500\n",
      "32/32 [==============================] - 2s - loss: 0.6958 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6987 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 348/500\n",
      "32/32 [==============================] - 2s - loss: 0.6607 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6839 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 349/500\n",
      "32/32 [==============================] - 2s - loss: 0.6902 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6702 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 350/500\n",
      "32/32 [==============================] - 2s - loss: 0.6957 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6931 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 351/500\n",
      "32/32 [==============================] - 2s - loss: 0.7015 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6905 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 352/500\n",
      "32/32 [==============================] - 2s - loss: 0.6754 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6878 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 353/500\n",
      "32/32 [==============================] - 2s - loss: 0.6718 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6922 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 354/500\n",
      "32/32 [==============================] - 2s - loss: 0.7125 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6845 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 355/500\n",
      "32/32 [==============================] - 2s - loss: 0.6992 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6898 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 356/500\n",
      "32/32 [==============================] - 2s - loss: 0.6845 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6834 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 357/500\n",
      "32/32 [==============================] - 2s - loss: 0.6715 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6843 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 358/500\n",
      "32/32 [==============================] - 2s - loss: 0.7018 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6992 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 359/500\n",
      "32/32 [==============================] - 2s - loss: 0.6950 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6906 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 360/500\n",
      "32/32 [==============================] - 2s - loss: 0.7144 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6959 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 361/500\n",
      "32/32 [==============================] - 2s - loss: 0.6861 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.7014 - val_acc: 0.3750 - val_recall: 0.3750 - val_precision: 0.3750 - val_fmeasure: 0.3750\n",
      "Epoch 362/500\n",
      "32/32 [==============================] - 2s - loss: 0.6786 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6789 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 363/500\n",
      "32/32 [==============================] - 2s - loss: 0.7145 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6900 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 364/500\n",
      "32/32 [==============================] - 2s - loss: 0.6673 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6945 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 365/500\n",
      "32/32 [==============================] - 2s - loss: 0.6862 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.7000 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 366/500\n",
      "32/32 [==============================] - 2s - loss: 0.6899 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6779 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 367/500\n",
      "32/32 [==============================] - 2s - loss: 0.6941 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.7030 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 368/500\n",
      "32/32 [==============================] - 2s - loss: 0.6759 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6846 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 369/500\n",
      "32/32 [==============================] - 2s - loss: 0.6976 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6619 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 370/500\n",
      "32/32 [==============================] - 2s - loss: 0.6789 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6919 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 371/500\n",
      "32/32 [==============================] - 2s - loss: 0.7053 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.7011 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 372/500\n",
      "32/32 [==============================] - 2s - loss: 0.6868 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6896 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 373/500\n",
      "32/32 [==============================] - 2s - loss: 0.7151 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6828 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 374/500\n",
      "32/32 [==============================] - 2s - loss: 0.7396 - acc: 0.3438 - recall: 0.3438 - precision: 0.3438 - fmeasure: 0.3437 - val_loss: 0.6764 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 375/500\n",
      "32/32 [==============================] - 2s - loss: 0.7130 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6897 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 376/500\n",
      "32/32 [==============================] - 2s - loss: 0.6828 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6759 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 377/500\n",
      "32/32 [==============================] - 2s - loss: 0.6921 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6957 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 378/500\n",
      "32/32 [==============================] - 2s - loss: 0.6643 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6769 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 379/500\n",
      "32/32 [==============================] - 2s - loss: 0.6896 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6716 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 380/500\n",
      "32/32 [==============================] - 2s - loss: 0.6956 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.7094 - val_acc: 0.3438 - val_recall: 0.3438 - val_precision: 0.3438 - val_fmeasure: 0.3437\n",
      "Epoch 381/500\n",
      "32/32 [==============================] - 2s - loss: 0.6577 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.7012 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 382/500\n",
      "32/32 [==============================] - 2s - loss: 0.7102 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6727 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 383/500\n",
      "32/32 [==============================] - 2s - loss: 0.6701 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6846 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 384/500\n",
      "32/32 [==============================] - 2s - loss: 0.6962 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6782 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 385/500\n",
      "32/32 [==============================] - 1s - loss: 0.7125 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6855 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 386/500\n",
      "32/32 [==============================] - 2s - loss: 0.6901 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.7076 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 387/500\n",
      "32/32 [==============================] - 2s - loss: 0.6974 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.7111 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 388/500\n",
      "32/32 [==============================] - 2s - loss: 0.6668 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6891 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 389/500\n",
      "32/32 [==============================] - 2s - loss: 0.6835 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6848 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 390/500\n",
      "32/32 [==============================] - 2s - loss: 0.6952 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6953 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 391/500\n",
      "32/32 [==============================] - 2s - loss: 0.6923 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6969 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 392/500\n",
      "32/32 [==============================] - 2s - loss: 0.7315 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6954 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 393/500\n",
      "32/32 [==============================] - 2s - loss: 0.6987 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6874 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 394/500\n",
      "32/32 [==============================] - 2s - loss: 0.6919 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6721 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 395/500\n",
      "32/32 [==============================] - 2s - loss: 0.6788 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6699 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 396/500\n",
      "32/32 [==============================] - 2s - loss: 0.6956 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6974 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 397/500\n",
      "32/32 [==============================] - 2s - loss: 0.7002 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6737 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 398/500\n",
      "32/32 [==============================] - 2s - loss: 0.6830 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6944 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 399/500\n",
      "32/32 [==============================] - 2s - loss: 0.6666 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6903 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 400/500\n",
      "32/32 [==============================] - 2s - loss: 0.6816 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6954 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 401/500\n",
      "32/32 [==============================] - 2s - loss: 0.7321 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6776 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 402/500\n",
      "32/32 [==============================] - 2s - loss: 0.7149 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6768 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 403/500\n",
      "32/32 [==============================] - 2s - loss: 0.6995 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6918 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 404/500\n",
      "32/32 [==============================] - 2s - loss: 0.7036 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6775 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 405/500\n",
      "32/32 [==============================] - 2s - loss: 0.6800 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6931 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 406/500\n",
      "32/32 [==============================] - 2s - loss: 0.7103 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6631 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 407/500\n",
      "32/32 [==============================] - 2s - loss: 0.6783 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6914 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 408/500\n",
      "32/32 [==============================] - 2s - loss: 0.6644 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6793 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 409/500\n",
      "32/32 [==============================] - 2s - loss: 0.6934 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6804 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 410/500\n",
      "32/32 [==============================] - 2s - loss: 0.7047 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6954 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 411/500\n",
      "32/32 [==============================] - 2s - loss: 0.7010 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6917 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 412/500\n",
      "32/32 [==============================] - 2s - loss: 0.7015 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6738 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 413/500\n",
      "32/32 [==============================] - 2s - loss: 0.6857 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6880 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 414/500\n",
      "32/32 [==============================] - 2s - loss: 0.7043 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6994 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 415/500\n",
      "32/32 [==============================] - 2s - loss: 0.6953 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6965 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 416/500\n",
      "32/32 [==============================] - 2s - loss: 0.6733 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6974 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 417/500\n",
      "32/32 [==============================] - 2s - loss: 0.6808 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.7088 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 418/500\n",
      "32/32 [==============================] - 2s - loss: 0.6892 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.7033 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 419/500\n",
      "32/32 [==============================] - 2s - loss: 0.6713 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6716 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 420/500\n",
      "32/32 [==============================] - 2s - loss: 0.6984 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6975 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 421/500\n",
      "32/32 [==============================] - 2s - loss: 0.6605 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6869 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 422/500\n",
      "32/32 [==============================] - 2s - loss: 0.7002 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6807 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 423/500\n",
      "32/32 [==============================] - 2s - loss: 0.7066 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6910 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 424/500\n",
      "32/32 [==============================] - 2s - loss: 0.6900 - acc: 0.4062 - recall: 0.4062 - precision: 0.4062 - fmeasure: 0.4062 - val_loss: 0.6917 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 425/500\n",
      "32/32 [==============================] - 2s - loss: 0.7019 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.7094 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 426/500\n",
      "32/32 [==============================] - 2s - loss: 0.6659 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6854 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 427/500\n",
      "32/32 [==============================] - 2s - loss: 0.7119 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6890 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 428/500\n",
      "32/32 [==============================] - 2s - loss: 0.6993 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6975 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 429/500\n",
      "32/32 [==============================] - 2s - loss: 0.6632 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6705 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 430/500\n",
      "32/32 [==============================] - 2s - loss: 0.6841 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.7057 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 431/500\n",
      "32/32 [==============================] - 2s - loss: 0.6961 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6919 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 432/500\n",
      "32/32 [==============================] - 2s - loss: 0.6793 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6743 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 433/500\n",
      "32/32 [==============================] - 2s - loss: 0.6817 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6882 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 434/500\n",
      "32/32 [==============================] - 2s - loss: 0.7093 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6895 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 435/500\n",
      "32/32 [==============================] - 2s - loss: 0.6760 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6838 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 436/500\n",
      "32/32 [==============================] - 2s - loss: 0.6768 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.6909 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 437/500\n",
      "32/32 [==============================] - 2s - loss: 0.6921 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6894 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 438/500\n",
      "32/32 [==============================] - 2s - loss: 0.6954 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.6975 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 439/500\n",
      "32/32 [==============================] - 2s - loss: 0.6933 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.6886 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 440/500\n",
      "32/32 [==============================] - 1s - loss: 0.6881 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6856 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 441/500\n",
      "32/32 [==============================] - 2s - loss: 0.6768 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6968 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 442/500\n",
      "32/32 [==============================] - 2s - loss: 0.6952 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6805 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 443/500\n",
      "32/32 [==============================] - 2s - loss: 0.6963 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6847 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 444/500\n",
      "32/32 [==============================] - 2s - loss: 0.6869 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6657 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 445/500\n",
      "32/32 [==============================] - 2s - loss: 0.6743 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6929 - val_acc: 0.4688 - val_recall: 0.4688 - val_precision: 0.4688 - val_fmeasure: 0.4687\n",
      "Epoch 446/500\n",
      "32/32 [==============================] - 2s - loss: 0.6950 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6917 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 447/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-09e8f8dd1fda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                               nb_epoch=NUM_EPOCHS2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1583\u001b[0m                                 \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m                                 \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m                                 pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m   1586\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m                             \u001b[0;31m# no need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, val_samples, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0menqueuer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m                 \u001b[0menqueuer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    476\u001b[0m                     \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pickle_safe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__stopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.join(): thread stopped\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(adience_gender_train_gen, \n",
    "                              validation_data=adience_gender_valid_gen,\n",
    "                              nb_val_samples=BATCH_SIZE,\n",
    "                              samples_per_epoch=BATCH_SIZE, \n",
    "                              nb_epoch=NUM_EPOCHS2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_history = history.history['acc']\n",
    "valid_history = history.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    " # Plotting training accuracy and testing accuracy acros epochs\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(train_history)\n",
    "plt.plot(valid_history)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig(PIC_NAME_FINETUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Tail-rolling average transform\n",
    "series_train = Series(train_history)\n",
    "rolling_train = series_train.rolling(window=100)\n",
    "rolling_mean_train = rolling_train.mean()\n",
    "\n",
    "series_valid = Series(valid_history)\n",
    "rolling_valid = series_valid.rolling(window=100)\n",
    "rolling_mean_valid = rolling_valid.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(rolling_mean_train)\n",
    "plt.plot(rolling_mean_valid)\n",
    "plt.title('Smoothened training and Validation Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Saving histories\n",
    "np.save(TRA_HISTORY_NAME_FINETUNING, train_history)\n",
    "np.save(VAL_HISTORY_NAME_FINETUNING, valid_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# saving weights\n",
    "model.save_weights(WEIGHTS_NAME_FINETUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(adience_gender_test_gen,BATCH_SIZE*400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
