{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# NECESSARY IMPORTS\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "from keras.models     import Sequential\n",
    "from keras.layers     import Dense, Dropout, Activation, Flatten, advanced_activations\n",
    "from keras.layers     import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import initializations\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend     as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas                     import Series\n",
    "from scipy.misc                 import imresize\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image  import (ImageDataGenerator, \n",
    "                                        array_to_img,\n",
    "                                        img_to_array,\n",
    "                                        load_img)\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# VGG16-Face Pre-trained weights download links\n",
    "TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "VGG16_LOCAL_W   = \"'vgg16_weights_tf_dim_ordering_tf_kernels.h5'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Ensure reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Path constants\n",
    "DATA_TEMPLATE     = \"./../../data/\"\n",
    "ADIENCE_META_P    = DATA_TEMPLATE + \"adience/meta\"\n",
    "ADIENCE_RAW_P     = DATA_TEMPLATE + \"adience/keras_format\"\n",
    "ADIENCE_AGE_P     = ADIENCE_RAW_P + \"/age\"\n",
    "ADIENCE_GEN_P     = ADIENCE_RAW_P + \"/gender\"\n",
    "IMG_PATH          = DATA_TEMPLATE + \"wiki/%s\"\n",
    "\n",
    "WIKI_META_P       = DATA_TEMPLATE + \"wiki_meta\"\n",
    "MODEL_TEMPLATE    = \"./models/%s\"\n",
    "WEIGHTS_TEMPLATE  = \"./weights/%s\"\n",
    "GRAPHS_TEMPLATE   = \"./graphs/%s\"\n",
    "HISTORY_TEMPLATE   = \"./histories/%s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Independent constants\n",
    "MODEL_NAME = \"1_gender_DEX_OG-BN\"\n",
    "INITIALIZATION = 'normal'\n",
    "LOSS           = \"binary_crossentropy\"\n",
    "OPTIMIZER      = SGD(lr=1e-3, momentum=0.9, decay=5e-4)\n",
    "BATCH_SIZE     = 32\n",
    "\n",
    "\n",
    "PIC_NAME     = GRAPHS_TEMPLATE % (MODEL_NAME + \".png\")\n",
    "PIC_NAME_FINETUNING = GRAPHS_TEMPLATE % (MODEL_NAME + \"_finetuning_.png\")\n",
    "WEIGHTS_NAME = WEIGHTS_TEMPLATE % (MODEL_NAME + \".h5\")\n",
    "TRA_HISTORY_NAME = HISTORY_TEMPLATE % (MODEL_NAME + \"_train_\"+\".npy\")\n",
    "VAL_HISTORY_NAME = HISTORY_TEMPLATE % (MODEL_NAME + \"_valid_\"+\".npy\")\n",
    "\n",
    "\n",
    "WEIGHTS_NAME_FINETUNING = WEIGHTS_TEMPLATE % (MODEL_NAME + \"_finetuning_.h5\")\n",
    "TRA_HISTORY_NAME_FINETUNING = HISTORY_TEMPLATE % (MODEL_NAME + \"_train_\"+\"_finetuning_.npy\")\n",
    "VAL_HISTORY_NAME_FINETUNING = HISTORY_TEMPLATE % (MODEL_NAME + \"_valid_\"+\"_finetuning_.npy\")\n",
    "\n",
    "IMG_WIDTH  = 227\n",
    "IMG_HEIGHT = 227\n",
    "\n",
    "\n",
    "ADIENCE_FULL = [\"idx\",\"user_id\",\"face_id\",\"original_image\",\"gender\",\"age\",\"img_path\",\"keras_path\"]\n",
    "ADIENCE_HEADER = [\"user_id\",\"face_id\",\"original_image\",\"gender\",\"age\",\"img_path\",\"keras_path\"]\n",
    "WIKI_HEADER    = [\"full_path\",\"age\",\"gender\"]\n",
    "\n",
    "NUM_EPOCHS  = 1500\n",
    "NUM_EPOCHS2 = 500\n",
    "\n",
    "\n",
    "BEST_CHECKPOINT = MODEL_NAME + \".weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "BEST_CHECKPOINT_FINE = MODEL_NAME + \"FINETUNE.weights.{epoch:02d}-{val_loss:.2f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "callback1 = ModelCheckpoint(BEST_CHECKPOINT, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "callback2 = ModelCheckpoint(BEST_CHECKPOINT_FINE, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dependent constants\n",
    "IMG_DIMS = (IMG_WIDTH, IMG_HEIGHT)\n",
    "MODEL_W  = MODEL_NAME + \".h5\"\n",
    "MODEL_P  = MODEL_NAME + \".txt\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Loading metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Adience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gender_train_path = ADIENCE_META_P + \"/gender_train_0.csv\"\n",
    "gender_valid_path = ADIENCE_META_P + \"/gender_valid_0.csv\"\n",
    "gender_train = pd.read_csv(filepath_or_buffer =gender_train_path)\n",
    "gender_valid = pd.read_csv(filepath_or_buffer =gender_valid_path)\n",
    "\n",
    "gender_train = gender_train[ADIENCE_HEADER]\n",
    "gender_valid = gender_valid[ADIENCE_HEADER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "age_train_path = ADIENCE_META_P + \"/age_train_0.csv\"\n",
    "age_valid_path = ADIENCE_META_P + \"/age_valid_0.csv\"\n",
    "age_train = pd.read_csv(filepath_or_buffer =gender_train_path)\n",
    "age_valid = pd.read_csv(filepath_or_buffer =gender_valid_path)\n",
    "\n",
    "age_train = age_train[ADIENCE_HEADER]\n",
    "age_valid = age_valid[ADIENCE_HEADER]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w_gender_train_path = WIKI_META_P + \"/gender/train_1.csv\"\n",
    "w_gender_valid_path = WIKI_META_P + \"/gender/valid_1.csv\"\n",
    "\n",
    "w_gender_train = pd.read_csv(filepath_or_buffer =w_gender_train_path)\n",
    "w_gender_valid = pd.read_csv(filepath_or_buffer =w_gender_valid_path)\n",
    "\n",
    "w_gender_train = w_gender_train[WIKI_HEADER]\n",
    "w_gender_valid = w_gender_valid[WIKI_HEADER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w_age_train_path = WIKI_META_P + \"/gender/train_1.csv\"\n",
    "w_age_valid_path = WIKI_META_P + \"/gender/valid_1.csv\"\n",
    "w_age_train = pd.read_csv(filepath_or_buffer =w_age_train_path)\n",
    "w_age_valid = pd.read_csv(filepath_or_buffer =w_age_valid_path)\n",
    "\n",
    "w_age_train = w_age_train[WIKI_HEADER]\n",
    "w_age_valid = w_age_valid[WIKI_HEADER]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### SHALLOW-ONLY TASK: Fix age ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef fix_age_ranges(age):\\n    if age < 4:\\n        return \"(0, 2)\"\\n    if age < 8:\\n        return \"(4, 6)\"\\n    if age < 15:\\n        return \"(8, 13)\"\\n    if age < 25:\\n        return \"(15, 20)\"\\n    if age < 38:\\n        return \"(25, 32)\"\\n    if age < 48:\\n        return \"(38, 43)\"\\n    if age < 60:\\n        return \"(48, 53)\"\\n    return \"(60-100)\"\\n\\nw_age_train[\"age\"]    = w_age_train[\"age\"].apply(lambda x: fix_age_ranges(x))\\nw_age_valid[\"age\"]    = w_age_valid[\"age\"].apply(lambda x: fix_age_ranges(x))\\nw_gender_train[\"age\"] = w_gender_train[\"age\"].apply(lambda x: fix_age_ranges(x))\\nw_gender_valid[\"age\"] = w_gender_valid[\"age\"].apply(lambda x: fix_age_ranges(x))\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def fix_age_ranges(age):\n",
    "    if age < 4:\n",
    "        return \"(0, 2)\"\n",
    "    if age < 8:\n",
    "        return \"(4, 6)\"\n",
    "    if age < 15:\n",
    "        return \"(8, 13)\"\n",
    "    if age < 25:\n",
    "        return \"(15, 20)\"\n",
    "    if age < 38:\n",
    "        return \"(25, 32)\"\n",
    "    if age < 48:\n",
    "        return \"(38, 43)\"\n",
    "    if age < 60:\n",
    "        return \"(48, 53)\"\n",
    "    return \"(60-100)\"\n",
    "\n",
    "w_age_train[\"age\"]    = w_age_train[\"age\"].apply(lambda x: fix_age_ranges(x))\n",
    "w_age_valid[\"age\"]    = w_age_valid[\"age\"].apply(lambda x: fix_age_ranges(x))\n",
    "w_gender_train[\"age\"] = w_gender_train[\"age\"].apply(lambda x: fix_age_ranges(x))\n",
    "w_gender_valid[\"age\"] = w_gender_valid[\"age\"].apply(lambda x: fix_age_ranges(x))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.1 Adience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "adience_train_aug = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "adience_valid_aug = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10505 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "ADIENCE_GENDER_TRAIN_P = ADIENCE_GEN_P + \"/train/1\"\n",
    "adience_gender_train_gen = adience_train_aug.flow_from_directory(\n",
    "    ADIENCE_GENDER_TRAIN_P,\n",
    "    target_size=IMG_DIMS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10505 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "ADIENCE_AGE_TRAIN_P = ADIENCE_AGE_P + \"/train/1\"\n",
    "adience_age_train_gen = adience_train_aug.flow_from_directory(\n",
    "    ADIENCE_AGE_TRAIN_P,\n",
    "    target_size=IMG_DIMS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3502 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "ADIENCE_GENDER_VALID_P = ADIENCE_GEN_P + \"/valid/1\"\n",
    "adience_gender_valid_gen = adience_valid_aug.flow_from_directory(\n",
    "    ADIENCE_GENDER_VALID_P,\n",
    "    target_size=IMG_DIMS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3502 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "ADIENCE_AGE_VALID_P = ADIENCE_AGE_P + \"/valid/1\"\n",
    "adience_age_valid_gen = adience_valid_aug.flow_from_directory(\n",
    "    ADIENCE_AGE_VALID_P,\n",
    "    target_size=IMG_DIMS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3445 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "ADIENCE_GENDER_TEST_P = ADIENCE_GEN_P + \"/test/\"\n",
    "adience_gender_test_gen = adience_valid_aug.flow_from_directory(\n",
    "    ADIENCE_GENDER_TEST_P,\n",
    "    target_size=IMG_DIMS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3445 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "ADIENCE_AGE_TEST_P = ADIENCE_AGE_P + \"/test/\"\n",
    "adience_age_test_gen = adience_valid_aug.flow_from_directory(\n",
    "    ADIENCE_AGE_TEST_P,\n",
    "    target_size=IMG_DIMS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.2 Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "true_path = lambda x: IMG_PATH % x\n",
    "w_age_train[\"full_path\"]    = w_age_train[\"full_path\"].apply(lambda x: true_path(x))\n",
    "w_gender_train[\"full_path\"] = w_gender_train[\"full_path\"].apply(lambda x: true_path(x))\n",
    "w_age_valid[\"full_path\"]    = w_age_valid[\"full_path\"].apply(lambda x: true_path(x))\n",
    "w_gender_valid[\"full_path\"] = w_gender_valid[\"full_path\"].apply(lambda x: true_path(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_image(x):\n",
    "    try:\n",
    "        val = img_to_array(imresize(load_img(x),IMG_DIMS))\n",
    "    except:\n",
    "        val = \"ERR\"\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data generator\n",
    "def generate_test(df, batch_size, target_feature):\n",
    "    start, end = 0, batch_size\n",
    "    while True:\n",
    "        while end < len(dfs.shape[0]):\n",
    "            ages_h = list(pd.get_dummies(data[\"age\"]).columns.values)\n",
    "            ages   = pd.get_dummies(data[\"age\"])\n",
    "            data[ages_h] = ages\n",
    "            \n",
    "            \n",
    "            genders_h = list(pd.get_dummies(data[\"gender\"]).columns.values)\n",
    "            genders   = pd.get_dummies(data[\"gender\"])\n",
    "            data[genders_h] = genders\n",
    "\n",
    "            sample = data[start:end]\n",
    "            start += batch_size\n",
    "            end   += batch_size\n",
    "\n",
    "            X         = pd.DataFrame(sample[\"full_path\"].apply(lambda x:get_image(x)))\n",
    "            good_rows = X[\"full_path\"] != \"ERR\"\n",
    "            X         = X[good_rows]\n",
    "            X.reset_index(inplace=True)\n",
    "            X = X[\"full_path\"].apply(lambda x: x.reshape((1,)+ x.shape))\n",
    "            X = np.vstack(X)\n",
    "            X /= 255\n",
    "\n",
    "            #X = model.predict(X, X.shape[0])\n",
    "\n",
    "            Y = sample[good_rows]\n",
    "            if target_feature == \"age\":\n",
    "                Y = Y[ages_h].as_matrix()\n",
    "            else:\n",
    "                Y = pd.get_dummies(Y[genders_h]).as_matrix()\n",
    "            yield (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data generator\n",
    "def generate_data(df, batch_size, target_feature):\n",
    "    start, end = 0, batch_size\n",
    "    while True:\n",
    "        data   = df.sample(frac=1).reset_index(drop=True)\n",
    "        ages_h = list(pd.get_dummies(data[\"age\"]).columns.values)\n",
    "        ages   = pd.get_dummies(data[\"age\"])\n",
    "        data[ages_h] = ages\n",
    "        \n",
    "        genders_h = list(pd.get_dummies(data[\"gender\"]).columns.values)\n",
    "        genders   = pd.get_dummies(data[\"gender\"])\n",
    "        data[genders_h] = genders\n",
    "        \n",
    "        sample = data[start:end]\n",
    "        \n",
    "        X         = pd.DataFrame(sample[\"full_path\"].apply(lambda x:get_image(x)))\n",
    "        good_rows = X[\"full_path\"] != \"ERR\"\n",
    "        X         = X[good_rows]\n",
    "        X.reset_index(inplace=True)\n",
    "        X = X[\"full_path\"].apply(lambda x: x.reshape((1,)+ x.shape))\n",
    "        X = np.vstack(X)\n",
    "        X /= 255\n",
    "        #X = model.predict(X, X.shape[0])\n",
    "        \n",
    "        Y = sample[good_rows]\n",
    "        if target_feature == \"age\":\n",
    "            Y = Y[ages_h].as_matrix()\n",
    "        else:\n",
    "            Y = pd.get_dummies(Y[genders_h]).as_matrix()\n",
    "        yield (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w_age_train_gen = generate_data(w_age_train, BATCH_SIZE, \"age\")\n",
    "w_age_valid_gen = generate_data(w_age_valid, BATCH_SIZE, \"age\")\n",
    "w_gender_train_gen = generate_data(w_gender_train, BATCH_SIZE, \"gender\")\n",
    "w_gender_valid_gen = generate_data(w_gender_valid, BATCH_SIZE, \"gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "class LRN2D(Layer):\n",
    "    \"\"\"\n",
    "    This code is adapted from pylearn2.\n",
    "    License at: https://github.com/lisa-lab/pylearn2/blob/master/LICENSE.txt\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=1e-4, k=2, beta=0.75, n=5):\n",
    "        if n % 2 == 0:\n",
    "            raise NotImplementedError(\"LRN2D only works with odd n. n provided: \" + str(n))\n",
    "        super(LRN2D, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.k = k\n",
    "        self.beta = beta\n",
    "        self.n = n\n",
    "\n",
    "    def get_output(self, train):\n",
    "        X = self.get_input(train)\n",
    "        b, ch, r, c = X.shape\n",
    "        half_n = self.n // 2\n",
    "        input_sqr = T.sqr(X)\n",
    "        extra_channels = T.alloc(0., b, ch + 2*half_n, r, c)\n",
    "        input_sqr = T.set_subtensor(extra_channels[:, half_n:half_n+ch, :, :], input_sqr)\n",
    "        scale = self.k\n",
    "        for i in range(self.n):\n",
    "            scale += self.alpha * input_sqr[:, i:i+ch, :, :]\n",
    "        scale = scale ** self.beta\n",
    "        return X / scale\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"name\": self.__class__.__name__,\n",
    "                \"alpha\": self.alpha,\n",
    "                \"k\": self.k,\n",
    "                \"beta\": self.beta,\n",
    "\"n\": self.n}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4. Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# VGG16 network\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=(IMG_WIDTH, IMG_HEIGHT,3)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), dim_ordering=\"tf\"))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), dim_ordering=\"tf\"))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), dim_ordering=\"tf\"))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), dim_ordering=\"tf\"))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2), dim_ordering=\"tf\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu', name=\"fc_1\"))\n",
    "model.add(Dense(4096, activation='relu', name=\"fc_w\"))\n",
    "model.add(Dense(1000, activation='softmax',  name=\"predictions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Obtain VGG16-Face weights\n",
    "weights_path = get_file(VGG16_LOCAL_W,TF_WEIGHTS_PATH, cache_subdir='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Loading VGG16-Face weights to VGG16 network\n",
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def my_init(shape, name=None):\n",
    "    return K.variable(np.reshape(np.arange(0, shape[0], 1), (101,1)), name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.pop()\n",
    "w1 = model.layers[-1].get_weights()\n",
    "model.pop()\n",
    "w2 = model.layers[-1].get_weights()\n",
    "\n",
    "model.add(Dense(4096, activation='relu', name=\"2fc_w\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4096, activation='relu', name=\"3fc_w\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.layers[-3].set_weights(w1)\n",
    "model.layers[-5].set_weights(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#layer = model.layers[-1]\n",
    "#layer.trainable = False\n",
    "\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=['accuracy', 'recall', 'precision','f1score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 6. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/ops.py:739: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = lib.scalar_compare(x, y, op)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 6s - loss: 1.1512 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6753 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 2/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8379 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6848 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 3/1500\n",
      "32/32 [==============================] - 1s - loss: 1.5203 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6575 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 4/1500\n",
      "32/32 [==============================] - 1s - loss: 0.9976 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6331 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 5/1500\n",
      "32/32 [==============================] - 1s - loss: 1.3416 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.6708 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 6/1500\n",
      "32/32 [==============================] - 1s - loss: 1.7160 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6788 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 7/1500\n",
      "32/32 [==============================] - 1s - loss: 0.9283 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6764 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 8/1500\n",
      "32/32 [==============================] - 1s - loss: 1.0055 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6778 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 9/1500\n",
      "32/32 [==============================] - 1s - loss: 0.9770 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.7050 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 10/1500\n",
      "32/32 [==============================] - 1s - loss: 1.5377 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.7182 - val_acc: 0.1250 - val_recall: 0.1250 - val_precision: 0.1250 - val_fmeasure: 0.1250\n",
      "Epoch 11/1500\n",
      "32/32 [==============================] - 1s - loss: 0.9199 - acc: 0.5000 - recall: 0.5000 - precision: 0.5000 - fmeasure: 0.5000 - val_loss: 0.7086 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 12/1500\n",
      "32/32 [==============================] - 1s - loss: 1.0693 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6697 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 13/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7892 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6619 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 14/1500\n",
      "32/32 [==============================] - 1s - loss: 1.2303 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6888 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 15/1500\n",
      "32/32 [==============================] - 1s - loss: 1.0097 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.6765 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 16/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7786 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.7585 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 17/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4968 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.7204 - val_acc: 0.1875 - val_recall: 0.1875 - val_precision: 0.1875 - val_fmeasure: 0.1875\n",
      "Epoch 18/1500\n",
      "32/32 [==============================] - 1s - loss: 1.4163 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.6731 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 19/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7569 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6809 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 20/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8788 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6200 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 21/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8764 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6181 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 22/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7825 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6617 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 23/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6511 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6734 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 24/1500\n",
      "32/32 [==============================] - 1s - loss: 1.0359 - acc: 0.3438 - recall: 0.3438 - precision: 0.3438 - fmeasure: 0.3437 - val_loss: 0.6408 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 25/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6393 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6086 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 26/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5805 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6388 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 27/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6692 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6581 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 28/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5446 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6455 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 29/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5987 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6956 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 30/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5587 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6446 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 31/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6230 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.7177 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 32/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6951 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.7518 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 33/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5681 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.7081 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 34/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6101 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6158 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 35/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4704 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6395 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 36/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5400 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.6542 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 37/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5582 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6001 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 38/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6714 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6595 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 39/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7935 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6322 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 40/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5988 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6186 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 41/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5999 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.6207 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 42/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5698 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6050 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 43/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5037 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5716 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 44/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4849 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5673 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 45/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3874 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6136 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 46/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4945 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5673 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 47/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5479 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5569 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 48/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5958 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6329 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 49/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6702 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6074 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 50/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4755 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5304 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 51/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5385 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5188 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 52/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4694 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5626 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 53/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4900 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6045 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 54/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4806 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6273 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 55/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3747 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5379 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 56/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4973 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5609 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 57/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3727 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6225 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 58/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4567 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5019 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 59/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4437 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6157 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 60/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3758 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5429 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 61/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5236 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5705 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 62/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2800 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6188 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 63/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5310 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6446 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 64/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5139 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5748 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 65/1500\n",
      "32/32 [==============================] - 1s - loss: 1.2875 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.5420 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 66/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4692 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6441 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 67/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3900 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5518 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 68/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3777 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5051 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 69/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4465 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5995 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 70/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5610 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.5707 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 71/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5081 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4151 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 72/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5067 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5049 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 73/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2803 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.5461 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 74/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4475 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4622 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 75/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5084 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6370 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 76/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6117 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5126 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 77/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5270 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4368 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 78/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8542 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6603 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 79/1500\n",
      "32/32 [==============================] - 1s - loss: 1.1220 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.4584 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 80/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4251 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6214 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 81/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4671 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5825 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 82/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4070 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6283 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 83/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8327 - acc: 0.3750 - recall: 0.3750 - precision: 0.3750 - fmeasure: 0.3750 - val_loss: 0.5720 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 84/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4996 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4833 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 85/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4490 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6104 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 86/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7053 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.4066 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 87/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4883 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6754 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 88/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5184 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4775 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 89/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4666 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6556 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 90/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4900 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4588 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 91/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4020 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4879 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 92/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4611 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4808 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 93/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3852 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5434 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 94/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4404 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4499 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 95/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5313 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6454 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 96/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4385 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4521 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 97/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3135 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4567 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 98/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2850 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5101 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 99/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3858 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.7771 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 100/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5193 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5539 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 101/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4060 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5123 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 102/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3277 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5065 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 103/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3360 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4861 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 104/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4276 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5149 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 105/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3768 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5167 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 106/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6080 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4545 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 107/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6038 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5544 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 108/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5808 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6821 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 109/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3740 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6436 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 110/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5240 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5324 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 111/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4588 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5376 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 112/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6474 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6626 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 113/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3676 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5247 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 114/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4826 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6187 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 115/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2747 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4780 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 116/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4108 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.7787 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 117/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4816 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4998 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 118/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2473 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5843 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 119/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4416 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5038 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 120/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5450 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5103 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 121/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4093 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4151 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 122/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6598 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.7044 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 123/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4827 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.7083 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 124/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4424 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5935 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 125/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5052 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4243 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 126/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6137 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5013 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 127/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3294 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4910 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 128/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5853 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4319 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 129/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4572 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4907 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 130/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6098 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4165 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 131/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3991 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4757 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 132/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5567 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4111 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 133/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4963 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4718 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 134/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3445 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4044 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 135/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4203 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4976 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 136/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4986 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4633 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 137/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5339 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5570 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 138/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3981 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6956 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 139/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6493 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5467 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 140/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3781 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5778 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 141/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4194 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5652 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 142/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5705 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4119 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 143/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4541 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5465 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 144/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4812 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6306 - val_acc: 0.4062 - val_recall: 0.4062 - val_precision: 0.4062 - val_fmeasure: 0.4062\n",
      "Epoch 145/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7608 - acc: 0.4375 - recall: 0.4375 - precision: 0.4375 - fmeasure: 0.4375 - val_loss: 0.5926 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 146/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8529 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.4371 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 147/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5671 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6711 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 148/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4368 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4717 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 149/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4354 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5700 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 150/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2055 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4721 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 151/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3463 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5575 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 152/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5212 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5424 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 153/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3035 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4086 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 154/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3330 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3437 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 155/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4584 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4319 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 156/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3523 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3695 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 157/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2690 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5514 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 158/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3133 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.7305 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 159/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8725 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5114 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 160/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5846 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3743 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 161/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6427 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5955 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 162/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7826 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.2597 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 163/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8815 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4840 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 164/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3756 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5844 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 165/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7551 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6479 - val_acc: 0.4375 - val_recall: 0.4375 - val_precision: 0.4375 - val_fmeasure: 0.4375\n",
      "Epoch 166/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5888 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5861 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 167/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4721 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5819 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 168/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7551 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3564 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 169/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5790 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3826 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 170/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5515 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.3751 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 171/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6956 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.3203 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 172/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4922 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6703 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 173/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7097 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.7186 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 174/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3932 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6579 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 175/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3652 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5484 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 176/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7024 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3951 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 177/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5241 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6129 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 178/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5987 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4602 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 179/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3581 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3511 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 180/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2902 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6356 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 181/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4859 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4491 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 182/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2287 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3376 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 183/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3742 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4574 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 184/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3144 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.5451 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 185/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2774 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3405 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 186/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2765 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.4395 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 187/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3366 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4963 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 188/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2988 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5674 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 189/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2132 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4467 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 190/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3916 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4157 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 191/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4438 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4460 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 192/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4869 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5123 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 193/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3329 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.5322 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 194/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5898 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4246 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 195/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3390 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5625 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 196/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4023 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3336 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 197/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4090 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5187 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 198/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4683 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4433 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 199/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4675 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4198 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 200/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2613 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4678 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 201/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4780 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4055 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 202/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3526 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3848 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 203/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3888 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3387 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 204/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3916 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4574 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 205/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2540 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4349 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 206/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5925 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5880 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 207/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3928 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5998 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 208/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4626 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5506 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 209/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2848 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.6070 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 210/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4184 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4963 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 211/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5997 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3563 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 212/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4622 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4541 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 213/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3344 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6341 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 214/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4109 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2069 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 215/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3087 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5256 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 216/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2643 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3452 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 217/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2687 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4316 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 218/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3422 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.5741 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 219/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4009 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3338 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 220/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2316 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5234 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 221/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3088 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2484 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 222/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4024 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4275 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 223/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3889 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5483 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 224/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5592 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.2416 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 225/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3544 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4364 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 226/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4944 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3573 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 227/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4284 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3149 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 228/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5250 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.8079 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 229/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5703 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.1823 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 230/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3698 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2491 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 231/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5468 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5926 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 232/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4496 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5251 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 233/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4537 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.8785 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 234/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3761 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3230 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 235/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4500 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4871 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 236/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4733 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2330 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 237/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5329 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2759 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 238/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2638 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5181 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 239/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3769 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4015 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 240/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4069 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6281 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 241/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3289 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5924 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 242/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3927 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.7117 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 243/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2365 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4372 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 244/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3791 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4533 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 245/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4040 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6304 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 246/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3124 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4644 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 247/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2362 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2582 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 248/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2552 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2910 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 249/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2755 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4420 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 250/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4374 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5092 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 251/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4064 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5179 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 252/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4213 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2314 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 253/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3754 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3844 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 254/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7090 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 1.1344 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 255/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5259 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5458 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 256/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6088 - acc: 0.5625 - recall: 0.5625 - precision: 0.5625 - fmeasure: 0.5625 - val_loss: 0.3696 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 257/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2177 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.5062 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 258/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8885 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4186 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 259/1500\n",
      "32/32 [==============================] - 1s - loss: 1.1769 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3331 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 260/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2841 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2868 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 261/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4697 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6553 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 262/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3394 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6826 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 263/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4169 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5523 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 264/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3503 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5701 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 265/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3197 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4282 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 266/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7133 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.9129 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 267/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4832 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3706 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 268/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4808 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5844 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 269/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3116 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6607 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 270/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3387 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.7749 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 271/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7555 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3957 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 272/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3260 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4837 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 273/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4880 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4480 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 274/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3661 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4457 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 275/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2913 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 1.3344 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 276/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2880 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5581 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 277/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5660 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3957 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 278/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8181 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3114 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 279/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5864 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6702 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 280/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4194 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3042 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 281/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6875 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.1608 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 282/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4762 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3157 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 283/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6178 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3521 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 284/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3350 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 1.1029 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 285/1500\n",
      "32/32 [==============================] - 1s - loss: 1.4114 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2935 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 286/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2304 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3434 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 287/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3247 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3664 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 288/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3281 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3408 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 289/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4886 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3007 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 290/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3738 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6119 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 291/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2702 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5132 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 292/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3761 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.7146 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 293/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5272 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3000 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 294/1500\n",
      "32/32 [==============================] - 1s - loss: 1.1607 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5149 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 295/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4271 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6614 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 296/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3558 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5321 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 297/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2390 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3616 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 298/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1582 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4056 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 299/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3315 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4446 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 300/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2801 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4899 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 301/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4541 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4266 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 302/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5342 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 1.0248 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 303/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4294 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4021 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 304/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3822 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4227 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 305/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3137 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.7942 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 306/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5152 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4539 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 307/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7316 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.2433 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 308/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3340 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.7024 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 309/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6876 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3678 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 310/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4560 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2953 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 311/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6217 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.5882 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 312/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4224 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4164 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 313/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2790 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3888 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 314/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3284 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4945 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 315/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1963 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2451 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 316/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5156 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4935 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 317/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4436 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4437 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 318/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3040 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2736 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 319/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2094 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4522 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 320/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2424 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3340 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 321/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3255 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3485 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 322/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4266 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2973 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 323/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7038 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.2892 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 324/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5108 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3230 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 325/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4473 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3583 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 326/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3220 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2547 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 327/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6698 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3163 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 328/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2630 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4484 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 329/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3283 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3369 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 330/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6862 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3052 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 331/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2247 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4280 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 332/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3588 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.1834 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 333/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2557 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6533 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 334/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3866 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4331 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 335/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2407 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6661 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 336/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2309 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5487 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 337/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3928 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2973 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 338/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2196 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3016 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 339/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4599 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2556 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 340/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6191 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3780 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 341/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2084 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4848 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 342/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6053 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2960 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 343/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4374 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6515 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 344/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1669 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3199 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 345/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2140 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4017 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 346/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3371 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2871 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 347/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1526 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3959 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 348/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4162 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4052 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 349/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3863 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1657 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 350/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3722 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6068 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 351/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3194 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5364 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 352/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4904 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2484 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 353/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2999 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2802 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 354/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1702 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3322 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 355/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4930 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6595 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 356/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3698 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2473 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 357/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7339 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3418 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 358/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5703 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.5380 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 359/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4849 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6848 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 360/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5757 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5353 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 361/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3436 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3595 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 362/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3639 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3226 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 363/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2081 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.4908 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 364/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3263 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3482 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 365/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3741 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2623 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 366/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3726 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2822 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 367/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2677 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.2758 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 368/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2289 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3417 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 369/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2015 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3668 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 370/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4710 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5472 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 371/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2416 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.7032 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 372/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2923 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3383 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 373/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3711 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5701 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 374/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2202 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.4172 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 375/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3770 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4762 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 376/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3099 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6069 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 377/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5317 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.1938 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 378/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4120 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5449 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 379/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4183 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.2163 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 380/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3766 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3712 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 381/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3143 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2453 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 382/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3085 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5491 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 383/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2341 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2997 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 384/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3074 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3683 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 385/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5170 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4983 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 386/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3513 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2458 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 387/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2978 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4264 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 388/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4772 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3485 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 389/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2856 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2322 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 390/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2083 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1633 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 391/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3255 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5382 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 392/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4877 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4239 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 393/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1877 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.9127 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 394/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2414 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4415 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 395/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4683 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5436 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 396/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4983 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3129 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 397/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4149 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6865 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 398/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1759 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3514 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 399/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4355 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4632 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 400/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2299 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3075 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 401/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1651 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1568 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 402/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3595 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3876 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 403/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2513 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4466 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 404/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2735 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3160 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 405/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3912 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3421 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 406/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2460 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3619 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 407/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4306 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.2423 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 408/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2733 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3161 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 409/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5292 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6513 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 410/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2890 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2808 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 411/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3367 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2021 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 412/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8125 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5225 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 413/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4806 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3655 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 414/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2698 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.5112 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 415/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4358 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4842 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 416/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2835 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4332 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 417/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3437 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3083 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 418/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5708 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3291 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 419/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2991 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2275 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 420/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2682 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6002 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 421/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2037 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4421 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 422/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4282 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6001 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 423/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3703 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2902 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 424/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2811 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3425 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 425/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5597 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3526 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 426/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3432 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2552 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 427/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2854 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4026 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 428/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3569 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6123 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 429/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4568 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2465 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 430/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2663 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2853 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 431/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5498 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6384 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 432/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2486 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.5399 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 433/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3858 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3194 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 434/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3564 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5028 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 435/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3597 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4117 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 436/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1732 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3666 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 437/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2582 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3445 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 438/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3820 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2427 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 439/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4675 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2087 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 440/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2691 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4281 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 441/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3473 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5374 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 442/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5343 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6939 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 443/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4030 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3539 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 444/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3893 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4124 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 445/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4229 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3563 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 446/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3817 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4593 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 447/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6679 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3370 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 448/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3424 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4477 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 449/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3120 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3832 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 450/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4749 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5162 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 451/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4831 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3489 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 452/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4208 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4702 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 453/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3574 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4056 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 454/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2738 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1990 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_fmeasure: 1.0000\n",
      "Epoch 455/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3078 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5205 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 456/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2143 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.5190 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 457/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3538 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4009 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 458/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3780 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4396 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 459/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8052 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4638 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 460/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2539 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5809 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 461/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7752 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.9549 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 462/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3822 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5722 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 463/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3440 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3367 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 464/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2311 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2790 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 465/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4337 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2208 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 466/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3023 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3094 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 467/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4994 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6215 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 468/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4710 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 1.2388 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 469/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2607 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 1.5199 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 470/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5807 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4522 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 471/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2469 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.1727 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 472/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2205 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3871 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 473/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3969 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5736 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 474/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4682 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4700 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 475/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3989 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3255 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 476/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7428 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2834 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 477/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3107 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.8481 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 478/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4740 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5627 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 479/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4257 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4580 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 480/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5754 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3223 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 481/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4261 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3976 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 482/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2584 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.1468 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 483/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3709 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3783 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 484/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6486 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2735 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 485/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2337 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4550 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 486/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5108 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3700 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 487/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6032 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3334 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 488/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2988 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2816 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 489/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3614 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3249 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 490/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2861 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4822 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 491/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2894 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2400 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 492/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4048 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.1716 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 493/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2587 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1796 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 494/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1946 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2352 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 495/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4045 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1494 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 496/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3101 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6490 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 497/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3869 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4414 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 498/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2026 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.1641 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 499/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2154 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3087 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 500/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5178 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4486 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 501/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2833 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.8285 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 502/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3884 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 1.3032 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 503/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5899 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2741 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 504/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4340 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3200 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 505/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5289 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.2698 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 506/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3091 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.7401 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 507/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4509 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.1597 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 508/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4655 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3669 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 509/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5423 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2443 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 510/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3367 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2922 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 511/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3649 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3096 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 512/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3146 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4855 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 513/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2911 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6718 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 514/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4054 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6871 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 515/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5648 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5734 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 516/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3766 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4141 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 517/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3131 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5407 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 518/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2686 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.7577 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 519/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2807 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3540 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 520/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2874 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5017 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 521/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1770 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2852 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 522/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2714 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5934 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 523/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3016 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3018 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 524/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3790 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6644 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 525/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4852 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5657 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 526/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3501 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5700 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 527/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2884 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2168 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 528/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2963 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4602 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 529/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3174 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4666 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 530/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3747 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3211 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 531/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4060 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2319 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 532/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4074 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4001 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 533/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3405 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2407 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 534/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1826 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.7996 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 535/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4322 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6543 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 536/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4016 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4911 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 537/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4705 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3582 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 538/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2743 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.0492 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_fmeasure: 1.0000\n",
      "Epoch 539/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3575 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2564 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 540/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4202 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6239 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 541/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3249 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1428 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 542/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2897 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3683 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 543/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5842 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2734 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 544/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4590 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3581 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 545/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2536 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4197 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 546/1500\n",
      "32/32 [==============================] - 1s - loss: 1.1138 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.3512 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 547/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5803 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.6440 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 548/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4793 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3324 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 549/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2439 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3340 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 550/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5496 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.7106 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 551/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3551 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2816 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 552/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4309 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3359 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 553/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4305 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3190 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 554/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3571 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4072 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 555/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6449 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.1421 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 556/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3889 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1098 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 557/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3556 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2870 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 558/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2274 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4209 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 559/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3402 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1086 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 560/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2737 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.1524 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 561/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5361 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2319 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 562/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2323 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.4879 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 563/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4210 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3774 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 564/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2788 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2963 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 565/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2945 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6984 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 566/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1447 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.5382 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 567/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3167 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2527 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 568/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1271 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3580 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 569/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3646 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5436 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 570/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3138 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3630 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 571/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3413 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1626 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 572/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3602 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2739 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 573/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4037 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2788 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 574/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1533 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.1907 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 575/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3035 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3706 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 576/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2076 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2098 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 577/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2527 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2048 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 578/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6178 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2865 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 579/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2401 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5452 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 580/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4519 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4871 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 581/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4932 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3453 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 582/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6122 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3561 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 583/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2533 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3665 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 584/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4453 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4498 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 585/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3766 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.8540 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 586/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2770 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4426 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 587/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2301 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2237 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 588/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5401 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2973 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 589/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2152 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.1532 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 590/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2304 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4235 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 591/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5126 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2673 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 592/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3675 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2362 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 593/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2920 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5431 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 594/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3348 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4651 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 595/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3707 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.1919 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 596/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2912 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3269 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 597/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4732 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.8068 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 598/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3879 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6691 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 599/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3292 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.8040 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 600/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4054 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3339 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 601/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3533 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3933 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 602/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4896 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6260 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 603/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3272 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2332 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 604/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2711 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2360 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 605/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3127 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2084 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 606/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1708 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4147 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 607/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2690 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.6558 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 608/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1643 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2190 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 609/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3307 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1784 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 610/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3449 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2625 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 611/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2440 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2614 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 612/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8777 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.3878 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 613/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2071 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3594 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 614/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1860 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.6221 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 615/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3551 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3006 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 616/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1649 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3072 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 617/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3714 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2137 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 618/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1107 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3983 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 619/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2794 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6114 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 620/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2525 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1163 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_fmeasure: 1.0000\n",
      "Epoch 621/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4237 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3394 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 622/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2321 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3003 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 623/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3384 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2887 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 624/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4122 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2195 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 625/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2089 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2692 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 626/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2044 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3318 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 627/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1844 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3674 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 628/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7983 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3254 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 629/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1687 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2880 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 630/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3586 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5115 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 631/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3051 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2149 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 632/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3890 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2922 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 633/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2618 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3272 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 634/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2283 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2713 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 635/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6589 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4061 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 636/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1622 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.9140 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 637/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5148 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4138 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 638/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3599 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3205 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 639/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2763 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3063 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 640/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4049 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2845 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 641/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4019 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3164 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 642/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2215 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4236 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 643/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2653 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.6395 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 644/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4269 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3277 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 645/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3072 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2145 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 646/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1870 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4232 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 647/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2312 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.1137 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 648/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2876 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2188 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 649/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5015 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3078 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 650/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5042 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.7590 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 651/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3099 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3063 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 652/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5660 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3210 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 653/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2598 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2737 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 654/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2217 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.1962 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 655/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2537 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2670 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 656/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7199 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5920 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 657/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3758 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1834 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 658/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5163 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2617 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 659/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3524 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2425 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 660/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3675 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.8440 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 661/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5908 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.7122 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 662/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7351 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.3168 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 663/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3814 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1451 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 664/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3106 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3399 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 665/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2940 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.7691 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 666/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8135 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2837 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 667/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2089 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.8978 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 668/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3548 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2755 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 669/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2499 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4774 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 670/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2891 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1974 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 671/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2458 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2160 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 672/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3690 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4420 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 673/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2567 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2355 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 674/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5741 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.2372 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 675/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3979 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2264 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 676/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4211 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.1750 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 677/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3668 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3401 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 678/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3243 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2654 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 679/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2920 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4501 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 680/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3843 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2148 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 681/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2181 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3031 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 682/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3309 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2619 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 683/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1440 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.2751 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 684/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2582 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4994 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 685/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1271 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3375 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 686/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1454 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.2745 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 687/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4428 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4507 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 688/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2519 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3869 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 689/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2235 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4100 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 690/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3217 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.7151 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 691/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2050 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2233 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 692/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3212 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3556 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 693/1500\n",
      "32/32 [==============================] - 1s - loss: 0.9797 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3792 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 694/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4098 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3328 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 695/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4463 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 1.0032 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 696/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5956 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.7353 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 697/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6113 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3960 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 698/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3931 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3504 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 699/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1796 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2029 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 700/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3503 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3997 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 701/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6242 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5777 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 702/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4266 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4284 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 703/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3943 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2998 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 704/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2631 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1441 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 705/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2738 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3551 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 706/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1838 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.4535 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 707/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2848 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3926 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 708/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2324 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3687 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 709/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2982 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4525 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 710/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3507 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4913 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 711/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2745 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5863 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 712/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1084 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.1628 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 713/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4657 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3523 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 714/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2848 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4462 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 715/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1462 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3583 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 716/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2617 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2787 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 717/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2173 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2220 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 718/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2845 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.1744 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 719/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2074 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1956 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 720/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3383 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3830 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 721/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2878 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1524 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 722/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2676 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3916 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 723/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4761 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3013 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 724/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5156 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3408 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 725/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5797 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2656 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 726/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4311 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3970 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 727/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1318 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4516 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 728/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6300 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4154 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 729/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5266 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.7891 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 730/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4418 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.8254 - val_acc: 0.5625 - val_recall: 0.5625 - val_precision: 0.5625 - val_fmeasure: 0.5625\n",
      "Epoch 731/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4553 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.7716 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 732/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4678 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5735 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 733/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8300 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.7827 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 734/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3477 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6341 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 735/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5508 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.7281 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 736/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2206 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.7069 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 737/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1946 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6844 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 738/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1607 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4885 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 739/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5851 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.6553 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 740/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4586 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6233 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 741/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1589 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.7052 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 742/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3577 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6167 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 743/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4129 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5377 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 744/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3434 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5164 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 745/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4053 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5596 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 746/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3037 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4739 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 747/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1972 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5397 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 748/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1477 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.7910 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 749/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3575 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5990 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 750/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2700 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6103 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 751/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4121 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5420 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 752/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4461 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4470 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 753/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7122 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4207 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 754/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1982 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6445 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 755/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3423 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6830 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 756/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4462 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5882 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 757/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2009 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5184 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 758/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5550 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4057 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 759/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3629 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3832 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 760/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2173 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2316 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 761/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2363 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2495 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 762/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4330 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3306 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 763/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4959 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4385 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 764/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2599 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4034 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 765/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3636 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4751 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 766/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2407 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5821 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 767/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4099 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2795 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 768/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2823 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3900 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 769/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5482 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.4193 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 770/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3770 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6552 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 771/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4378 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3973 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 772/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3158 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3374 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 773/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2002 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4272 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 774/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4126 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5847 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 775/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8352 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3890 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 776/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3251 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2189 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 777/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3156 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3963 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 778/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4493 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3073 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 779/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1873 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2484 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 780/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3984 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4478 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 781/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2364 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.9308 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 782/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4236 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6237 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 783/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5367 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 1.7579 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 784/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7779 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 1.3610 - val_acc: 0.5000 - val_recall: 0.5000 - val_precision: 0.5000 - val_fmeasure: 0.5000\n",
      "Epoch 785/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2369 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.9737 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 786/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4721 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3004 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 787/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1971 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3882 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 788/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5285 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2430 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 789/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2966 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5043 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 790/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1402 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.3554 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 791/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4926 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.1712 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 792/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6047 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.1733 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 793/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2054 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4177 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 794/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4693 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.2709 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 795/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3752 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5018 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 796/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2583 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5654 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 797/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4476 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6973 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 798/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4394 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1291 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 799/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2678 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2416 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 800/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3018 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4853 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 801/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2394 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.1881 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 802/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6892 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.1772 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 803/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2753 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2006 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 804/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1766 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2422 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 805/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2973 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1989 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 806/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2698 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2953 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 807/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4509 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1703 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 808/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5620 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4523 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 809/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4988 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3226 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 810/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3977 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4986 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 811/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3258 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2007 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 812/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3517 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2190 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 813/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3317 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5245 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 814/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3444 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1447 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 815/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1943 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.4827 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 816/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3872 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4094 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 817/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2198 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2575 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 818/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7106 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4061 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 819/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2189 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5079 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 820/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4525 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2197 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 821/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3519 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4466 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 822/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2363 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3651 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 823/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1893 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4600 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 824/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2775 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3591 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 825/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2536 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5142 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 826/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2743 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3983 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 827/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1255 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.4933 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 828/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1718 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.5789 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 829/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1364 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.1666 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 830/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2792 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3734 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 831/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1364 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3880 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 832/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3822 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1887 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 833/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2323 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3819 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 834/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3560 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5317 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 835/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2979 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1776 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 836/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1577 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.7609 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 837/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2095 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3350 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 838/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8054 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6730 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 839/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3860 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.7205 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 840/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5065 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3243 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 841/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2645 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4668 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 842/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2213 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6001 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 843/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4418 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3132 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 844/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5567 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5094 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 845/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2025 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3401 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 846/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3784 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.9815 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 847/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2823 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3206 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 848/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2604 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3903 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 849/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1627 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.1762 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 850/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2493 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3055 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 851/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4544 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 1.0939 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 852/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1659 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2713 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 853/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2488 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4621 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 854/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1933 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2574 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 855/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7800 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3225 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 856/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4419 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2689 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 857/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5257 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4234 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 858/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3040 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4759 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 859/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2086 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1234 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 860/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4246 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5358 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 861/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5297 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4910 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 862/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2268 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.1564 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 863/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2524 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2709 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 864/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5291 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4678 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 865/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4106 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1830 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 866/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5549 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2807 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 867/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4363 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1760 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 868/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4738 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4327 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 869/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4066 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4535 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 870/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2488 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.7751 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 871/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3319 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1189 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 872/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2142 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3124 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 873/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1433 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3787 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 874/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1431 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.9102 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 875/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2963 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1158 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 876/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7833 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.0756 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_fmeasure: 1.0000\n",
      "Epoch 877/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2021 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.5428 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 878/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4351 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2125 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 879/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2520 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6436 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 880/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4514 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2527 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 881/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2232 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2992 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 882/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2063 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5743 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 883/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2290 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.1435 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_fmeasure: 1.0000\n",
      "Epoch 884/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2913 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2840 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 885/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1198 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1699 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 886/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2254 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2398 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 887/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6693 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1871 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 888/1500\n",
      "32/32 [==============================] - 1s - loss: 0.0942 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.1526 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 889/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2327 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3851 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 890/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4434 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6316 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 891/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2445 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2265 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 892/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1148 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3221 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 893/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3452 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1938 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 894/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2925 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3611 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 895/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3179 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2741 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 896/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1599 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5486 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 897/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2049 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1346 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 898/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4623 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4718 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 899/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2012 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4618 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 900/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2078 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3711 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 901/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2554 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2709 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 902/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3268 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.6544 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 903/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4766 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3559 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 904/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7241 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.0609 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_fmeasure: 1.0000\n",
      "Epoch 905/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5722 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3344 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 906/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5269 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3128 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 907/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4119 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2484 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 908/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8226 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.1681 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 909/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2107 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2707 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 910/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3139 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4816 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 911/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4512 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.1815 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 912/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7567 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4441 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 913/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6113 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3986 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 914/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3933 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3684 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 915/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2644 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.1797 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 916/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3008 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1910 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 917/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2407 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3694 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 918/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4568 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.8096 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 919/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5115 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3385 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 920/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4604 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4099 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 921/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2544 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3658 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 922/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2844 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3655 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 923/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2342 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3166 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 924/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7426 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3525 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 925/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5749 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2336 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 926/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4857 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.9951 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 927/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4562 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.9611 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 928/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5866 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4582 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 929/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1929 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2857 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 930/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2647 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1576 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 931/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1418 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3468 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 932/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1132 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.2978 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 933/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2807 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.4124 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 934/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3646 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3704 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 935/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6174 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3514 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 936/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4158 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4232 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 937/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8490 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1879 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 938/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3480 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2434 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 939/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3068 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4585 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 940/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1624 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.1808 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 941/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2015 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2036 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 942/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2879 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3172 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 943/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4224 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2746 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 944/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4316 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4074 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 945/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2346 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2203 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 946/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1789 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3351 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 947/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3694 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3963 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 948/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2013 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3742 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 949/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4017 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3739 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 950/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1746 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2635 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 951/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1096 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.2684 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 952/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1918 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3712 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 953/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3546 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2830 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 954/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2620 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4802 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 955/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2929 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4057 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 956/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2123 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4076 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 957/1500\n",
      "32/32 [==============================] - 1s - loss: 0.0798 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.3071 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 958/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1623 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.2349 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 959/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5229 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4472 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 960/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2566 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2860 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 961/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2388 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2585 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 962/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2041 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1205 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 963/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1745 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2428 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 964/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1861 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2105 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 965/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3740 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2147 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 966/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2744 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2591 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 967/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4387 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3156 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 968/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2883 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3247 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 969/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2771 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4173 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 970/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2000 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2757 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 971/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1581 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1202 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 972/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1129 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.1269 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 973/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3216 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2088 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 974/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1630 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2644 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 975/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2048 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3854 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 976/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4692 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.1511 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_fmeasure: 1.0000\n",
      "Epoch 977/1500\n",
      "32/32 [==============================] - 1s - loss: 1.1183 - acc: 0.6250 - recall: 0.6250 - precision: 0.6250 - fmeasure: 0.6250 - val_loss: 0.3890 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 978/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1673 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3032 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 979/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1956 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2891 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 980/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1255 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.4032 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 981/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2548 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5130 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 982/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3947 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3589 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 983/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3198 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4004 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 984/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1299 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.5930 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 985/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3454 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4635 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 986/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3480 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.7794 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 987/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3379 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.7580 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 988/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2344 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3799 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 989/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2818 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5457 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 990/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4046 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3248 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 991/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1483 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.7965 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 992/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2529 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6065 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 993/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2230 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.7393 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 994/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5261 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4285 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 995/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3921 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4925 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 996/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1870 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.6202 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 997/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2724 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3225 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 998/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1458 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4370 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 999/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1592 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3658 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1000/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3256 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2890 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1001/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1618 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.6832 - val_acc: 0.6250 - val_recall: 0.6250 - val_precision: 0.6250 - val_fmeasure: 0.6250\n",
      "Epoch 1002/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3375 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4877 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1003/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2300 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3824 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1004/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2829 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2404 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1005/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2755 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4231 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1006/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2151 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2450 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1007/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6376 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4408 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1008/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3693 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3495 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1009/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2849 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3733 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1010/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1287 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3496 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1011/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2625 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5333 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 1012/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2368 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4253 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1013/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4460 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5030 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1014/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2263 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3148 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1015/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1934 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2992 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1016/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2043 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2348 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1017/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3351 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4338 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1018/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2694 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.5645 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1019/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3473 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5060 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1020/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3433 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3842 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1021/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4056 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3630 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1022/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7904 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3278 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1023/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2051 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2320 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1024/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2456 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5500 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1025/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4307 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5987 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1026/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4389 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2586 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1027/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3934 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3850 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1028/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2315 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2957 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1029/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2170 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4664 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1030/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2634 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.5741 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1031/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1602 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3149 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1032/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2327 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6397 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1033/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4502 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3834 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1034/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2755 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4242 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1035/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3087 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4798 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1036/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1968 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.9307 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1037/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4364 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4527 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1038/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1728 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.7715 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1039/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1258 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.5080 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1040/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6177 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4782 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1041/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7873 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.9291 - val_acc: 0.5312 - val_recall: 0.5312 - val_precision: 0.5312 - val_fmeasure: 0.5312\n",
      "Epoch 1042/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5863 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4174 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1043/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1723 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3409 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1044/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1372 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3743 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1045/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2226 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4615 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1046/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2545 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3661 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1047/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1070 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.3951 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1048/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1703 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.5935 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1049/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3241 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.7265 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1050/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2214 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3652 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1051/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1846 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2505 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1052/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6237 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5276 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1053/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2780 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3032 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1054/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2678 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2751 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1055/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5343 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6985 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1056/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2218 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2675 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1057/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3610 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2559 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1058/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5951 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4187 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1059/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5080 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.7169 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1060/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3219 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1730 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1061/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3654 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.4328 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1062/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1865 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1357 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1063/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5266 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2018 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1064/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1883 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3272 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1065/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1884 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2775 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1066/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7272 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2220 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1067/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5856 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.3966 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1068/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1553 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3158 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1069/1500\n",
      "32/32 [==============================] - 1s - loss: 0.0792 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.5661 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1070/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3919 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2019 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1071/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2287 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.0938 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1072/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2242 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3263 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1073/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2982 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.0221 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_fmeasure: 1.0000\n",
      "Epoch 1074/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3176 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2380 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1075/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2303 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2528 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1076/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2518 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1482 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1077/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1201 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.1739 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1078/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2713 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2187 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1079/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2404 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.8931 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1080/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2559 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2786 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1081/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4517 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3615 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1082/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1702 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3027 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1083/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4900 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.1958 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1084/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3685 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2002 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1085/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2057 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2105 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1086/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7889 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2714 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1087/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1764 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1477 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1088/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2288 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.5852 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1089/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2269 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3106 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1090/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5445 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3470 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1091/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3960 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4144 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1092/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3032 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3669 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1093/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1938 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4945 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1094/1500\n",
      "32/32 [==============================] - 1s - loss: 1.0656 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.7140 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1095/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2894 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2280 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1096/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2450 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1474 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1097/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6600 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1939 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1098/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2488 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3966 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1099/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2240 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4553 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1100/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4340 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4458 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1101/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3512 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2997 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1102/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2704 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4128 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1103/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3671 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4395 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1104/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2471 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4250 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1105/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2163 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5421 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1106/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2308 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3033 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1107/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3066 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3679 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1108/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2807 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3867 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1109/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2501 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2927 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1110/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2550 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2079 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1111/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3915 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2535 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1112/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1304 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.1667 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1113/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2063 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.1996 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1114/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1191 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.0662 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_fmeasure: 1.0000\n",
      "Epoch 1115/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1544 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2923 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1116/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2071 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3257 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1117/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5584 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.4897 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1118/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2913 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2530 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1119/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3862 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1432 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_fmeasure: 1.0000\n",
      "Epoch 1120/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4493 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1595 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1121/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2294 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3294 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1122/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1384 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.4689 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1123/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7652 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2971 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1124/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3945 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3100 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1125/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3003 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3988 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1126/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7887 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2092 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1127/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3481 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1864 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1128/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2966 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2623 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1129/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1407 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1034 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1130/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3983 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3143 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1131/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3698 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1849 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1132/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6128 - acc: 0.6562 - recall: 0.6562 - precision: 0.6562 - fmeasure: 0.6562 - val_loss: 0.6072 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1133/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3379 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1097 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1134/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1349 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.6227 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1135/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1755 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.5587 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1136/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5019 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3049 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1137/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3844 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2732 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1138/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8548 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5786 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1139/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4057 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5302 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1140/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3356 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2568 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1141/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2647 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2962 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1142/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8559 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.2714 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1143/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3294 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2991 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1144/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2414 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4163 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1145/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4023 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4212 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1146/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3004 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5276 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1147/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2071 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3869 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1148/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3230 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5340 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1149/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3923 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5563 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1150/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4785 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2558 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1151/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1639 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2990 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1152/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1011 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.0752 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1153/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1920 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2300 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1154/1500\n",
      "32/32 [==============================] - 1s - loss: 1.0114 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3358 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1155/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3451 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4834 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1156/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2235 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2359 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1157/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8144 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.2000 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1158/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2770 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1305 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1159/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5687 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2525 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1160/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3265 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3310 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1161/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3321 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5498 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1162/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7318 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4992 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1163/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3639 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2804 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1164/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2538 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3495 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1165/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6437 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2611 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1166/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3355 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3830 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1167/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2627 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4871 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1168/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3490 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4444 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1169/1500\n",
      "32/32 [==============================] - 1s - loss: 1.9346 - acc: 0.5312 - recall: 0.5312 - precision: 0.5312 - fmeasure: 0.5312 - val_loss: 0.7747 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1170/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8250 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.1860 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1171/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8544 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3575 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1172/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2881 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4129 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1173/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4198 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.5282 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1174/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3081 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3600 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1175/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3525 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4430 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1176/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2828 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2144 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1177/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4256 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2194 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1178/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1135 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4815 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1179/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2219 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5291 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1180/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4499 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4551 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1181/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5742 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.1737 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1182/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6251 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4903 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1183/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2732 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2935 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1184/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1925 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.1646 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1185/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4593 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.1466 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1186/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5335 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.3758 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1187/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4605 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.1404 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1188/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1281 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.2299 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1189/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2941 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4546 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1190/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6084 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.1745 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1191/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1848 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.8329 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1192/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4562 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.8684 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1193/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3373 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6259 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1194/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3681 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5886 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1195/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1697 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2879 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1196/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6042 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3145 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1197/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4116 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.7646 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1198/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3571 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.6052 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1199/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4661 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2954 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1200/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4307 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4673 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1201/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1853 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3051 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1202/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3246 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2548 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1203/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1455 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1191 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1204/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2279 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3812 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1205/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2736 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2700 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1206/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2923 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3600 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1207/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3884 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4361 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1208/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4108 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4770 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1209/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2870 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2469 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1210/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6307 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5112 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1211/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6919 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.4964 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1212/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3310 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3422 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1213/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3216 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3150 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1214/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3057 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2598 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1215/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4108 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.7751 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1216/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5655 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4393 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1217/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1245 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3646 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1218/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3280 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.1688 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1219/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2451 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1768 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1220/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4132 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5990 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1221/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3866 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5434 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1222/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1559 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3756 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1223/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7446 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2697 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1224/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1335 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.2827 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1225/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3583 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.8162 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1226/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3621 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4048 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1227/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1452 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1924 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1228/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1210 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4274 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1229/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5058 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.2864 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1230/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2201 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4349 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1231/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3651 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3827 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1232/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2478 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1890 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1233/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1856 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2078 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1234/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1596 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3137 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1235/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1787 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1720 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1236/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3971 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2095 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1237/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2822 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3435 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1238/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2387 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5172 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1239/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1716 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2214 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1240/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2981 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2094 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1241/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3382 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.1806 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1242/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2374 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2730 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1243/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2246 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4174 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1244/1500\n",
      "32/32 [==============================] - 1s - loss: 0.9688 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.1263 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1245/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1203 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.2907 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1246/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6483 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4082 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1247/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1409 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2742 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1248/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1145 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4472 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1249/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3590 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2347 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1250/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2855 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5032 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1251/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4155 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4565 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1252/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2563 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4268 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1253/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1736 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3008 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1254/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2570 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3017 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1255/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3665 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3416 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1256/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2499 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2574 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1257/1500\n",
      "32/32 [==============================] - 1s - loss: 0.0860 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.4003 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1258/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1548 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.2452 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1259/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3258 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2504 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1260/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1997 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2499 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1261/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5877 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2584 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1262/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4338 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.1230 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1263/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7474 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.1907 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1264/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4176 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5587 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1265/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3616 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3970 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1266/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3928 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3401 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1267/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3483 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2038 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1268/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3904 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3247 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1269/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2992 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1732 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1270/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4073 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1724 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1271/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1664 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3263 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1272/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1909 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4285 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1273/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2434 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.0901 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_fmeasure: 1.0000\n",
      "Epoch 1274/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1748 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5049 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1275/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7114 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3148 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1276/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2015 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2685 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1277/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4733 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2361 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1278/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3221 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3558 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1279/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2946 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5567 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1280/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4604 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5249 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1281/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4054 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3411 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1282/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1321 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.4931 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1283/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1717 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2546 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1284/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1867 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2988 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1285/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1528 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5012 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1286/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1485 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.5063 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1287/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3545 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2527 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1288/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2055 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3358 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1289/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1596 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1335 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1290/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1851 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2739 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1291/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2300 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2782 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1292/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2974 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2607 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1293/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2134 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4274 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1294/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3621 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4498 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1295/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8408 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3198 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1296/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3591 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3839 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1297/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2109 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4330 - val_acc: 0.7188 - val_recall: 0.7188 - val_precision: 0.7188 - val_fmeasure: 0.7187\n",
      "Epoch 1298/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3380 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4582 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1299/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2125 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3229 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1300/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1420 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3183 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1301/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4009 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4478 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1302/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2088 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.1362 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1303/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1867 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2930 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1304/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2978 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1793 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1305/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2198 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2603 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1306/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2245 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1966 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1307/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1943 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2015 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1308/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1862 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2497 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1309/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3464 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4029 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1310/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5327 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.1614 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1311/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1485 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4732 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1312/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2420 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3781 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1313/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2766 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4611 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1314/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1881 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4577 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1315/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2826 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1938 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1316/1500\n",
      "32/32 [==============================] - 1s - loss: 0.0806 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.6075 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1317/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3725 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1454 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1318/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3152 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1543 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1319/1500\n",
      "32/32 [==============================] - 1s - loss: 0.0877 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.2963 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1320/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3233 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2396 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1321/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2103 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2463 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1322/1500\n",
      "32/32 [==============================] - 1s - loss: 0.0508 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.3526 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1323/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5410 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.1576 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1324/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4505 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3799 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1325/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1704 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2275 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1326/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1166 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4044 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1327/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3220 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4430 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1328/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4871 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2051 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1329/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2378 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2179 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1330/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1166 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.2885 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1331/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1660 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4668 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1332/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4290 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.4765 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1333/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5382 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.3060 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1334/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2583 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3750 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1335/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3095 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2816 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1336/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2197 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3493 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1337/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1618 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3509 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1338/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5780 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.1855 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1339/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1033 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3074 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1340/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1440 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3600 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1341/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2829 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2816 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1342/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3310 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3314 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1343/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3210 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3754 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1344/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1733 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3299 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1345/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5431 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.2228 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1346/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3736 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2818 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1347/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4516 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5434 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1348/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2242 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2275 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1349/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4980 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2026 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1350/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1741 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5721 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1351/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1991 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2941 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1352/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2363 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1589 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1353/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3987 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4480 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1354/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2601 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2704 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1355/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2382 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4493 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1356/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4131 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2381 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1357/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3074 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4861 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1358/1500\n",
      "32/32 [==============================] - 1s - loss: 0.9004 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.1750 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1359/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3367 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.3923 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1360/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3368 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1570 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1361/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1894 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.1202 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_fmeasure: 1.0000\n",
      "Epoch 1362/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4488 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1880 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1363/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3780 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4665 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1364/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7020 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1725 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1365/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1871 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4071 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1366/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2513 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3231 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1367/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1179 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3094 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1368/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5446 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2862 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1369/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2356 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5164 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1370/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2487 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2243 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1371/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2532 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3984 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1372/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3041 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5762 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1373/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1967 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.2329 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1374/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3277 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4720 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1375/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4020 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3722 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1376/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1992 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3446 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1377/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2451 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3055 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1378/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1127 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.2731 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1379/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3023 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1301 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1380/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1587 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.4044 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1381/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1318 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3493 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1382/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2123 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3143 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1383/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3576 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3920 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1384/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1245 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3141 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1385/1500\n",
      "32/32 [==============================] - 1s - loss: 0.0622 - acc: 1.0000 - recall: 1.0000 - precision: 1.0000 - fmeasure: 1.0000 - val_loss: 0.2777 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1386/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1737 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3660 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1387/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1795 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1310 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1388/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3565 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3184 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1389/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3866 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4510 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1390/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6968 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.1461 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1391/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5906 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1928 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1392/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1319 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3479 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1393/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5072 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.5986 - val_acc: 0.6562 - val_recall: 0.6562 - val_precision: 0.6562 - val_fmeasure: 0.6562\n",
      "Epoch 1394/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3227 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2981 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1395/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3831 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.1557 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1396/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1670 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.1245 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1397/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4413 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2128 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1398/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3227 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3298 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1399/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1929 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3565 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1400/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3213 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1938 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1401/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7629 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.6145 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1402/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2118 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.0756 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1403/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4947 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3150 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1404/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4798 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3463 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1405/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2824 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.5595 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1406/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4196 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 1.0838 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1407/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7199 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 1.1641 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 1408/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6273 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.2451 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1409/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2007 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2333 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1410/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2149 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4174 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1411/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2672 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.4127 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1412/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3141 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.5284 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1413/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6507 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.4405 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1414/1500\n",
      "32/32 [==============================] - 1s - loss: 1.5574 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4779 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1415/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7796 - acc: 0.5938 - recall: 0.5938 - precision: 0.5938 - fmeasure: 0.5937 - val_loss: 0.3990 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1416/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8993 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3874 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1417/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1689 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.4533 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1418/1500\n",
      "32/32 [==============================] - 1s - loss: 1.0056 - acc: 0.7188 - recall: 0.7188 - precision: 0.7188 - fmeasure: 0.7187 - val_loss: 0.6505 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1419/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2800 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1124 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1420/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1373 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.0939 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1421/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5098 - acc: 0.7812 - recall: 0.7812 - precision: 0.7812 - fmeasure: 0.7812 - val_loss: 0.4127 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1422/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2442 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.7382 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1423/1500\n",
      "32/32 [==============================] - 1s - loss: 0.9455 - acc: 0.4688 - recall: 0.4688 - precision: 0.4688 - fmeasure: 0.4687 - val_loss: 0.3487 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1424/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1574 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.2404 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1425/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3950 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5365 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1426/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6344 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2195 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1427/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1970 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 1.3993 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1428/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3042 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1997 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1429/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1687 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2952 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1430/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4229 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3881 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1431/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4043 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2439 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1432/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2235 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3044 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1433/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7845 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2110 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1434/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2701 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3174 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1435/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6580 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.1171 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1436/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1571 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5067 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1437/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1222 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.2318 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1438/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1557 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.4239 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1439/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1976 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4824 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1440/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1920 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2704 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1441/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3998 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2068 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1442/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4004 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4509 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1443/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3334 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2720 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1444/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4123 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5099 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1445/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3809 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.9651 - val_acc: 0.5938 - val_recall: 0.5938 - val_precision: 0.5938 - val_fmeasure: 0.5937\n",
      "Epoch 1446/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6220 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.2834 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1447/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2164 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3455 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1448/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2462 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1737 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1449/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4022 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2032 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1450/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2785 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.8105 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1451/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6244 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2345 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1452/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4539 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3647 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1453/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1624 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3722 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1454/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2349 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2337 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1455/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2013 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3811 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1456/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4648 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.6371 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1457/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2634 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2064 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1458/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2848 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5621 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1459/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4994 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5560 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1460/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2534 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2633 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1461/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4646 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2139 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1462/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6420 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3245 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1463/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1687 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.5267 - val_acc: 0.7812 - val_recall: 0.7812 - val_precision: 0.7812 - val_fmeasure: 0.7812\n",
      "Epoch 1464/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1795 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.3767 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1465/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2654 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2002 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1466/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6569 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.4147 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1467/1500\n",
      "32/32 [==============================] - 1s - loss: 0.6831 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5203 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1468/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2007 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.4163 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1469/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1454 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.3804 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1470/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3745 - acc: 0.7500 - recall: 0.7500 - precision: 0.7500 - fmeasure: 0.7500 - val_loss: 0.5860 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1471/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4884 - acc: 0.6875 - recall: 0.6875 - precision: 0.6875 - fmeasure: 0.6875 - val_loss: 0.3054 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1472/1500\n",
      "32/32 [==============================] - 1s - loss: 0.5119 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.2800 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1473/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4257 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.7361 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1474/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3682 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3027 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1475/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3524 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.5853 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1476/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2839 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2778 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1477/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2294 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3232 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1478/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3378 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.2385 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1479/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3890 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.8563 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1480/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2545 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.1482 - val_acc: 0.9688 - val_recall: 0.9688 - val_precision: 0.9688 - val_fmeasure: 0.9687\n",
      "Epoch 1481/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3741 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.3680 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1482/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2232 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2803 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1483/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1895 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3154 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1484/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2659 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3406 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1485/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4339 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.2387 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1486/1500\n",
      "32/32 [==============================] - 1s - loss: 0.7191 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3912 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1487/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1265 - acc: 0.9688 - recall: 0.9688 - precision: 0.9688 - fmeasure: 0.9687 - val_loss: 0.6618 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1488/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2875 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.6409 - val_acc: 0.6875 - val_recall: 0.6875 - val_precision: 0.6875 - val_fmeasure: 0.6875\n",
      "Epoch 1489/1500\n",
      "32/32 [==============================] - 1s - loss: 0.4257 - acc: 0.8438 - recall: 0.8438 - precision: 0.8438 - fmeasure: 0.8437 - val_loss: 0.5634 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1490/1500\n",
      "32/32 [==============================] - 1s - loss: 0.3708 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3892 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1491/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1727 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.0692 - val_acc: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_fmeasure: 1.0000\n",
      "Epoch 1492/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2848 - acc: 0.8750 - recall: 0.8750 - precision: 0.8750 - fmeasure: 0.8750 - val_loss: 0.3377 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1493/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2049 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.1868 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1494/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1918 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.1620 - val_acc: 0.9375 - val_recall: 0.9375 - val_precision: 0.9375 - val_fmeasure: 0.9375\n",
      "Epoch 1495/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8923 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.5243 - val_acc: 0.7500 - val_recall: 0.7500 - val_precision: 0.7500 - val_fmeasure: 0.7500\n",
      "Epoch 1496/1500\n",
      "32/32 [==============================] - 1s - loss: 1.1875 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.3120 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n",
      "Epoch 1497/1500\n",
      "32/32 [==============================] - 1s - loss: 0.8979 - acc: 0.8125 - recall: 0.8125 - precision: 0.8125 - fmeasure: 0.8125 - val_loss: 0.7898 - val_acc: 0.8125 - val_recall: 0.8125 - val_precision: 0.8125 - val_fmeasure: 0.8125\n",
      "Epoch 1498/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2490 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.2778 - val_acc: 0.8750 - val_recall: 0.8750 - val_precision: 0.8750 - val_fmeasure: 0.8750\n",
      "Epoch 1499/1500\n",
      "32/32 [==============================] - 1s - loss: 0.1930 - acc: 0.9062 - recall: 0.9062 - precision: 0.9062 - fmeasure: 0.9062 - val_loss: 0.3558 - val_acc: 0.9062 - val_recall: 0.9062 - val_precision: 0.9062 - val_fmeasure: 0.9062\n",
      "Epoch 1500/1500\n",
      "32/32 [==============================] - 1s - loss: 0.2517 - acc: 0.9375 - recall: 0.9375 - precision: 0.9375 - fmeasure: 0.9375 - val_loss: 0.5890 - val_acc: 0.8438 - val_recall: 0.8438 - val_precision: 0.8438 - val_fmeasure: 0.8437\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(w_gender_train_gen, \n",
    "                              validation_data=w_gender_valid_gen,\n",
    "                              nb_val_samples=BATCH_SIZE,\n",
    "                              samples_per_epoch=BATCH_SIZE, \n",
    "                              nb_epoch=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 7. Evaluating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acc',\n",
       " 'loss',\n",
       " 'val_fmeasure',\n",
       " 'recall',\n",
       " 'precision',\n",
       " 'fmeasure',\n",
       " 'val_acc',\n",
       " 'val_recall',\n",
       " 'val_precision',\n",
       " 'val_loss']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_history = history.history['acc']\n",
    "valid_history = history.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJIAAAJcCAYAAACi347hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0a0096b210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0a00939cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Plotting training accuracy and testing accuracy acros epochs\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(train_history)\n",
    "plt.plot(valid_history)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig(PIC_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Tail-rolling average transform\n",
    "series_train = Series(train_history)\n",
    "rolling_train = series_train.rolling(window=100)\n",
    "rolling_mean_train = rolling_train.mean()\n",
    "\n",
    "series_valid = Series(valid_history)\n",
    "rolling_valid = series_valid.rolling(window=100)\n",
    "rolling_mean_valid = rolling_valid.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ8AAAJcCAYAAABXIQVRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNf8EWdqHoKK/GjoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0a003bf910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(rolling_mean_train)\n",
    "plt.plot(rolling_mean_valid)\n",
    "plt.title('Smoothened training and Validation Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Saving histories\n",
    "np.save(TRA_HISTORY_NAME, train_history)\n",
    "np.save(VAL_HISTORY_NAME, valid_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# saving weights\n",
    "model.save_weights(WEIGHTS_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Results on Adience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2026342423816379,\n",
       " 0.53776011232342724,\n",
       " 0.53776011227465093,\n",
       " 0.53776011227465093,\n",
       " 0.53776005267000615]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(adience_gender_test_gen,BATCH_SIZE*400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-06be4542c84f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mEX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'EX' is not defined"
     ]
    }
   ],
   "source": [
    "raise EX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Finetuning with Adience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(adience_gender_train_gen, \n",
    "                              validation_data=adience_gender_valid_gen,\n",
    "                              nb_val_samples=BATCH_SIZE,\n",
    "                              samples_per_epoch=BATCH_SIZE, \n",
    "                              nb_epoch=NUM_EPOCHS2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_history = history.history['acc']\n",
    "valid_history = history.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    " # Plotting training accuracy and testing accuracy acros epochs\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(train_history)\n",
    "plt.plot(valid_history)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig(PIC_NAME_FINETUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Tail-rolling average transform\n",
    "series_train = Series(train_history)\n",
    "rolling_train = series_train.rolling(window=100)\n",
    "rolling_mean_train = rolling_train.mean()\n",
    "\n",
    "series_valid = Series(valid_history)\n",
    "rolling_valid = series_valid.rolling(window=100)\n",
    "rolling_mean_valid = rolling_valid.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(rolling_mean_train)\n",
    "plt.plot(rolling_mean_valid)\n",
    "plt.title('Smoothened training and Validation Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Saving histories\n",
    "np.save(TRA_HISTORY_NAME_FINETUNING, train_history)\n",
    "np.save(VAL_HISTORY_NAME_FINETUNING, valid_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# saving weights\n",
    "model.save_weights(WEIGHTS_NAME_FINETUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(adience_gender_test_gen,BATCH_SIZE*400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
