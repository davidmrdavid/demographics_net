{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<center><h1>2. Vainilla CNNs</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Necessary modules\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "from keras.models     import Sequential\n",
    "from keras.layers     import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers     import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get the data\n",
    "data = pd.read_csv(filepath_or_buffer=\"../data/face_image_project/fold_0_data.txt\", sep=\"\\t\")\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = data[[\"user_id\",\"original_image\",\"face_id\",\"gender\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data.loc[data.gender != \"m\", \"gender\"] = 0\n",
    "data.loc[data.gender == \"m\", \"gender\"] = 1\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "path_template = \"../data/face_image_project/aligned/%s/landmark_aligned_face.%d.%s\"\n",
    "data[\"file_path\"] = data[[\"user_id\",\"face_id\",\"original_image\"]].apply(lambda x:  \n",
    "                                                                   path_template % (x[0],x[1],x[2]),\n",
    "                                                                   axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = data[[\"file_path\",\"gender\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Occurences of each gender seem pretty balanced. Looks good to me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Y      = data[\"gender\"]\n",
    "X_path = data[\"file_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tempo = X_path[1:3]\n",
    "tempo.apply(lambda x: img_to_array( load_img(x) ) ) #DOES IT NEED A RESHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "\n",
    "i_width  = 227\n",
    "i_height = 227\n",
    "\n",
    "#scipy.misc.imresize(original_image, (i_height, i_width))\n",
    "\n",
    "\n",
    "def train_generator(data):\n",
    "    while True:\n",
    "        start, end = 0, 32\n",
    "        while end < len(data):\n",
    "            data = data.sample(frac=1).reset_index(drop=True)\n",
    "            sample  = data[start:end]\n",
    "\n",
    "            X = pd.DataFrame(sample[\"file_path\"].apply(lambda x:  img_to_array( scipy.misc.imresize(load_img(x), (i_height, i_width) ) ) ))\n",
    "            \n",
    "            X = X[\"file_path\"].apply(lambda x: x.reshape((1,)+ x.shape))\n",
    "            X = np.vstack(X)\n",
    "            #print X[0].shape\n",
    "            #print X.shape\n",
    "            #\n",
    "            Y = sample[\"gender\"].as_matrix()\n",
    "            #print Y.as_matrix()\n",
    "            #print X.shape\n",
    "            #print X\n",
    "            yield (X, Y)\n",
    "            start += 32\n",
    "            end += 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gen = train_generator(data)\n",
    "a = gen.next()\n",
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Building a vainilla CNN\n",
    "vainilla_cnn = Sequential()\n",
    "vainilla_cnn.add(Convolution2D(32, 3, 3, input_shape=(227,227,3)))\n",
    "vainilla_cnn.add(Activation('relu'))\n",
    "vainilla_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "vainilla_cnn.add(Convolution2D(64, 3, 3))\n",
    "vainilla_cnn.add(Activation('relu'))\n",
    "vainilla_cnn.add(Convolution2D(64, 3, 3))\n",
    "vainilla_cnn.add(Activation('relu'))\n",
    "vainilla_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "vainilla_cnn.add(Flatten())\n",
    "vainilla_cnn.add(Dense(output_dim=200, input_dim=500))\n",
    "vainilla_cnn.add(BatchNormalization())\n",
    "vainilla_cnn.add(Activation(\"relu\"))\n",
    "vainilla_cnn.add(Dense(output_dim=100, input_dim=200))\n",
    "vainilla_cnn.add(BatchNormalization())\n",
    "vainilla_cnn.add(Activation(\"relu\"))\n",
    "vainilla_cnn.add(Dense(output_dim=1))\n",
    "vainilla_cnn.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compile\n",
    "vainilla_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "vainilla_cnn.fit_generator(train_generator(data), samples_per_epoch=64, nb_epoch=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rowToImgPath(row):\n",
    "    userid = row[\"user_id\"]\n",
    "    faceid = row[\"face_id\"]\n",
    "    original_img = row[\"original_image\"]\n",
    "    imgPath = \"../data/face_image_project/aligned/%s/landmark_aligned_face.%d.%s\" % (userid, faceid, original_img)\n",
    "    return imgPath\n",
    "\n",
    "def loadXY(data):\n",
    "    \"\"\" BE INCREDIBLY CAREFUL... The data is large - you could run out of memory and start thrashing.\n",
    "    It is highly advised to load a small subset at a time (100-200 rows)\n",
    "    \"\"\" \n",
    "    X = np.zeros((len(data), 816, 816, 3))\n",
    "    Y = data[\"gender\"]\n",
    "    for i in range(len(data)):\n",
    "        row = data.iloc[i]\n",
    "        img = load_img(rowToImgPath(row))\n",
    "        imgArray = img_to_array(img)\n",
    "        X[i] = imgArray\n",
    "    return X, Y\n",
    "\n",
    "def generateXY(data, size=5):\n",
    "    \"\"\" From Keras fit_generator API: The generator is expected to loop over its data indefinitely. \"\"\"\n",
    "    while True:\n",
    "        start, end = 0, size\n",
    "        while end <= len(data):\n",
    "            yield loadXY(data[start: end])\n",
    "            start, end =  start + size, end + size\n",
    "\n",
    "            \n",
    "def loadXY2(data):\n",
    "    \"\"\" BE INCREDIBLY CAREFUL... The data is large - you could run out of memory and start thrashing.\n",
    "    It is highly advised to load a small subset at a time (100-200 rows)\n",
    "    \"\"\" \n",
    "    X = np.zeros((len(data), 816, 816, 3))\n",
    "    Y = data[\"gender\"]\n",
    "    for i in range(len(data)):\n",
    "        row = data.iloc[i]\n",
    "        img = load_img(rowToImgPath(row))\n",
    "        imgArray = img_to_array(img)\n",
    "        X[i] = imgArray\n",
    "    return X, Y\n",
    "\n",
    "def generateXY2(data, size=32):\n",
    "    \"\"\" From Keras fit_generator API: The generator is expected to loop over its data indefinitely. \"\"\"\n",
    "    while True:\n",
    "        start, end = 0, size\n",
    "        while end <= len(data):\n",
    "            yield loadXY(data[start: end])\n",
    "            start, end =  start + size, end + size\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
