{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<center><h1>1. Adience Overview</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## About this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In order to evaluate our model, we need to split our available data intro training, validation and testing portions. That way, we can use the traning split to learn parameters, the validation set to decide on hyperparameters and the testing set to determine the final performance of our models unseen data. This method of model evaluation is called <b>Cross Validation</b>.\n",
    "\n",
    "However, it is often problematic to decide on which portions of the dataset should be used for training, testing and validation because the quality of the splits has a non-trivial effect on the model's performance. Luckily enough, the question of which portion to use for testing is already answered by the Adience Benchmark guidelines. More precisely, the 5th fold - that would be the fold4 because the folds are indexed starting at 0- is to be used as the testing set.\n",
    "\n",
    "With that question out of the way, we're still concerned with how to split the remaining data into a training and validation split. The technique of <b>K-Fold Cross Validation</b> answer this question by creating K different training and validation splits out of the remaining data, then testing our model and all of them and having the average performance of our models on all splits be our measure of accuracy / 'goodness'. We'll be using a specific variant of K-Fold Cross Validation called <b>Stratified K-Fold Cross Validation</b>.\n",
    "\n",
    "Stratified K-Fold Cross Validation forces the K different training-validation splits to have roughly the same distribution of classes in each of them. The idea here is to prevent any fold from having a non-trivial excess of a given class that would then bias the classifier created on it.\n",
    "\n",
    "Lastly, after our folds have been created, we'll organize them into directories in such a way that Keras's Image Processing tools can make use of it without extra -often hacky- workarounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Suggested Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If the explanation above didn't quite make sense. I recommend reviewing the sources below.\n",
    "\n",
    "1. https://www.youtube.com/watch?v=TIgfjmp-4BA\n",
    "2. stats.stackexchange.com/questions/117643/why-use-stratified-cross-validation-why-does-this-not-damage-variance-related-b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Creating the foundational splits on the Adience Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Adience Benchmark source: http://www.openu.ac.il/home/hassner/Adience/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensure reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path constants\n",
    "ADIENCE_TEMPALTE  = \"../../data/adience/%s\"\n",
    "METADATA_TEMPLATE = \"../../data/adience/face_image_project/fold_%s_data.txt\"\n",
    "IMG_TEMPLATE      = \"../../data/face_image_project/aligned/%s/landmark_aligned_face.%d.%s\"\n",
    "\n",
    "KERAS_TRAIN_TEMPLATE = \"../data/face_image_project/keras_format/train/%s/%d.jpg\"\n",
    "KERAS_VALID_TEMPLATE = \"../data/face_image_project/keras_format/valid/%s/%d.jpg\"\n",
    "KERAS_TEST_TEMPLATE  = \"../data/face_image_project/keras_format/test/%s/%d.jpg\"\n",
    "\n",
    "RELEVANT_COLS = [\"user_id\",\"face_id\",\"original_image\",\"gender\",\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Indepdendent constants\n",
    "NUM_TRAIN_FOLDS = 4\n",
    "IDX_TEST_FOLD   = 4\n",
    "NUM_SPLITS      = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependendent constants\n",
    "METADATA_TEST = METADATA_TEMPLATE % IDX_TEST_FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File ../../data/face_image_project/fold_0_data.txt does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-02b2b6e6466a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_TRAIN_FOLDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMETADATA_TEMPLATE\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrvl_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    644\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:4184)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:8449)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File ../../data/face_image_project/fold_0_data.txt does not exist"
     ]
    }
   ],
   "source": [
    "# Extracting the test partition and \n",
    "# creating a combined train_validation (trvl) superset\n",
    "\n",
    "folds = []\n",
    "for index in range(NUM_TRAIN_FOLDS):\n",
    "    path = METADATA_TEMPLATE % index\n",
    "    folds.append(pd.read_csv(filepath_or_buffer=path, sep=\"\\t\"))\n",
    "    \n",
    "trvl_meta = pd.concat(folds, ignore_index=True)\n",
    "test_meta = pd.read_csv(filepath_or_buffer=METADATA_TEST, sep=\"\\t\")\n",
    "\n",
    "trvl_meta = trvl_meta[RELEVANT_COLS]\n",
    "test_meta = test_meta[RELEVANT_COLS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "At this point, we've created an initial partition of our dataset into a testing split and its complement. Both splits still need more processing before they're ready for primetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Overview of current splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_meta[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_meta[\"age\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Aha! There are 'None'-valued ages. That's problematic. We'll need to do something about those. Thanfully, it's apparently only a few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_meta.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is unexpected, there are null / NaN values in this split. Let us inspect that further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_meta[test_meta.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### test complement set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trvl_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trvl_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trvl_meta[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trvl_meta[\"age\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is weird. There should not be ages outside ranges. Let's look into this as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trvl_meta.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Is is TRUE that there are NaN value in this set as well. We'll have to fix it too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fixing dataset inconsistencies and filling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The summaries above show problems with the dataset. Namely, NaNs as gender values, None as age values and inconsistent / overlapping labels for age. We address those issues right here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Dropping rows with NaN gender and None age simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Rows with NaN gender and None age are the most problematic because we cannot average any values in order to 'guesstimate' their real values. A possible solution would be to fill in those values by running a state-of-the-art model such as Face++ or Microsofts' Facial Features model but we think that'd be unecessary given that there aren't that many rows with these two characteristics at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Conditions for dropping\n",
    "NaN_gender_trvl = trvl_meta[\"gender\"].isnull()\n",
    "None_age_trvl   = trvl_meta[\"age\"] == \"None\"\n",
    "trvl_bad_rows    = NaN_gender_trvl & None_age_trvl\n",
    "trvl_bad_indices = trvl_meta[trvl_bad_rows].index.values\n",
    "\n",
    "# Dropping rows when two conditions are present\n",
    "trvl_meta.drop(labels=trvl_bad_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Conditions for dropping\n",
    "NaN_gender_test = test_meta[\"gender\"].isnull()\n",
    "None_age_test   = test_meta[\"age\"] == \"None\"\n",
    "test_bad_rows   = NaN_gender_test & None_age_test\n",
    "test_bad_indices = test_meta[test_bad_rows].index.values\n",
    "\n",
    "# Dropping rows when two conditions are present\n",
    "test_meta.drop(labels=test_bad_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fixing bad age ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We already know that some of the age labels for some reason are not declared as a range, as most other labels, but instead as a single number. This is problematic. The next section transform real, continuous ages into their matching ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Testing complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trvl_meta[\"age\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So we see that there are a lot of ages that are not in range format. Since the number of such occurences is rather limited. We'll fix them manually in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].replace(\"13\",\"(8, 13)\")\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].replace(\"(8, 12)\",\"(8, 13)\")\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].replace(\"42\",\"(38, 42)\")\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].replace(\"2\",\"(0, 2)\")\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].replace(\"29\",\"(25, 32)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What follows is a non-trivial change. For some reason, some of the ages don't fit into the supposed labeled ranges in the dataset. So we're gonna have to take some ages and simply group them inside their closest label, which will not necessary extend to the right range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].replace(\"35\",\"(25, 32)\")\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].replace(\"22\",\"(15, 20)\")\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].replace(\"34\",\"(25, 32)\")\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].replace(\"23\",\"(25, 32)\")\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].replace(\"45\",\"(48, 53)\")\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].replace(\"55\",\"(48, 53)\")\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].replace(\"36\",\"(38, 43)\")\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].replace(\"3\",\"(0, 2)\")\n",
    "\n",
    "\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].replace(\"57\",\"(60, 100)\")\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].replace(\"58\",\"(60, 100)\")\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].replace(\"56\",\"(60, 100)\")\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].replace(\"46\",\"(48, 53)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trvl_meta[\"age\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dropping None ages. Not worth manually tagging them\n",
    "trvl_meta = trvl_meta[trvl_meta[\"age\"] != \"None\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trvl_meta[\"age\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we do the same procedure as above but with the testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_meta[\"age\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_meta[\"age\"] = test_meta[\"age\"].replace(\"35\", \"(25, 32)\")\n",
    "test_meta[\"age\"] = test_meta[\"age\"].replace(\"57\", \"(60, 100)\")\n",
    "test_meta[\"age\"] = test_meta[\"age\"].replace(\"55\", \"(48, 53)\")\n",
    "test_meta[\"age\"] = test_meta[\"age\"].replace(\"45\", \"(38, 43)\")\n",
    "test_meta[\"age\"] = test_meta[\"age\"].replace(\"32\", \"(25, 32)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trvl_meta[\"gender\"].value_counts()\n",
    "test_meta[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_meta[\"age\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Nan Genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NaN_gender_trvl = trvl_meta[\"gender\"].notnull()\n",
    "NaN_gender_trvl.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NaN_gender_test = test_meta[\"gender\"].notnull()\n",
    "NaN_gender_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Since the number of NaN gender is quite small, there's no problem with dropping those as wel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_meta = test_meta[NaN_gender_test]\n",
    "trvl_meta = trvl_meta[NaN_gender_trvl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Checking value counts again for sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NaN_gender_trvl = trvl_meta[\"gender\"].notnull()\n",
    "NaN_gender_trvl.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NaN_gender_test = test_meta[\"gender\"].notnull()\n",
    "NaN_gender_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Perfect! The dataset has been fully curated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generating k-folds of train and validation splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this section we create K stratified folds of training and validation splits out of the complement of the testing set. We'll set the number of folds created to be equal to 5 as that is the number of splits suggested by the Adience Benchmark README file.\n",
    "\n",
    "Let us take this moment to discuss propotions. Each fold of the original, unprocessed, dataset contains roughly the same amount of data. Given that there are a total of 5 folds and one of them is reserved for testing, the percentage of the dataset used for testing will be roughly 20%. Out of the remaining data, we'll use  25% of each of the k-folds to be reserved for validation. This means that our testing dataset split follows roughly the following proportions.\n",
    "\n",
    "<ul>\n",
    "<li><b>Testing:</b> 20%</li>\n",
    "<li><b>Validation:</b>20%</li>\n",
    "<li><b>Training</b>:60%</li>\n",
    "</ul>\n",
    "\n",
    "This configuration is not accidental, we've chosen this proportions because they're common practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_splits = 5\n",
    "validation_prop = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=num_splits, test_size=validation_prop, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Prepping the test complement set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For the stratified k-fold partitioning tool to function, all classes need to appear at least twice in the training dataset. Given the amount of data we've dropped, such is not the case anymore. Observe below the current frequency of targets for age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trvl_meta[\"age\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As one can observe, (8,23) and (38,48) appear only once. We'll artifically force them to appear twice by literally duplicating their entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query1 = trvl_meta[\"age\"] == \"(8, 23)\"\n",
    "query2 = trvl_meta[\"age\"] == \"(38, 48)\"\n",
    "trvl_meta[query1 | query2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trvl_meta = trvl_meta.append(trvl_meta[query1 | query2], ignore_index=True)\n",
    "trvl_meta[\"age\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we're good to go! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here I'll introduce a minor but necessary fix to the dataset. Directory names in UNIX cannot start with parenthesis. Thus, I'll remove the parenthesis from the age column and replace them with '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].str.replace(\"(\", \"_\")\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].str.replace(\")\", \"_\")\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].str.replace(\" \", \"-\")\n",
    "trvl_meta[\"age\"] = trvl_meta[\"age\"].str.replace(\",\", \"\")\n",
    "trvl_meta[\"age\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_meta[\"age\"] = test_meta[\"age\"].str.replace(\"(\", \"_\")\n",
    "test_meta[\"age\"] = test_meta[\"age\"].str.replace(\")\", \"_\")\n",
    "test_meta[\"age\"] = test_meta[\"age\"].str.replace(\" \", \"-\")\n",
    "test_meta[\"age\"] = test_meta[\"age\"].str.replace(\",\", \"\")\n",
    "test_meta[\"age\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next up, since we'll be creating models for various classification tasks (predict gender, age and gender+age) then we need to make sure that our dataset has all those targets as columns. We're missing the column for gender+age. That column is created below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trvl_meta[\"gender_age\"] = trvl_meta[[\"gender\",\"age\"]].apply(lambda x: x[0]+\"_\"+x[1], axis=1)\n",
    "trvl_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This column will suffer from the same problem as age: to few instances of a given class. We fix that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query1 = trvl_meta[\"gender_age\"] == \"u__4-6_\"\n",
    "query2 = trvl_meta[\"gender_age\"] == \"u__60-100_\"\n",
    "trvl_meta[query1 | query2]\n",
    "trvl_meta = trvl_meta.append(trvl_meta[query1 | query2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trvl_meta_X     = trvl_meta\n",
    "trvl_meta_X_arr = trvl_meta_X.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trvl_meta_Y_gender  = trvl_meta[\"gender\"].as_matrix()\n",
    "trvl_meta_Y_age     = trvl_meta[\"age\"].as_matrix()\n",
    "trvl_meta_Y_both    = trvl_meta[\"gender_age\"].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Splits for gender-only classication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "X = trvl_meta_X_arr\n",
    "y = trvl_meta_Y_gender\n",
    "sss = StratifiedShuffleSplit(n_splits=num_splits, test_size=validation_prop, random_state=0)\n",
    "sss.get_n_splits(X, y)\n",
    "\n",
    "fold_count   = 1\n",
    "fold_container_gender = []\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print \"FOLD #: %d\" % fold_count\n",
    "    print \"TRAIN      :\", train_index\n",
    "    print \"VALIDATION :\", test_index\n",
    "    print \"=========================================================\"\n",
    "    fold_count += 1\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    fold_container_gender.append([X_train,X_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Splits for age-only classication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "X = trvl_meta_X_arr\n",
    "y = trvl_meta_Y_age\n",
    "sss = StratifiedShuffleSplit(n_splits=num_splits, test_size=validation_prop, random_state=0)\n",
    "sss.get_n_splits(X, y)\n",
    "\n",
    "fold_count   = 1\n",
    "fold_container_age = []\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print \"FOLD #: %d\" % fold_count\n",
    "    print \"TRAIN      :\", train_index\n",
    "    print \"VALIDATION :\", test_index\n",
    "    print \"=========================================================\"\n",
    "    fold_count += 1\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    fold_container_age.append([X_train,X_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generating dataframes for each classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "headers = [\"user_id\",\"face_id\",\"original_image\",\"gender\",\"age\",\"gender_age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gender_fold1_train = pd.DataFrame(fold_container_gender[0][0], columns=headers)\n",
    "gender_fold1_valid = pd.DataFrame(fold_container_gender[0][1], columns=headers)\n",
    "\n",
    "gender_fold2_train = pd.DataFrame(fold_container_gender[1][0], columns=headers)\n",
    "gender_fold2_valid = pd.DataFrame(fold_container_gender[1][1], columns=headers)\n",
    "\n",
    "gender_fold3_train = pd.DataFrame(fold_container_gender[2][0], columns=headers)\n",
    "gender_fold3_valid = pd.DataFrame(fold_container_gender[2][1], columns=headers)\n",
    "\n",
    "gender_fold4_train = pd.DataFrame(fold_container_gender[3][0], columns=headers)\n",
    "gender_fold4_valid = pd.DataFrame(fold_container_gender[3][1], columns=headers)\n",
    "\n",
    "gender_fold5_train = pd.DataFrame(fold_container_gender[4][0], columns=headers)\n",
    "gender_fold5_valid = pd.DataFrame(fold_container_gender[4][1], columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "age_fold1_train = pd.DataFrame(fold_container_age[0][0], columns=headers)\n",
    "age_fold1_valid = pd.DataFrame(fold_container_age[0][1], columns=headers)\n",
    "\n",
    "age_fold2_train = pd.DataFrame(fold_container_age[1][0], columns=headers)\n",
    "age_fold2_valid = pd.DataFrame(fold_container_age[1][1], columns=headers)\n",
    "\n",
    "age_fold3_train = pd.DataFrame(fold_container_age[2][0], columns=headers)\n",
    "age_fold3_valid = pd.DataFrame(fold_container_age[2][1], columns=headers)\n",
    "\n",
    "age_fold4_train = pd.DataFrame(fold_container_age[3][0], columns=headers)\n",
    "age_fold4_valid = pd.DataFrame(fold_container_age[3][1], columns=headers)\n",
    "\n",
    "age_fold5_train = pd.DataFrame(fold_container_age[4][0], columns=headers)\n",
    "age_fold5_valid = pd.DataFrame(fold_container_age[4][1], columns=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Augment Dataframes to contain the current image path and the image path to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img_path         = \"../data/face_image_project/aligned/%s/landmark_aligned_face.%d.%s\"\n",
    "\n",
    "keras_gender_train_path = \"../data/face_image_project/keras_format/gender/%d/train/%s/%d.jpg\"\n",
    "keras_gender_valid_path = \"../data/face_image_project/keras_format/gender/%d/valid/%s/%d.jpg\"\n",
    "\n",
    "keras_age_train_path = \"../data/face_image_project/keras_format/age/%d/train/%s/%d.jpg\"\n",
    "keras_age_valid_path = \"../data/face_image_project/keras_format/age/%d/valid/%s/%d.jpg\"\n",
    "\n",
    "relevant_cols = [\"user_id\",\"face_id\",\"original_image\",\"gender\",\"age\",\"gender_age\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gender_fold1_train[\"img_path\"] = gender_fold1_train[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "gender_fold1_valid[\"img_path\"] = gender_fold1_valid[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "\n",
    "gender_fold2_train[\"img_path\"] = gender_fold2_train[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "gender_fold2_valid[\"img_path\"] = gender_fold2_valid[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "\n",
    "gender_fold3_train[\"img_path\"] = gender_fold3_train[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "gender_fold3_valid[\"img_path\"] = gender_fold3_valid[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "\n",
    "gender_fold4_train[\"img_path\"] = gender_fold4_train[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "gender_fold4_valid[\"img_path\"] = gender_fold4_valid[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "\n",
    "gender_fold5_train[\"img_path\"] = gender_fold5_train[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "gender_fold5_valid[\"img_path\"] = gender_fold5_valid[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "age_fold1_train[\"img_path\"] = age_fold1_train[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "age_fold1_valid[\"img_path\"] = age_fold1_valid[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "\n",
    "age_fold2_train[\"img_path\"] = age_fold2_train[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "age_fold2_valid[\"img_path\"] = age_fold2_valid[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "\n",
    "age_fold3_train[\"img_path\"] = age_fold3_train[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "age_fold3_valid[\"img_path\"] = age_fold3_valid[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "\n",
    "age_fold4_train[\"img_path\"] = age_fold4_train[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "age_fold4_valid[\"img_path\"] = age_fold4_valid[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "\n",
    "age_fold5_train[\"img_path\"] = age_fold5_train[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "age_fold5_valid[\"img_path\"] = age_fold5_valid[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "both_fold1_train[\"img_path\"] = both_fold1_train[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "both_fold1_valid[\"img_path\"] = both_fold1_valid[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "\n",
    "both_fold2_train[\"img_path\"] = both_fold2_train[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "both_fold2_valid[\"img_path\"] = both_fold2_valid[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "\n",
    "both_fold3_train[\"img_path\"] = both_fold3_train[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "both_fold3_valid[\"img_path\"] = both_fold3_valid[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "\n",
    "both_fold4_train[\"img_path\"] = both_fold4_train[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "both_fold4_valid[\"img_path\"] = both_fold4_valid[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "\n",
    "both_fold5_train[\"img_path\"] = both_fold5_train[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)\n",
    "both_fold5_valid[\"img_path\"] = both_fold5_valid[relevant_cols].apply(lambda x: img_path % (x[0],x[1],x[2]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Keras path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gender_fold1_train[\"keras_path\"] = gender_fold1_train[relevant_cols].apply(lambda x: keras_gender_train_path % (1, x[3],x.name), axis=1)\n",
    "gender_fold1_valid[\"keras_path\"] = gender_fold1_valid[relevant_cols].apply(lambda x: keras_gender_valid_path % (1, x[3],x.name), axis=1)\n",
    "\n",
    "gender_fold2_train[\"keras_path\"] = gender_fold2_train[relevant_cols].apply(lambda x: keras_gender_train_path % (2, x[3],x.name), axis=1)\n",
    "gender_fold2_valid[\"keras_path\"] = gender_fold2_valid[relevant_cols].apply(lambda x: keras_gender_valid_path % (2, x[3],x.name), axis=1)\n",
    "\n",
    "gender_fold3_train[\"keras_path\"] = gender_fold3_train[relevant_cols].apply(lambda x: keras_gender_train_path % (3, x[3],x.name), axis=1)\n",
    "gender_fold3_valid[\"keras_path\"] = gender_fold3_valid[relevant_cols].apply(lambda x: keras_gender_valid_path % (3, x[3],x.name), axis=1)\n",
    "\n",
    "gender_fold4_train[\"keras_path\"] = gender_fold4_train[relevant_cols].apply(lambda x: keras_gender_train_path % (4, x[3],x.name), axis=1)\n",
    "gender_fold4_valid[\"keras_path\"] = gender_fold4_valid[relevant_cols].apply(lambda x: keras_gender_valid_path % (4, x[3],x.name), axis=1)\n",
    "\n",
    "gender_fold5_train[\"keras_path\"] = gender_fold5_train[relevant_cols].apply(lambda x: keras_gender_train_path % (5, x[3],x.name), axis=1)\n",
    "gender_fold5_valid[\"keras_path\"] = gender_fold5_valid[relevant_cols].apply(lambda x: keras_gender_valid_path % (5, x[3],x.name), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "age_fold1_train[\"keras_path\"] = age_fold1_train[relevant_cols].apply(lambda x: keras_age_train_path % (1, x[4],x.name), axis=1)\n",
    "age_fold1_valid[\"keras_path\"] = age_fold1_valid[relevant_cols].apply(lambda x: keras_age_valid_path % (1, x[4],x.name), axis=1)\n",
    "\n",
    "age_fold2_train[\"keras_path\"] = age_fold2_train[relevant_cols].apply(lambda x: keras_age_train_path % (2, x[4],x.name), axis=1)\n",
    "age_fold2_valid[\"keras_path\"] = age_fold2_valid[relevant_cols].apply(lambda x: keras_age_valid_path % (2, x[4],x.name), axis=1)\n",
    "\n",
    "age_fold3_train[\"keras_path\"] = age_fold3_train[relevant_cols].apply(lambda x: keras_age_train_path % (3, x[4],x.name), axis=1)\n",
    "age_fold3_valid[\"keras_path\"] = age_fold3_valid[relevant_cols].apply(lambda x: keras_age_valid_path % (3, x[4],x.name), axis=1)\n",
    "\n",
    "age_fold4_train[\"keras_path\"] = age_fold4_train[relevant_cols].apply(lambda x: keras_age_train_path % (4, x[4],x.name), axis=1)\n",
    "age_fold4_valid[\"keras_path\"] = age_fold4_valid[relevant_cols].apply(lambda x: keras_age_valid_path % (4, x[4],x.name), axis=1)\n",
    "\n",
    "age_fold5_train[\"keras_path\"] = age_fold5_train[relevant_cols].apply(lambda x: keras_age_train_path % (5, x[4],x.name), axis=1)\n",
    "age_fold5_valid[\"keras_path\"] = age_fold5_valid[relevant_cols].apply(lambda x: keras_age_valid_path % (5, x[4],x.name), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "both_fold1_train[\"keras_path\"] = both_fold1_train[relevant_cols].apply(lambda x: keras_both_train_path % (1, x[5],x.name), axis=1)\n",
    "both_fold1_valid[\"keras_path\"] = both_fold1_valid[relevant_cols].apply(lambda x: keras_both_valid_path % (1, x[5],x.name), axis=1)\n",
    "\n",
    "both_fold2_train[\"keras_path\"] = both_fold2_train[relevant_cols].apply(lambda x: keras_both_train_path % (2, x[5],x.name), axis=1)\n",
    "both_fold2_valid[\"keras_path\"] = both_fold2_valid[relevant_cols].apply(lambda x: keras_both_valid_path % (2, x[5],x.name), axis=1)\n",
    "\n",
    "both_fold3_train[\"keras_path\"] = both_fold3_train[relevant_cols].apply(lambda x: keras_both_train_path % (3, x[5],x.name), axis=1)\n",
    "both_fold3_valid[\"keras_path\"] = both_fold3_valid[relevant_cols].apply(lambda x: keras_both_valid_path % (3, x[5],x.name), axis=1)\n",
    "\n",
    "both_fold4_train[\"keras_path\"] = both_fold4_train[relevant_cols].apply(lambda x: keras_both_train_path % (4, x[5],x.name), axis=1)\n",
    "both_fold4_valid[\"keras_path\"] = both_fold4_valid[relevant_cols].apply(lambda x: keras_both_valid_path % (4, x[5],x.name), axis=1)\n",
    "\n",
    "both_fold5_train[\"keras_path\"] = both_fold5_train[relevant_cols].apply(lambda x: keras_both_train_path % (5, x[5],x.name), axis=1)\n",
    "both_fold5_valid[\"keras_path\"] = both_fold5_valid[relevant_cols].apply(lambda x: keras_both_valid_path % (5, x[5],x.name), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def prep_adience():\n",
    "    all_gender_train = [gender_fold1_train,gender_fold2_train,gender_fold3_train,gender_fold4_train,gender_fold5_train]\n",
    "    all_gender_valid = [gender_fold1_valid,gender_fold2_valid,gender_fold3_valid,gender_fold4_valid,gender_fold5_valid]\n",
    "    \n",
    "    #all_age_train = [age_fold1_train,age_fold2_train,age_fold3_train,age_fold4_train,age_fold5_train]\n",
    "    #all_age_valid = [age_fold1_valid,age_fold2_valid,age_fold3_valid,age_fold4_valid,age_fold5_valid]\n",
    "\n",
    "    #all_both_train = [both_fold1_train,both_fold2_train,both_fold3_train,both_fold4_train,both_fold5_train]\n",
    "    #all_both_valid = [both_fold1_valid,both_fold2_valid,both_fold3_valid,both_fold4_valid,both_fold5_valid]\n",
    "    \n",
    "    full_meta = pd.concat(all_gender_train + all_gender_valid)\n",
    "\n",
    "    for index, row in full_meta.iterrows():\n",
    "        \n",
    "        mkdir_template = \"mkdir -p %s\"\n",
    "        command_template = \"cp -p %s %s\"\n",
    "        command0 = mkdir_template % row[\"keras_path\"]\n",
    "        command1 = command_template % (row[\"img_path\"], row[\"keras_path\"])\n",
    "        wkspFldr = os.path.dirname(row[\"keras_path\"])\n",
    "        \n",
    "        os.system(command0)\n",
    "        os.system(command1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "raise Ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prep_adience()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Testing Image Pre-Processing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img(\"../data/face_image_project/keras_format/train/m/9.jpg\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "#os.makedirs(\"../data/preview\")\n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='../data/preview', save_prefix='augmented_', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 5:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from glob import glob\n",
    "import PIL\n",
    "images = [ PIL.Image.open(f) for f in glob('../data/preview/*') ]\n",
    "\n",
    "def img2array(im):\n",
    "    if im.mode != 'RGB':\n",
    "        im = im.convert(mode='RGB')\n",
    "    return np.fromstring(im.tobytes(), dtype='uint8').reshape((im.size[1], im.size[0], 3))\n",
    "\n",
    "np_images = [ img2array(im) for im in images ]\n",
    "\n",
    "\n",
    "\n",
    "for img in np_images:\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
